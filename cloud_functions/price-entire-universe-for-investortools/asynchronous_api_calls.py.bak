'''
Author: Developer Ray
Date: 2024-05-24
Last Editor: Developer Ray
Last Edit Date: 2025-03-05
Description: Makes asynchronous calls for large batch pricing.
'''
import aiohttp
import asyncio
import async_timeout

import pandas as pd

from auxiliary_variables import TESTING, COLUMNS_TO_KEEP
from auxiliary_functions import get_api_call


MAX_RETRIES_FOR_EXPONENTIAL_BACKOFF = 3


async def exponential_backoff(session, url, data, max_retries=MAX_RETRIES_FOR_EXPONENTIAL_BACKOFF, backoff_factor=2):
    retries = 0
    timeout = 300    # in seconds
    while retries < max_retries:
        try:
            async with async_timeout.timeout(300):    # timeout set to 5 minutes
                async with session.post(url, data=data) as response:
                    if response.status == 200:
                        return await response.json()
                    else:
                        response_text = await response.text()
                        raise aiohttp.ClientResponseError(request_info=response.request_info,
                                                          history=response.history,
                                                          status=response.status,
                                                          message=response_text,
                                                          headers=response.headers)
        except asyncio.TimeoutError as e:
            print(f'Request timed out (did not complete within {timeout} seconds) inside asynchronous_api_calls.py::exponential_backoff(...). {type(e)}: {e}. Request called with data:\n{data}')
        except Exception as e:
            print(f'Request failed inside asynchronous_api_calls.py::exponential_backoff(...). {type(e)}: {e}. Request called with data:\n{data}')
        retries += 1
        wait_time = min(backoff_factor ** retries, 10)
        print(f'Retrying inside asynchronous_api_calls.py::exponential_backoff(...) after {wait_time} seconds. {max_retries - retries} retries remaining after this one.')
        await asyncio.sleep(wait_time)
    max_retries_exceeded_error_message = f'Max retries of {max_retries} exceeded inside asynchronous_api_calls.py::exponential_backoff(...).'
    # each of the below `print` statements should be its own `print` statement instead of putting them in a single `print` statement with `\n` separators because Google Cloud logging has a limit of how many characters can be printed per log entry and splitting it into multiple `print` statements allows for each to be a separate log entry
    print(max_retries_exceeded_error_message)
    print(f'CUSIPs: {data["cusipList"]}')
    print(f'Quantities: {data["quantityList"]}')
    print(f'Trade types: {data["tradeTypeList"]}')
    raise RuntimeError(max_retries_exceeded_error_message)


async def call_batch_pricing(session, cusip_list, quantity_list, trade_type_list, username, password):
    url, data = get_api_call(cusip_list, quantity_list, trade_type_list, username, password)
    if TESTING:
        print(f'Sending the following form to the POST request at: {url}')    # using `tqdm.write(...)` was supposed to maintain the progress bar even with print statements but is instead causing errors in `functions-framework`
        print(data)    # using `tqdm.write(...)` was supposed to maintain the progress bar even with print statements but is instead causing errors in `functions-framework`
    response_json = await exponential_backoff(session, url, data)

    try:
        priced_df = pd.read_json(response_json)[COLUMNS_TO_KEEP]
    except Exception:
        if 'error' in response_json and response_json['error'] == 'You have been logged out due to a period of inactivity. Refresh the page!':
            print('User credentials could not been found, so raising aiohttp.ClientResponseError inside asynchronous_api_calls.py::call_batch_pricing(...)')
            raise aiohttp.ClientResponseError(request_info=None, history=None, status=401, message='You have been logged out due to a period of inactivity. Refresh the page!', headers=None)
        else:
            raise RuntimeError(f'unable to call `pd.read_json(...)` on the response even though `response.ok` is `True`. Running `response.json()` provides:\n{response_json}')    # raise error instead of printing the message to trigger the retry from the decorator: `run_multiple_times_before_failing`
    priced_df['quantity'] = priced_df['quantity'] // 1000    # requested by InvestorTools
    return priced_df


async def price_batches(cusip_list_batches, quantity_list_batches, trade_type_list_batches, username, password):
    async with aiohttp.ClientSession() as session:
        tasks = []
        for batch in zip(cusip_list_batches, quantity_list_batches, trade_type_list_batches):
            await asyncio.sleep(0.1)    # 0.1 second sleep between each call to not overwhelm the server
            tasks.append(asyncio.create_task(call_batch_pricing(session, *batch, username, password)))    # task automatically starts running when called with `asyncio.create_task(...)`
        priced_batches = await asyncio.gather(*tasks, return_exceptions=True)
    return priced_batches
