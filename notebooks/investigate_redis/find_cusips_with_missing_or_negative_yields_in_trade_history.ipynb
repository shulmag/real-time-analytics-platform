{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import redis\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import multiprocess as mp    # using `multiprocess` instead of `multiprocessing` because function to be called in `map` is in the same file as the function which is calling it: https://stackoverflow.com/questions/41385708/multiprocessing-example-giving-attributeerro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from `cloud_functions/fast_trade_history_redis_update/main.py`\n",
    "FEATURES_FOR_EACH_TRADE_IN_HISTORY = {'msrb_valid_from_date': 'DATETIME', \n",
    "                                      'msrb_valid_to_date': 'DATETIME', \n",
    "                                      'rtrs_control_number': 'INTEGER', \n",
    "                                      'trade_datetime': 'DATETIME', \n",
    "                                      'publish_datetime': 'DATETIME', \n",
    "                                      'yield': 'FLOAT', \n",
    "                                      'dollar_price': 'FLOAT', \n",
    "                                      'par_traded': 'NUMERIC', \n",
    "                                      'trade_type': 'STRING', \n",
    "                                      'is_non_transaction_based_compensation': 'BOOLEAN', \n",
    "                                      'is_lop_or_takedown': 'BOOLEAN', \n",
    "                                      'brokers_broker': 'STRING', \n",
    "                                      'is_alternative_trading_system': 'BOOLEAN', \n",
    "                                      'is_weighted_average_price': 'BOOLEAN', \n",
    "                                      'settlement_date': 'DATE', \n",
    "                                      'calc_date': 'DATE', \n",
    "                                      'calc_day_cat': 'INTEGER', \n",
    "                                      'maturity_date': 'DATE', \n",
    "                                      'next_call_date': 'DATE', \n",
    "                                      'par_call_date': 'DATE', \n",
    "                                      'refund_date': 'DATE', \n",
    "                                      'transaction_type': 'STRING', \n",
    "                                      'sequence_number': 'INTEGER'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_history_redis_client = redis.Redis(host='10.75.46.228', port=6379, db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_negative_yields(trade_history_df):\n",
    "    '''First remove missing yields and then check if there are negative yields.'''\n",
    "    trade_history_df = trade_history_df[~pd.isna(trade_history_df['yield'])]    # remove trades with missing yields\n",
    "    return (trade_history_df['yield'] < 0).any()\n",
    "\n",
    "\n",
    "def has_missing_yields(trade_history_df):\n",
    "    '''Check if any trade has a missing yield.'''\n",
    "    return pd.isna(trade_history_df['yield']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_yields_in_trade_history = []\n",
    "missing_yields_in_trade_history = []\n",
    "for cusip in trade_history_redis_client.scan_iter():    # scan_iter() is superior to keys() for large numbers of keys because it gives you an iterator you can use rather than trying to load all the keys into memory; https://stackoverflow.com/questions/22255589/get-all-keys-in-redis-database-with-python\n",
    "    trade_history_df = pd.DataFrame(pickle.loads(trade_history_redis_client.get(cusip)), columns=list(FEATURES_FOR_EACH_TRADE_IN_HISTORY.keys()))\n",
    "    if has_negative_yields(trade_history_df):    # may have missing yields as well\n",
    "        negative_yields_in_trade_history.append(cusip.decode('utf-8'))    # decode with 'utf-8' is necessary since the keys are byte-strings; https://stackoverflow.com/questions/606191/convert-bytes-to-a-string-in-python-3\n",
    "    if has_missing_yields(trade_history_df):\n",
    "        missing_yields_in_trade_history.append(cusip.decode('utf-8'))    # decode with 'utf-8' is necessary since the keys are byte-strings; https://stackoverflow.com/questions/606191/convert-bytes-to-a-string-in-python-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_negative_yields_or_missing_yields(cusip):\n",
    "    trade_history = pickle.loads(trade_history_redis_client.get(cusip))\n",
    "    return cusip.decode('utf-8'), has_negative_yields(trade_history), has_missing_yields(trade_history)    # decode with 'utf-8' is necessary since the keys are byte-strings; https://stackoverflow.com/questions/606191/convert-bytes-to-a-string-in-python-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool() as pool_object:\n",
    "    cusips_with_negative_yields_or_missing_yields = pool_object.map(has_negative_yields_or_missing_yields, trade_history_redis_client.scan_iter())\n",
    "\n",
    "negative_yields_in_trade_history, missing_yields_in_trade_history = [], []\n",
    "for cusip, has_negative_yield, missing_yield in cusips_with_negative_yields_or_missing_yields:\n",
    "    if has_negative_yield: negative_yields_in_trade_history.append(cusip)\n",
    "    if has_missing_yields: missing_yields_in_trade_history.append(cusip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_cusip_list_to_csv(cusip_list, csv_file_name):\n",
    "    '''Write each CUSIP in `cusip_list` to a new line in the csv at `csv_file_name`.'''\n",
    "    with open(csv_file_name, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        for cusip in cusip_list:\n",
    "            csv_writer.writerow([cusip])\n",
    "    return csv_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cusips_with_missing_yields_in_trade_history.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_cusip_list_to_csv(negative_yields_in_trade_history, 'cusips_with_negative_yields_in_trade_history.csv')\n",
    "write_cusip_list_to_csv(missing_yields_in_trade_history, 'cusips_with_missing_yields_in_trade_history.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
