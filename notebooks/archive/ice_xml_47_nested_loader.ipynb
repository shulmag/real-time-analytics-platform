{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os, csv, xmltodict, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../creds.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'eng-reactor-287421'\n",
    "dataset = 'reference_data'\n",
    "data_table = 'ice_nested'\n",
    "map_table = 'ice_bq_map'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get schema and modification details from bq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient = bigquery.Client(project=PROJECT,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mapping schema from bigquery\n",
    "map_query = \"\"\"\n",
    "SELECT * FROM {}.{}\n",
    "\n",
    "           \"\"\".format(dataset,map_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_map_result = bqclient.query(map_query).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_map_result = list(bq_map_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_schema,map_version,leaf_nodes,repeated_record_nodes,address_key_list,bad_address_list = bq_map_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes = [[entry['path'],entry['type'],entry['mode']] for entry in leaf_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_key_list = [[entry['path'],entry['key']] for entry in address_key_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_leafs = [entry[0] for entry in leaf_nodes if entry[2]=='REPEATED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_repeated_nodes = repeated_leafs + repeated_record_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address_list is '/' seperated string of nodes address\n",
    "# xml_dict is ice instrument in python dict\n",
    "# function checks all repeated nodes in address, if in the instrument, checks if instrument is wrapped in a list\n",
    "# if not, entry is wrapped in a list\n",
    "\n",
    "def repeated_enforcement(address_list,xml_dict):\n",
    "    split_address_list = [entry.split('/')[1:] for entry in address_list]\n",
    "    \n",
    "    for address in split_address_list:\n",
    "        current_xml_level = xml_dict\n",
    "        for current_index in range(len(address)-1):\n",
    "            if address[current_index] not in current_xml_level:\n",
    "                break\n",
    "            current_xml_level = current_xml_level[address[current_index]]\n",
    "\n",
    "        if address[-1] not in current_xml_level:\n",
    "            continue\n",
    "        else:\n",
    "            if not isinstance(current_xml_level[address[-1]],list):\n",
    "                current_xml_level[address[-1]]=[current_xml_level[address[-1]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address_key_list contains '/' seperated string of nodes address and the key value to extract\n",
    "# key value in child node of node in address_key_list is extracted and put as value for node\n",
    "\n",
    "def record_key_flatten(address_key_list,xml_dict):\n",
    "    split_address_key_list = [[entry[0].split('/')[1:],entry[1]] for entry in address_key_list]\n",
    "    \n",
    "    for entry in split_address_key_list:\n",
    "        address, key = entry\n",
    "        current_xml_level = xml_dict\n",
    "        for current_index in range(len(address)-1):\n",
    "            if address[current_index] not in current_xml_level:\n",
    "                break\n",
    "            current_xml_level = current_xml_level[address[current_index]]\n",
    "            \n",
    "        if address[-1] not in current_xml_level:\n",
    "            continue\n",
    "        else:\n",
    "            if isinstance(current_xml_level[address[-1]],dict):\n",
    "                current_xml_level[address[-1]]= current_xml_level[address[-1]][key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a one off on a poorly handled field in ICE data\n",
    "# usually not repeated, when repeated, just take the first entry in list\n",
    "\n",
    "def derepeat_bad_fields(bad_address_list,xml_dict):\n",
    "    split_bad_address_list = [entry.split('/')[1:] for entry in bad_address_list]\n",
    "    \n",
    "    for address in split_bad_address_list:\n",
    "        current_xml_level = xml_dict\n",
    "        for current_index in range(len(address)-1):\n",
    "            if address[current_index] not in current_xml_level:\n",
    "                break\n",
    "            current_xml_level = current_xml_level[address[current_index]]\n",
    "            \n",
    "        if address[-1] not in current_xml_level:\n",
    "            continue\n",
    "        else:\n",
    "            if isinstance(current_xml_level[address[-1]],list):\n",
    "                current_xml_level[address[-1]]= current_xml_level[address[-1]][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  loading handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp_from_file_name(file_name):\n",
    "    date = re.search('([0-9]{4}[0-9]{2}[0-9]{2}T[0-9]{4}-[0-9]{2})', file_name)[0]\n",
    "    date = date.replace('-','')\n",
    "    return(datetime.strftime(datetime.strptime(date, '%Y%m%dT%H%M%S'),'%Y-%m-%dT%H:%M:%SZ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xmls_list(gz_file_name):\n",
    "    storage_client = storage.Client()\n",
    "    #bucket = storage_client.bucket('ref_data_1')\n",
    "    bucket = storage_client.bucket('ice_init_xml')\n",
    "    blob = bucket.get_blob(gz_file_name) #e.g. 'gsm_update_muni_APFICC_GSMF10I.35.1_1.20201221T0800-05.xml.gz')\n",
    "    file = blob.download_to_filename('/tmp/temp_gz_file.xml.gz')\n",
    "\n",
    "    f = gzip.open('/tmp/temp_gz_file.xml.gz', 'rt')\n",
    "    file_str = f.read()\n",
    "    clean_file = file_str.split('<payload>')[1]\n",
    "    return (clean_file.split('</instrument>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nested_table_uri_json(table_id,uri):\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    ice_nested_table = bqclient.get_table(table_id)\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        schema=ice_nested_table.schema,\n",
    "        source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "    )\n",
    "\n",
    "    bq_client.load_table_from_uri(uri, table_id, job_config=job_config)# Make an API request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_ndjson_as_uri(file_name,xmls,timestamp):\n",
    "    ndjson = ''\n",
    "    total = len(xmls)-1\n",
    "\n",
    "    for n in range(total):\n",
    "        xml_str = xmls[n]+'</instrument>' \n",
    "        instrument_dict = xmltodict.parse(xml_str,attr_prefix='',cdata_key='text')\n",
    "        \n",
    "        # add timestamp to dict, constant for now\n",
    "        instrument_dict['ice_file_date'] = timestamp\n",
    "        \n",
    "        # conform fields with bq schema \n",
    "        derepeat_bad_fields(bad_address_list,instrument_dict)\n",
    "        record_key_flatten(address_key_list,instrument_dict)\n",
    "        repeated_enforcement(all_repeated_nodes,instrument_dict)\n",
    "        \n",
    "        ndjson+= json.dumps(instrument_dict)+'\\n'\n",
    "\n",
    "    json_file_name = '%snest.json' % (file_name) \n",
    "    with open('/tmp/%s' % (json_file_name), 'wb+') as f:\n",
    "        f.write(ndjson.encode())\n",
    "        f.seek(0)\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket('ice_ndjsons')\n",
    "        blob = bucket.blob(json_file_name)\n",
    "        blob.upload_from_filename('/tmp/%s' % (json_file_name))\n",
    "        f.close\n",
    "    uri = 'gs://ice_ndjsons/' + json_file_name\n",
    "    return(uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = event['name']\n",
    "file_name = 'gsm_init_muni_APFICC_GSMF10I.1.1_1.20201222T1700-05.xml.gz'\n",
    "xmls = get_xmls_list(file_name)\n",
    "uri = get_nested_ndjson_as_uri(file_name,xmls,get_timestamp_from_file_name(file_name))  \n",
    "load_nested_table_uri_json('eng-reactor-287421.reference_data.ice_nested',uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#gcloud functions deploy load_ice_data_from_gz_file \\\n",
    "#--runtime python37 \\\n",
    "#--trigger-resource ref_data_1 \\\n",
    "#--trigger-event google.storage.object.finalize\n",
    "import xmltodict\n",
    "import json\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "import collections\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery, storage\n",
    "from datetime import datetime,timedelta\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../creds.json\"\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "\n",
    "def main(event, context):\n",
    "    file_name = event['name']\n",
    "    xmls = get_xmls_list(file_name)\n",
    "    uri = get_ndjson_as_uri(file_name,xmls,get_timestamp_from_file_name(file_name))  \n",
    "    load_table_uri_json('eng-reactor-287421.reference_data.ice',uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading from json rows in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigQuery API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_bigquery(rows_to_insert, table_id):\n",
    "    bq_client = bigquery.Client()\n",
    "    error = bq_client.insert_rows_json(table_id, rows_to_insert)  # Make an API request.\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = '{}.{}.{}'.format(PROJECT,dataset,data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test loading script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "for hundreds in range():\n",
    "    test_a_json = []\n",
    "    for xml_instrument in xml_list[hundreds*100:(hundreds+1)*100]:\n",
    "        xml_str = xml_instrument+'</instrument>' \n",
    "        instrument_dict = xmltodict.parse(xml_str,attr_prefix='',cdata_key='text')\n",
    "        \n",
    "        # add timestamp to dict, constant for now\n",
    "        instrument_dict['ice_file_date'] = '2020-12-22 17:00:05 UTC'\n",
    "        \n",
    "        # conform fields with bq schema \n",
    "        derepeat_bad_fields(bad_address_list,instrument_dict)\n",
    "        record_key_flatten(address_key_list,instrument_dict)\n",
    "        repeated_enforcement(all_repeated_nodes,instrument_dict)\n",
    "        \n",
    "        # dict to json\n",
    "        test_a_json.append(json.loads(json.dumps(instrument_dict)))\n",
    "\n",
    "    error = add_to_bigquery(test_a_json,table_id)\n",
    "    if len(error)>0: \n",
    "        print(error)\n",
    "    else:\n",
    "        print((hundreds+1)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get xml as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_path = 'C:/Users/vcrom/Desktop/ficc/Files/'\n",
    "save_path = '/tmp/'\n",
    "file_name = 'gsm_init_muni_APFICC_GSMF10I.1.1_1.20201222T1700-05.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path+file_name,'r') as f:\n",
    "    #file_str = f.read(100000000)\n",
    "    file_str = f.read()\n",
    "    clean_file = file_str.split('<payload>')[1]\n",
    "    xml_list = clean_file.split('</instrument>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11547"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xml_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('ref_data_1')\n",
    "\n",
    "#save_path = 'C:/Users/vcrom/Desktop/ficc/Files/'\n",
    "save_path = '/tmp/'\n",
    "file_name = 'gsm_init_muni_APFICC_GSMF10I.1.1_1.20201222T1700-05.xml'\n",
    "\n",
    "blob = bucket.blob(file_name)\n",
    "\n",
    "blob.download_to_filename(save_path+file_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
