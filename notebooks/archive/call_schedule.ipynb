{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-ae7adc059e03>:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm_notebook().pandas()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e598369955124d67a8cf5b8519d09653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/FICC.AI/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import bigquery\n",
    "# from google.cloud import bigquery_storage\n",
    "\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "# import table_schema as table_schema\n",
    "import pytz\n",
    "# import qfrm\n",
    "from datetime import datetime,timedelta\n",
    "# from send_email import send_error_email\n",
    "# from google.api_core.exceptions import BadRequest\n",
    "# from google.cloud import secretmanager\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "tqdm_notebook().pandas()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "sns.set()\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import math\n",
    "from pandas import NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../creds.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../gsm_init_muni_APFICC_GSMF10I.1.1_1.20201203T1300-05.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'eng-reactor-287421'\n",
    "dataset = 'FULL_ICE'\n",
    "table = 'call_schedule'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bqclient = bigquery.Client(project=PROJECT,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_table_with_schema(bq,project_id,dataset,table_id,schema = []):\n",
    "    PROJECT = project_id\n",
    "    bq = bq\n",
    "    table_id = '{}.{}.{}'.format(PROJECT,dataset,table_id)\n",
    "    table = bq.create_table(table_id, exists_ok=True)\n",
    "    print('{} created on {}'.format(table.table_id, table.created))\n",
    "    table = bq.get_table(table_id)\n",
    "    table.schema = schema\n",
    "    table = bq.update_table(table, [\"schema\"])\n",
    "\n",
    "def load_data(bq,data,project,dataset,table):\n",
    "    bq = bq\n",
    "    table_id = '{}.{}.{}'.format(project,dataset,table)\n",
    "    job_config = bigquery.LoadJobConfig(schema =[])\n",
    "    job = bq.load_table_from_dataframe(data, table_id,job_config=job_config)\n",
    "\n",
    "    try:\n",
    "        job.result() # Waits for the job to complete.\n",
    "        return 'success'  \n",
    "    except BadRequest as ex:\n",
    "        print(ex) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_schedule created on 2020-12-14 17:29:28.395000+00:00\n"
     ]
    }
   ],
   "source": [
    "create_table_with_schema(bqclient,PROJECT,dataset,table,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(bqclient,doc_df,PROJECT,dataset,table,count):\n",
    "    try:\n",
    "        test = load_data(bqclient,doc_df,PROJECT,dataset,table)\n",
    "        print(test)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        for columns in doc_df.columns:\n",
    "            print(columns)\n",
    "        print(doc_df.head)\n",
    "        print(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_schedule(new_elem,final_list):\n",
    "    \n",
    "    list_of_elem = new_elem.xpath(\"//instrument/debt/call_details\")\n",
    "    instrument_id = new_elem.xpath(\"//instrument\")[0].attrib[\"id\"]\n",
    "    if len(list_of_elem)>0:\n",
    "        for element in list_of_elem[0].getchildren():\n",
    "            if element.tag == \"call_schedule\":\n",
    "                new_dict = {}\n",
    "                new_dict.update({\"instrument_id\":instrument_id})\n",
    "#                 print(\"inside call schedule\")\n",
    "#                 print(len(element.getchildren()))\n",
    "#                 new_dict.update({element.tag:element.text})\n",
    "                for childs in element.getchildren():\n",
    "#                     print(\"inside childs\")\n",
    "#                     print(childs.text)\n",
    "#                     print(childs.text)\n",
    "                    \n",
    "                    new_dict.update({childs.tag:childs.text})\n",
    "                    \n",
    "                final_list.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_call_schedule(new_elem,final_list):\n",
    "#     new_dict = {}\n",
    "    \n",
    "    call_schedule(new_elem,final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataframe(final_list,count,data_timestamp):\n",
    "    doc_df = pd.DataFrame(final_list)\n",
    "    #             print(doc_df)\n",
    "    new_columns = []\n",
    "    for columns in doc_df.columns:\n",
    "        columns = columns.replace(\"&\",\"\")\n",
    "        columns = columns.replace(\" \",\"_\")\n",
    "        columns = columns.replace(\"-\",\"_\")\n",
    "        new_columns.append(columns)\n",
    "    doc_df.columns = new_columns\n",
    "    doc_df[\"upload_date\"] = my_timezone.localize(datetime.now()).date() \n",
    "    doc_df[\"data_timestamp\"] = pd.to_datetime(data_timestamp[0])\n",
    "    doc_df[\"data_timestamp\"] = doc_df[\"data_timestamp\"].dt.date\n",
    "    doc_df.replace(np.nan,None,inplace = True)\n",
    "    doc_df.replace([np.nan],[None],inplace = True)\n",
    "    doc_df.replace(\"nan\",None,inplace = True)\n",
    "    print(len(doc_df))\n",
    "\n",
    "    #             doc_df.to_pickle(storage_path+\"_\"+str(count)+\".pkl\")\n",
    "    load_dataframe(bqclient,doc_df,PROJECT,dataset,table,count)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "my_timezone = pytz.timezone('America/New_York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "218764\n",
      "success\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "233143\n",
      "success\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "229688\n",
      "success\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "215814\n",
      "success\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "212731\n",
      "success\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "220773\n",
      "success\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "217237\n",
      "success\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "245414\n",
      "success\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "224747\n",
      "success\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "212278\n",
      "success\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "223438\n",
      "success\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "231985\n",
      "success\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "226336\n",
      "success\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "211218\n",
      "success\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "217575\n",
      "success\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "226504\n",
      "success\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "226586\n",
      "success\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "221985\n",
      "success\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "215271\n",
      "success\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "220468\n",
      "success\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "233988\n",
      "success\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "226419\n",
      "success\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "211064\n",
      "success\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "220912\n",
      "success\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "222953\n",
      "success\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "232789\n",
      "success\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "222790\n",
      "success\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "213561\n",
      "success\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "216920\n",
      "success\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "229916\n",
      "success\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "229258\n",
      "success\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "215343\n",
      "success\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "222540\n",
      "success\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "212752\n",
      "success\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "234530\n",
      "success\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "221165\n",
      "success\n",
      "46418\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "# count = 0\n",
    "total = 1086089\n",
    "columns_list = []\n",
    "data_timestamp = []\n",
    "head_context = etree.iterparse(path,events=(\"start\",),tag = \"header\")\n",
    "for event,elem in head_context:\n",
    "    new_elem = etree.parse(BytesIO(etree.tostring(elem)))\n",
    "    list_of_elem = elem.xpath(\"//header\")\n",
    "    if len(list_of_elem)>0:\n",
    "        for element in list_of_elem[0].getchildren():\n",
    "#             print(element.tag)\n",
    "            if element.tag == \"timestamp\":\n",
    "                print(\"hello\")\n",
    "                data_timestamp.append(element.text)\n",
    "    break\n",
    "\n",
    "\n",
    "def new_fast_iter(context,data_timestamp, *args, **kwargs):\n",
    "  \n",
    "    processes = []\n",
    "    final_list = []\n",
    "    count = 0\n",
    "    jobs = []\n",
    "    for event,elem in context:\n",
    "        new_elem = etree.parse(BytesIO(etree.tostring(elem)))\n",
    "        create_df_call_schedule(new_elem,final_list)\n",
    "        \n",
    "        count += 1\n",
    "    #         elem.clear()\n",
    "    #         elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "#         if count == 10:\n",
    "#             break\n",
    "#         print(\"******\")\n",
    "\n",
    "        if count%10000 == 0:\n",
    "    #             print(elem.attrib)\n",
    "            print(count)\n",
    "        if count %30000== 0:\n",
    "            upload_dataframe(final_list,count,data_timestamp)\n",
    "#             thread = threading.Thread(target = threaded_stuff(final_list))\n",
    "\n",
    "            final_list = []\n",
    "\n",
    "\n",
    "        if count == total:\n",
    "            upload_dataframe(final_list,count,data_timestamp)\n",
    "#             thread = threading.Thread(target = threaded_stuff(final_list))\n",
    "\n",
    "            final_list = []\n",
    "            \n",
    "\n",
    "# def process_element(elem,final_list):\n",
    "# #     new_elem = elem\n",
    "    \n",
    "#     new_elem = etree.parse(BytesIO(etree.tostring(elem)))\n",
    "# #     print(etree.tostring(elem, pretty_print=True))\n",
    "# #     print(etree.dump(new_elem))\n",
    "#     create_df_call_schedule(new_elem,final_list)\n",
    "\n",
    "\n",
    "\n",
    "context = etree.iterparse(path,events=(\"start\",),tag = \"instrument\")\n",
    "new_fast_iter(context,data_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
