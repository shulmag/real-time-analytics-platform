{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4494ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Calc_date_and_price notebook 3.15.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f500d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"../creds.json\"\n",
    "bqclient = bigquery.Client()\n",
    "\n",
    "project = \"eng-reactor-287421\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be40f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88f5dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    " NUM_OF_DAYS_IN_YEAR = 360\n",
    "\n",
    "COUPON_FREQUENCY_DICT = {0:\"Unknown\",\n",
    "                        1:\"Semiannually\",\n",
    "                        2:\"Monthly\",\n",
    "                        3:\"Annually\",\n",
    "                        4:\"Weekly\",\n",
    "                        5:\"Quarterly\",\n",
    "                        6:\"Every 2 years\",\n",
    "                        7:\"Every 3 years\",\n",
    "                        8:\"Every 4 years\",\n",
    "                        9:\"Every 5 years\",\n",
    "                        10:\"Every 7 years\",\n",
    "                        11:\"Every 8 years\",\n",
    "                        12:\"Biweekly\",\n",
    "                        13:\"Changeable\",\n",
    "                        14:\"Daily\",\n",
    "                        15:\"Term mode\",\n",
    "                        16:\"Interest at maturity\",\n",
    "                        17:\"Bimonthly\",\n",
    "                        18:\"Every 13 weeks\",\n",
    "                        19:\"Irregular\",\n",
    "                        20:\"Every 28 days\",\n",
    "                        21:\"Every 35 days\",\n",
    "                        22:\"Every 26 weeks\",\n",
    "                        23:\"Not Applicable\",\n",
    "                        24:\"Tied to prime\",\n",
    "                        25:\"One time\",\n",
    "                        26:\"Every 10 years\",\n",
    "                        27:\"Frequency to be determined\",\n",
    "                        28:\"Mandatory put\",\n",
    "                        29:\"Every 52 weeks\",\n",
    "                        30:\"When interest adjusts-commercial paper\",\n",
    "                        31:\"Zero coupon\",\n",
    "                        32:\"Certain years only\",\n",
    "                        33:\"Under certain circumstances\",\n",
    "                        34:\"Every 15 years\",\n",
    "                        35:\"Custom\",\n",
    "                        36:\"Single Interest Payment\"}\n",
    "\n",
    "LARGE_NUMBER = 1e6\n",
    "\n",
    "COUPON_FREQUENCY_TYPE = {\"Unknown\":LARGE_NUMBER,\n",
    "                         \"Semiannually\":2,\n",
    "                         \"Monthly\":12,\n",
    "                         \"Annually\":1,\n",
    "                         \"Weekly\":52,\n",
    "                         \"Quarterly\":4,\n",
    "                         \"Every 2 years\":0.5,\n",
    "                         \"Every 3 years\":1/3,\n",
    "                         \"Every 4 years\":0.25,\n",
    "                         \"Every 5 years\":0.2,\n",
    "                         \"Every 7 years\":1/7,\n",
    "                         \"Every 8 years\":1/8,\n",
    "                         \"Biweekly\": 26,\n",
    "                         \"Changeable\":44,\n",
    "                         \"Daily\":360,\n",
    "                         \"Interest at maturity\":0,\n",
    "                         \"Not Applicable\":LARGE_NUMBER}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105c1810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OF_DAYS_IN_YEAR = 360\n",
    "\n",
    "'''\n",
    "This function compares two date objects whether they are in Timestamp or datetime.date. \n",
    "The different types are causing a future warning. If date1 occurs after date2, return 1. \n",
    "If date1 equals date2, return 0. Otherwise, return -1.\n",
    "'''\n",
    "def compare_dates(date1, date2):\n",
    "    if type(date1) == pd.Timestamp:\n",
    "        date1 = date1.date()\n",
    "    if type(date2) == pd.Timestamp:\n",
    "        date2 = date2.date()\n",
    "    \n",
    "    if date1 > date2:\n",
    "        return 1\n",
    "    elif date1 == date2:\n",
    "        return 0\n",
    "    elif date1 < date2:\n",
    "        return -1\n",
    "\n",
    "'''\n",
    " # @ Create Time: 2021-12-20 10:00:17\n",
    " # @ Modified by: Developer\n",
    " # @ Modified time: 2022-01-20 09:33:30\n",
    " # @ Description: This file implements a function to calculate the difference in \n",
    " # days between two days in accordance to the provision of MSRB rule 33G\n",
    " '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "This function calculates the difference in days using the 360/30 \n",
    "convention specified in MSRB Rule Book G-33, rule (e). \n",
    "Note that we only handle the 360/30 convention for date calculations.\n",
    "'''\n",
    "def diff_in_days_two_dates(end_date, start_date, convention=\"360/30\"):\n",
    "    if convention != \"360/30\":\n",
    "        print(\"unknown convention\", convention)\n",
    "        return None\n",
    "\n",
    "    Y2 = end_date.year\n",
    "    Y1 = start_date.year\n",
    "    M2 = end_date.month\n",
    "    M1 = start_date.month\n",
    "    D2 = end_date.day\n",
    "    D1 = start_date.day\n",
    "    D1 = min(D1, 30)\n",
    "    if D1 == 30: \n",
    "        D2 = min(D2, 30)\n",
    "    return (Y2 - Y1) * 360 + (M2 - M1) * 30 + (D2 - D1)\n",
    "\n",
    "def diff_in_days(trade, convention=\"360/30\", **kwargs):\n",
    "    #See MSRB Rule 33-G for details\n",
    "    if 'calc_type' in kwargs:\n",
    "        if kwargs['calc_type'] == 'accrual' and not pd.isnull(trade.accrual_date):\n",
    "            start_date = trade.accrual_date\n",
    "            end_date = trade.settlement_date\n",
    "        else:\n",
    "            raise ValueError('Invalid arguments')\n",
    "    else:\n",
    "        start_date = trade.dated_date\n",
    "        end_date = trade.settlement_date\n",
    "\n",
    "    return diff_in_days_two_dates(end_date, start_date, convention)\n",
    "\n",
    "'''\n",
    " # @ Create Time: 2022-01-13 18:02:00\n",
    " # @ Description: This file implements functions for truncating final outputs.\n",
    " '''\n",
    "\n",
    "'''\n",
    "This file truncations an input to a specified number of decimal\n",
    "places. See the doctests.\n",
    "'''\n",
    "def trunc(x, decimal_places):\n",
    "    \"\"\"\n",
    "    >>> trunc(3.33333, 3)\n",
    "    3.333\n",
    "    >>> trunc(3.99499, 3)\n",
    "    3.994\n",
    "    >>> trunc(30.99499, 3)\n",
    "    30.994\n",
    "    \"\"\"\n",
    "    ten_places = 10 ** decimal_places\n",
    "    return ((x * ten_places) // 1) / ten_places\n",
    "\n",
    "'''\n",
    "This function rounds the final price according to \n",
    "MSRB Rule Book G-33, rule (d).\n",
    "'''\n",
    "def trunc_and_round_price(price):\n",
    "    return trunc(price, 3)\n",
    "\n",
    "'''\n",
    "This function rounds the final yield according to \n",
    "MSRB Rule Book G-33, rule (d).\n",
    "'''\n",
    "def trunc_and_round_yield(yield_rate):\n",
    "    return round(trunc(yield_rate, 4), 3)\n",
    "\n",
    "'''\n",
    " # @ Author: Developer \n",
    " # @ Create Time: 2021-12-15 13:59:54\n",
    " # @ Modified by: Developer\n",
    " # @ Modified time: 2022-02-10 10:49:09\n",
    " # @ Description: This file contains function to help the functions \n",
    " # to process training data\n",
    " '''\n",
    "import pandas as pd\n",
    "\n",
    "def sqltodf(sql, bq_client):\n",
    "    bqr = bq_client.query(sql).result()\n",
    "    return bqr.to_dataframe()\n",
    "\n",
    "\n",
    "def drop_extra_columns(df):\n",
    "    df.drop(columns=[\n",
    "                 'sp_stand_alone',\n",
    "                 'sp_icr_school',\n",
    "                 'sp_icr_school',\n",
    "                 'sp_icr_school',\n",
    "                 'sp_watch_long',\n",
    "                 'sp_outlook_long',\n",
    "                 'sp_prelim_long',\n",
    "                 'MSRB_maturity_date',\n",
    "                 'MSRB_INST_ORDR_DESC',\n",
    "                 'MSRB_valid_from_date',\n",
    "                 'MSRB_valid_to_date',\n",
    "                 'upload_date',\n",
    "                 'sequence_number',\n",
    "                 'ref_valid_from_date',\n",
    "                 'ref_valid_to_date',\n",
    "                 'additional_next_sink_date',\n",
    "                 'last_period_accrues_from_date',\n",
    "                 'primary_market_settlement_date',\n",
    "                 'assumed_settlement_date',\n",
    "                 'sale_date','q','d'],\n",
    "                  inplace=True)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_dates(df):\n",
    "    date_cols = [col for col in list(df.columns) if 'DATE' in col.upper()]\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "'''\n",
    "This function  \n",
    "'''\n",
    "def process_ratings(df):\n",
    "    df = df[df.sp_long.isin(['BBB+','A-','A','A+','AA-','AA','AA+','AAA','NR'])] \n",
    "    df['rating'] = df['sp_long']\n",
    "    return df\n",
    "    \n",
    "'''\n",
    "This function extracts the features of the latest trade from \n",
    "the trade history array\n",
    "'''\n",
    "def get_latest_trade_feature(x, feature):\n",
    "    recent_trade = x[0]\n",
    "    if feature == 'yield_spread':\n",
    "        return recent_trade[0]\n",
    "    elif feature == 'seconds_ago':\n",
    "        return recent_trade[-1]\n",
    "    elif feature == 'par_traded':\n",
    "        return recent_trade[1]\n",
    "\n",
    "'''\n",
    "This function compares two date objects whether they are in Timestamp or datetime.date. \n",
    "The different types are causing a future warning. If date1 occurs after date2, return 1. \n",
    "If date1 equals date2, return 0. Otherwise, return -1.\n",
    "'''\n",
    "def compare_dates(date1, date2):\n",
    "    if type(date1) == pd.Timestamp:\n",
    "        date1 = date1.date()\n",
    "    if type(date2) == pd.Timestamp:\n",
    "        date2 = date2.date()\n",
    "    \n",
    "    if date1 > date2:\n",
    "        return 1\n",
    "    elif date1 == date2:\n",
    "        return 0\n",
    "    elif date1 < date2:\n",
    "        return -1\n",
    "\n",
    "'''\n",
    "This function directly calls `compare_dates` to check if two dates are equal.\n",
    "'''\n",
    "def dates_are_equal(date1, date2):\n",
    "    return compare_dates(date1, date2) == 0\n",
    "\n",
    "'''\n",
    "This function converts the columns with object datatypes to category data types\n",
    "'''\n",
    "def convert_object_to_category(df):\n",
    "    print(\"Converting object data type to categorical data type\")\n",
    "    for col_name in df.columns:\n",
    "        if col_name.endswith(\"event\") or col_name.endswith(\"redemption\") or col_name.endswith(\"history\") or col_name.endswith(\"date\"):\n",
    "            continue\n",
    "\n",
    "        if df[col_name].dtype == \"object\" and col_name not in ['organization_primary_name','security_description','recent','issue_text','series_name']:\n",
    "            df[col_name] = df[col_name].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "'''\n",
    " # @ Create Time: 2022-01-13 17:58:00\n",
    " # @ Modified by: Developer\n",
    " # @ Modified time: 2022-01-24 12:19:00\n",
    " # @ Description: This file implements functions for bonds that have been called.\n",
    " '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "This function provides the end date for a called bond. \n",
    "'''\n",
    "def end_date_for_called_bond(trade):\n",
    "    if not pd.isnull(trade.refund_date):\n",
    "        return trade.refund_date\n",
    "    else:\n",
    "        raise ValueError(f\"Bond (CUSIP: {trade.cusip}, RTRS: {trade.rtrs_control_number}) is called, but no refund date.\")\n",
    "\n",
    "'''\n",
    "This function provides the par value for a called bond.\n",
    "'''\n",
    "def refund_price_for_called_bond(trade):\n",
    "    if not pd.isnull(trade.refund_price):\n",
    "        return trade.refund_price\n",
    "    else:\n",
    "        raise ValueError(f\"Bond (CUSIP: {trade.cusip}, RTRS: {trade.rtrs_control_number}) is called, but no refund price.\")\n",
    "\n",
    "'''\n",
    " # @ Create Time: 2022-01-13 23:04:00\n",
    " # @ Modified by: Developer\n",
    " # @ Modified time: 2022-02-25 14:04:00\n",
    " # @ Description: This file implements functions to compute the price of a trade\n",
    " # given the yield.\n",
    " '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46757167",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " # @ Author: Developer \n",
    " # @ Create Time: 2021-12-15 13:59:54\n",
    " # @ Modified by: Developer\n",
    " # @ Modified time: 2022-02-10 10:49:09\n",
    " # @ Description: This file contains function to help the functions \n",
    " # to process training data\n",
    " '''\n",
    "import pandas as pd\n",
    "\n",
    "def sqltodf(sql, bq_client):\n",
    "    bqr = bq_client.query(sql).result()\n",
    "    return bqr.to_dataframe()\n",
    "\n",
    "\n",
    "def drop_extra_columns(df):\n",
    "    df.drop(columns=[\n",
    "                 'sp_stand_alone',\n",
    "                 'sp_icr_school',\n",
    "                 'sp_icr_school',\n",
    "                 'sp_icr_school',\n",
    "                 'sp_watch_long',\n",
    "                 'sp_outlook_long',\n",
    "                 'sp_prelim_long',\n",
    "                 'MSRB_maturity_date',\n",
    "                 'MSRB_INST_ORDR_DESC',\n",
    "                 'MSRB_valid_from_date',\n",
    "                 'MSRB_valid_to_date',\n",
    "                 'upload_date',\n",
    "                 'sequence_number',\n",
    "                 'ref_valid_from_date',\n",
    "                 'ref_valid_to_date',\n",
    "                 'additional_next_sink_date',\n",
    "                 'last_period_accrues_from_date',\n",
    "                 'primary_market_settlement_date',\n",
    "                 'assumed_settlement_date',\n",
    "                 'sale_date','q','d'],\n",
    "                  inplace=True)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_dates(df):\n",
    "    date_cols = [col for col in list(df.columns) if 'DATE' in col.upper()]\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "'''\n",
    "This function  \n",
    "'''\n",
    "def process_ratings(df):\n",
    "    df = df[df.sp_long.isin(['BBB+','A-','A','A+','AA-','AA','AA+','AAA','NR'])] \n",
    "    df['rating'] = df['sp_long']\n",
    "    return df\n",
    "    \n",
    "'''\n",
    "This function extracts the features of the latest trade from \n",
    "the trade history array\n",
    "'''\n",
    "def get_latest_trade_feature(x, feature):\n",
    "    recent_trade = x[0]\n",
    "    if feature == 'yield_spread':\n",
    "        return recent_trade[0]\n",
    "    elif feature == 'seconds_ago':\n",
    "        return recent_trade[-1]\n",
    "    elif feature == 'par_traded':\n",
    "        return recent_trade[1]\n",
    "\n",
    "'''\n",
    "This function compares two date objects whether they are in Timestamp or datetime.date. \n",
    "The different types are causing a future warning. If date1 occurs after date2, return 1. \n",
    "If date1 equals date2, return 0. Otherwise, return -1.\n",
    "'''\n",
    "def compare_dates(date1, date2):\n",
    "    if type(date1) == pd.Timestamp:\n",
    "        date1 = date1.date()\n",
    "    if type(date2) == pd.Timestamp:\n",
    "        date2 = date2.date()\n",
    "    \n",
    "    if date1 > date2:\n",
    "        return 1\n",
    "    elif date1 == date2:\n",
    "        return 0\n",
    "    elif date1 < date2:\n",
    "        return -1\n",
    "\n",
    "'''\n",
    "This function directly calls `compare_dates` to check if two dates are equal.\n",
    "'''\n",
    "def dates_are_equal(date1, date2):\n",
    "    return compare_dates(date1, date2) == 0\n",
    "\n",
    "'''\n",
    "This function converts the columns with object datatypes to category data types\n",
    "'''\n",
    "def convert_object_to_category(df):\n",
    "    print(\"Converting object data type to categorical data type\")\n",
    "    for col_name in df.columns:\n",
    "        if col_name.endswith(\"event\") or col_name.endswith(\"redemption\") or col_name.endswith(\"history\") or col_name.endswith(\"date\"):\n",
    "            continue\n",
    "\n",
    "        if df[col_name].dtype == \"object\" and col_name not in ['organization_primary_name','security_description','recent','issue_text','series_name']:\n",
    "            df[col_name] = df[col_name].astype(\"category\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8481fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " # @ Create Time: 2022-01-13 17:54:00\n",
    " # @ Description: This file implements functions to handle interest payment\n",
    " # frequency information of a bond.\n",
    " '''\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "This function returns the frequency of coupon payments based on \n",
    "the interest payment frequency identifier in the bond reference data.\n",
    "'''\n",
    "def get_frequency(identifier):\n",
    "    # check whether the frequency dict has already been applied to the identifier\n",
    "    if type(identifier) == str:\n",
    "        return COUPON_FREQUENCY_TYPE[identifier]\n",
    "    else:\n",
    "        return COUPON_FREQUENCY_TYPE[COUPON_FREQUENCY_DICT[identifier]]\n",
    "\n",
    "'''\n",
    "This function returns a time delta object based on the interest payment frequency. \n",
    "The first step is to identify whether the interest payment frequency passed in \n",
    "is in terms of the number of months in a year or the number of weeks in a year. \n",
    "Then, based on this the time delta object is returned.\n",
    "'''\n",
    "def get_time_delta_from_interest_frequency(interest_payment_frequency):\n",
    "    error_string = lambda num: f\"The interest payment frequency of {interest_payment_frequency} is invalid, since it must divide {num}\"\n",
    "\n",
    "    NUM_OF_MONTHS_IN_YEAR = 12\n",
    "    NUM_OF_WEEKS_IN_YEAR = 52\n",
    "    NUM_OF_DAYS_IN_YEAR = 360\n",
    "\n",
    "    time_delta = 0\n",
    "    if interest_payment_frequency != 0:\n",
    "        if interest_payment_frequency <= 1:\n",
    "            delta = 1 / interest_payment_frequency\n",
    "            time_delta = relativedelta(years=delta)\n",
    "        elif interest_payment_frequency > 1 and interest_payment_frequency <= NUM_OF_MONTHS_IN_YEAR:\n",
    "            if NUM_OF_MONTHS_IN_YEAR % interest_payment_frequency != 0:\n",
    "                raise ValueError(error_string(NUM_OF_MONTHS_IN_YEAR))\n",
    "            delta = NUM_OF_MONTHS_IN_YEAR / interest_payment_frequency\n",
    "            time_delta = relativedelta(months=delta)\n",
    "        elif interest_payment_frequency > NUM_OF_MONTHS_IN_YEAR and interest_payment_frequency <= NUM_OF_WEEKS_IN_YEAR:\n",
    "            if NUM_OF_WEEKS_IN_YEAR % interest_payment_frequency != 0:\n",
    "                raise ValueError(error_string(NUM_OF_WEEKS_IN_YEAR))\n",
    "            delta = NUM_OF_WEEKS_IN_YEAR / interest_payment_frequency\n",
    "            time_delta = relativedelta(weeks=delta)\n",
    "        elif interest_payment_frequency > NUM_OF_WEEKS_IN_YEAR and interest_payment_frequency <= NUM_OF_DAYS_IN_YEAR:\n",
    "            if NUM_OF_DAYS_IN_YEAR % interest_payment_frequency != 0:\n",
    "                raise ValueError(error_string(NUM_OF_DAYS_IN_YEAR))\n",
    "            delta = NUM_OF_DAYS_IN_YEAR / interest_payment_frequency\n",
    "            time_delta = relativedelta(days=delta)\n",
    "    return time_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92eca373",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " # @ Create Time: 2022-01-13 17:44:00\n",
    " # @ Description: This file implements functions to help with pricing bonds\n",
    " # and computing yields.\n",
    " '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "This function takes the dataframe from the bigquery and updates certain \n",
    "fields to be the right type. Note that this function mutates the fields \n",
    "passed in dataframe, so the function itself has no return value.\n",
    "'''\n",
    "def transform_reference_data(df):\n",
    "    df['interest_payment_frequency'] = df.apply(lambda trade: get_frequency(trade[\"interest_payment_frequency\"]), axis=1)\n",
    "    df['coupon'] = df['coupon'].astype(float)\n",
    "    df['yield'] = df['yield'].astype(float)\n",
    "    df['deferred'] = (df.interest_payment_frequency == 0) | df.coupon == 0\n",
    "    \n",
    "    df['next_call_price'] = df['next_call_price'].astype(float)\n",
    "    return df\n",
    "\n",
    "'''\n",
    "This function computes the next time a coupon is paid.\n",
    "Note that this function could return a `next_coupon_date` that is after the end_date. \n",
    "This does not create a problem since we deal with the final coupon separately in \n",
    "`price_of_bond_with_multiple_periodic_interest_payments`.\n",
    "Note that it may be that this function is not necessary because the field \n",
    "`next_coupon_date` is never null when there is a \"next coupon date.\" In the \n",
    "future, we should confirm whether this is the case.\n",
    "'''\n",
    "def get_next_coupon_date(first_coupon_date, start_date, time_delta):\n",
    "    date = first_coupon_date\n",
    "    while compare_dates(date, start_date) < 0:\n",
    "        date = date + time_delta\n",
    "    return date\n",
    "#     cannot use the below code since division is not valid between datetime.timedelta and relativedelta, and converting between types introduces potential for errors\n",
    "#     num_of_time_periods = int(np.ceil((start_date - first_coupon_date) / time_delta))    # `int` wraps the `ceil` function because the `ceil` function returns a float\n",
    "#     return first_coupon_date + time_delta * num_of_time_periods\n",
    "\n",
    "'''\n",
    "This function computes the previous time a coupon was paid for this bond \n",
    "by relating it to the next coupon date.\n",
    "Note that it may be that this function is not necessary because the field \n",
    "`previous_coupon_date` is never null when `next_coupon_date` exists. In the \n",
    "future, we should confirm whether this is the case.\n",
    "'''\n",
    "def get_previous_coupon_date(first_coupon_date, start_date, accrual_date, time_delta, next_coupon_date=None):\n",
    "    if next_coupon_date == None:\n",
    "        next_coupon_date = get_next_coupon_date(first_coupon_date, start_date, time_delta)   \n",
    "    if dates_are_equal(next_coupon_date, first_coupon_date):\n",
    "        return accrual_date\n",
    "    return next_coupon_date - time_delta\n",
    "\n",
    "'''\n",
    "This function is valid for bonds that don't pay coupons, whereas the previous \n",
    "two functions assume the bond pays coupons.\n",
    "Note: the field of `next_coupon_payment_date` corresponds to our variable of \n",
    "`next_coupon_date` (removing the word `payment`) for more concise and readable \n",
    "code, and similarly with `previous_coupon_date`\n",
    "'''\n",
    "def get_prev_coupon_date_and_next_coupon_date(trade, frequency, time_delta):\n",
    "    if frequency == 0:\n",
    "        next_coupon_date = trade.maturity_date\n",
    "        prev_coupon_date = trade.accrual_date\n",
    "    else:\n",
    "        if pd.isnull(trade.next_coupon_payment_date):\n",
    "            if pd.isnull(trade.first_coupon_date):\n",
    "                print(f'no coupon date for {trade.rtrs_control_number, trade.cusip}')\n",
    "                return None, None\n",
    "            else: \n",
    "                next_coupon_date = get_next_coupon_date(trade.first_coupon_date, trade.settlement_date, time_delta)\n",
    "        else:\n",
    "            next_coupon_date = pd.to_datetime(trade.next_coupon_payment_date)\n",
    "\n",
    "        if pd.isnull(trade.previous_coupon_payment_date):\n",
    "            prev_coupon_date = get_previous_coupon_date(trade.first_coupon_date, trade.settlement_date, trade.accrual_date, time_delta, next_coupon_date)\n",
    "        else:\n",
    "            prev_coupon_date = pd.to_datetime(trade.previous_coupon_payment_date)\n",
    "\n",
    "    return prev_coupon_date, next_coupon_date\n",
    "\n",
    "'''\n",
    "This function returns the number of interest payments and the final coupon \n",
    "date based on the next coupon date, the end date, and the gap between coupon \n",
    "payments. This function returns both together because one is always a \n",
    "byproduct of computing the other.\n",
    "Note that the special case of an odd final coupon is handled below in \n",
    "`price_of_bond_with_multiple_periodic_interest_payments`.\n",
    "'''\n",
    "def get_num_of_interest_payments_and_final_coupon_date(next_coupon_date, end_date, time_delta): \n",
    "    if compare_dates(next_coupon_date, end_date) > 0:\n",
    "        return 0, next_coupon_date    # return 1, end_date (would be valid in isolation)\n",
    "    \n",
    "    num_of_interest_payments = 1\n",
    "    final_coupon_date = next_coupon_date\n",
    "    while compare_dates(final_coupon_date + time_delta, end_date) <= 0:\n",
    "        num_of_interest_payments += 1\n",
    "        final_coupon_date += time_delta\n",
    "    return num_of_interest_payments, final_coupon_date\n",
    "\n",
    "'''\n",
    "This function is called when the interest is only paid at maturity (which is represented \n",
    "in the transformed dataframe as interest payment frequency equaling 0). There are two \n",
    "cases when interest is paid at maturity. The first case is for short term bonds where \n",
    "there is a single coupon payment at maturity, and this logic will reduce to the logic \n",
    "in MSRB Rule Book G-33, rule (b)(i)(A). The second case is when when there is a compounding \n",
    "accreted value (i.e., capital appreciation bonds) which accrues semianually. Then, to get \n",
    "the price of this bond, we need to account for the accrued interest. This can be thought \n",
    "of as a bond that pays a coupon semiannually through the duration of the bond, but all the \n",
    "coupon payments are made as a single payment at the time the bond is called / maturity. \n",
    "For more info and an example, see the link: \n",
    "https://www.investopedia.com/terms/c/cav.asp#:~:text=Compound%20accreted%20value%20(CAV)%20is,useful%20metric%20for%20bond%20investors.\n",
    "'''\n",
    "def price_of_bond_with_interest_at_maturity(cusip,    # can be used for debugging purposes\n",
    "                                            settlement_date, \n",
    "                                            accrual_date, \n",
    "                                            end_date, \n",
    "                                            yield_rate, \n",
    "                                            coupon, \n",
    "                                            RV):\n",
    "    NOMINAL_FREQUENCY = 2    # semiannual interest payment frequency\n",
    "    accrual_date_to_settlement_date = diff_in_days_two_dates(settlement_date, accrual_date)\n",
    "    settlement_date_to_end_date = diff_in_days_two_dates(end_date, settlement_date)\n",
    "    accrued = coupon * accrual_date_to_settlement_date / NUM_OF_DAYS_IN_YEAR\n",
    "    num_of_periods_from_settlement_date_to_end_date = settlement_date_to_end_date / (NUM_OF_DAYS_IN_YEAR / NOMINAL_FREQUENCY)\n",
    "    denom = (1 + yield_rate / NOMINAL_FREQUENCY) ** num_of_periods_from_settlement_date_to_end_date\n",
    "    accrual_date_to_end_date = diff_in_days_two_dates(end_date, accrual_date)\n",
    "    base = (RV + coupon * accrual_date_to_end_date / NUM_OF_DAYS_IN_YEAR) / denom\n",
    "    return base - accrued\n",
    "\n",
    "'''\n",
    "This function computes the price of a bond with multiple periodic interest \n",
    "payments using MSRB Rule Book G-33, rule (b)(i)(B)(2). Comments with capital \n",
    "letter symbols represent those same symbols seen in formula in MSRB rule book.\n",
    "'''\n",
    "def price_of_bond_with_multiple_periodic_interest_payments(cusip,    # can be used for debugging purposes\n",
    "                                                           settlement_date, \n",
    "                                                           accrual_date,\n",
    "                                                           first_coupon_date, \n",
    "                                                           prev_coupon_date, \n",
    "                                                           next_coupon_date,    \n",
    "                                                           final_coupon_date, \n",
    "                                                           end_date, \n",
    "                                                           frequency,\n",
    "                                                           num_of_interest_payments, \n",
    "                                                           yield_rate,\n",
    "                                                           coupon, \n",
    "                                                           RV, \n",
    "                                                           time_delta, \n",
    "                                                           last_period_accrues_from_date):\n",
    "    num_of_days_in_period = NUM_OF_DAYS_IN_YEAR / frequency\n",
    "    discount_rate = 1 + yield_rate / frequency    # 1 + Y / M\n",
    "    final_coupon_date_to_end_date = diff_in_days_two_dates(end_date, final_coupon_date)\n",
    "    prev_coupon_date_to_settlement_date = diff_in_days_two_dates(settlement_date, prev_coupon_date)    # A\n",
    "    interest_due_at_end_date = coupon * final_coupon_date_to_end_date / NUM_OF_DAYS_IN_YEAR\n",
    "    \n",
    "    RV_and_interest_due_at_end_date = RV + interest_due_at_end_date\n",
    "    settlement_date_to_next_coupon_date = diff_in_days_two_dates(next_coupon_date, settlement_date)    # E - A\n",
    "    settlement_date_to_next_coupon_date_frac = settlement_date_to_next_coupon_date / num_of_days_in_period    # (E - A) / E\n",
    "    final_coupon_date_to_end_date_frac = final_coupon_date_to_end_date / num_of_days_in_period\n",
    "    num_of_periods_from_settlement_date_to_end_date = num_of_interest_payments - 1 + settlement_date_to_next_coupon_date_frac + final_coupon_date_to_end_date_frac\n",
    "    \n",
    "    RV_and_interest_due_at_end_date_discounted = RV_and_interest_due_at_end_date / (discount_rate ** num_of_periods_from_settlement_date_to_end_date)\n",
    "    \n",
    "    # The following logic statements are necessary to address odd first and final coupons\n",
    "    if dates_are_equal(next_coupon_date, first_coupon_date):\n",
    "        num_of_days_in_current_interest_payment_period = diff_in_days_two_dates(first_coupon_date, accrual_date)\n",
    "    elif not pd.isna(last_period_accrues_from_date) and compare_dates(settlement_date, last_period_accrues_from_date + time_delta) > 0:    # this logic has not been tested\n",
    "        num_of_days_in_current_interest_payment_period = 0\n",
    "    else:\n",
    "        num_of_days_in_current_interest_payment_period = num_of_days_in_period\n",
    "\n",
    "    coupon_payments_discounted_total = (coupon * num_of_days_in_current_interest_payment_period / NUM_OF_DAYS_IN_YEAR) / \\\n",
    "                                       (discount_rate ** settlement_date_to_next_coupon_date_frac)\n",
    "    coupon_payment = coupon / frequency\n",
    "    for k in range(1, num_of_interest_payments):\n",
    "        coupon_payment_discounted = coupon_payment / (discount_rate ** (settlement_date_to_next_coupon_date_frac + k))\n",
    "        coupon_payments_discounted_total += coupon_payment_discounted\n",
    "        \n",
    "    accrued = coupon * prev_coupon_date_to_settlement_date / NUM_OF_DAYS_IN_YEAR    # R * A / B\n",
    "    return RV_and_interest_due_at_end_date_discounted + coupon_payments_discounted_total - accrued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335c3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "This function is a helper function for `compute_price`. This function calculates the price of a trade, where `yield_rate` \n",
    "is a specific yield and `end_date` is a fixed repayment date. All dates must be valid relative to the settlement \n",
    "date, as opposed to the trade date. Note that \"yield\" is a reserved word in Python and should not be used as the name \n",
    "of a variable or column.\n",
    "Formulas are from https://www.msrb.org/pdf.aspx?url=https%3A%2F%2Fwww.msrb.org%2FRules-and-Interpretations%2FMSRB-Rules%2FGeneral%2FRule-G-33.aspx.\n",
    "For all bonds, `base` is the present value of future cashflows to the buyer. \n",
    "The clean price is this price minus the accumulated amount of simple interest that the buyer must pay to the seller, which is called `accrued`.\n",
    "Zero-coupon bonds are handled first. For these, the yield is assumed to be compounded semi-annually, i.e., once every six months.\n",
    "For bonds with non-zero coupon, the first and last interest payment periods may have a non-standard length,\n",
    "so they must be handled separately.\n",
    "When referring to the formulas in the MSRB handbook (link above), the below variables map to the code.\n",
    "A: prev_coupon_date_to_settlement_date\n",
    "B: NUM_OF_DAYS_IN_YEAR\n",
    "Y: yield_rate\n",
    "N: num_of_interest_payments\n",
    "E: num_of_days_in_period\n",
    "F: settlement_date_to_next_coupon_date\n",
    "P: price\n",
    "D: settlement_date_to_end_date\n",
    "H: prev_coupon_date_to_end_date\n",
    "R: coupon\n",
    "'''\n",
    "def get_price(cusip, \n",
    "              prev_coupon_date, \n",
    "              first_coupon_date, \n",
    "              next_coupon_date, \n",
    "              end_date, \n",
    "              settlement_date, \n",
    "              accrual_date, \n",
    "              frequency, \n",
    "              yield_rate, \n",
    "              coupon, \n",
    "              RV, \n",
    "              time_delta, \n",
    "              last_period_accrues_from_date):\n",
    "    yield_rate = yield_rate / 100\n",
    "    \n",
    "    # Right now we do not disambiguate zero coupon from interest at maturity. More specfically, \n",
    "    # we should add logic that separates the cases of MSRB Rule Book G-33, rule (b) and rule (c)\n",
    "    if frequency == 0:\n",
    "        # See description for `price_of_bond_with_interest_at_maturity`\n",
    "        price = price_of_bond_with_interest_at_maturity(cusip, \n",
    "                                                        settlement_date, \n",
    "                                                        accrual_date, \n",
    "                                                        end_date, \n",
    "                                                        yield_rate, \n",
    "                                                        coupon, \n",
    "                                                        RV)\n",
    "    else:\n",
    "        num_of_interest_payments, final_coupon_date = get_num_of_interest_payments_and_final_coupon_date(next_coupon_date, \n",
    "                                                                                                         end_date, \n",
    "                                                                                                         time_delta)\n",
    "        prev_coupon_date_to_settlement_date = diff_in_days_two_dates(settlement_date, prev_coupon_date)\n",
    "            \n",
    "        num_of_days_in_period = NUM_OF_DAYS_IN_YEAR / frequency    # number of days in interest payment period \n",
    "        assert num_of_days_in_period == round(num_of_days_in_period)\n",
    "         \n",
    "        if compare_dates(end_date, next_coupon_date) <= 0:\n",
    "            # MSRB Rule Book G-33, rule (b)(i)(B)(1)\n",
    "            settlement_date_to_end_date = diff_in_days_two_dates(end_date, settlement_date)\n",
    "            final_coupon_date_to_end_date = diff_in_days_two_dates(end_date, final_coupon_date)\n",
    "            interest_due_at_end_date = coupon * final_coupon_date_to_end_date / NUM_OF_DAYS_IN_YEAR\n",
    "            base = (RV + coupon / frequency + interest_due_at_end_date) / \\\n",
    "                   (1 + (yield_rate / frequency) * settlement_date_to_end_date / num_of_days_in_period)\n",
    "            accrued = coupon * prev_coupon_date_to_settlement_date / NUM_OF_DAYS_IN_YEAR\n",
    "            price = base - accrued\n",
    "        else:\n",
    "            # MSRB Rule Book G-33, rule (b)(i)(B)(2)\n",
    "            price = price_of_bond_with_multiple_periodic_interest_payments(cusip, \n",
    "                                                                           settlement_date, \n",
    "                                                                           accrual_date, \n",
    "                                                                           first_coupon_date, \n",
    "                                                                           prev_coupon_date, \n",
    "                                                                           next_coupon_date, \n",
    "                                                                           final_coupon_date, \n",
    "                                                                           end_date,  \n",
    "                                                                           frequency,\n",
    "                                                                           num_of_interest_payments, \n",
    "                                                                           yield_rate,\n",
    "                                                                           coupon, \n",
    "                                                                           RV, \n",
    "                                                                           time_delta, \n",
    "                                                                           last_period_accrues_from_date)              \n",
    "    return trunc_and_round_price(price)\n",
    "\n",
    "'''\n",
    "This function computes the price of a trade. For bonds that have not been called, the price is the lowest of\n",
    "three present values: to the next call date (which may be above par), to the next par call date, and to maturity.\n",
    "'''\n",
    "def compute_price(trade, yield_rate=None):\n",
    "    if trade.interest_payment_frequency != 0 and pd.isnull(trade.first_coupon_date):\n",
    "        print(f\"Bond (CUSIP: {trade.cusip}, RTRS: {trade.rtrs_control_number}) has a coupon but no first coupon date.\")    # printing instead of raising an error to not disrupt processing large quantities of trades\n",
    "        old_date = pd.to_datetime('2000-01-01')\n",
    "        return -100, old_date, -100,-100,-100, -1\n",
    "    # check if frequency is not 0 and if there is not first_coupon_date, if true, warn and exit\n",
    "    if yield_rate == None:\n",
    "        yield_rate = trade['yield']\n",
    "    elif type(yield_rate) == str:\n",
    "        raise ValueError('Yield rate argument cannot be a string. It must be a numerical value.')\n",
    "\n",
    "    frequency = trade.interest_payment_frequency\n",
    "    time_delta = get_time_delta_from_interest_frequency(frequency)\n",
    "    my_prev_coupon_date, my_next_coupon_date = get_prev_coupon_date_and_next_coupon_date(trade, frequency, time_delta)\n",
    "\n",
    "    get_price_caller = lambda end_date, redemption_value: get_price(trade.cusip, \n",
    "                                                                    my_prev_coupon_date, \n",
    "                                                                    trade.first_coupon_date, \n",
    "                                                                    my_next_coupon_date, \n",
    "                                                                    end_date, \n",
    "                                                                    trade.settlement_date, \n",
    "                                                                    trade.accrual_date, \n",
    "                                                                    frequency, \n",
    "                                                                    yield_rate, \n",
    "                                                                    trade.coupon, \n",
    "                                                                    redemption_value, \n",
    "                                                                    time_delta, \n",
    "                                                                    trade.last_period_accrues_from_date)\n",
    "\n",
    "    redemption_value_at_maturity = 100\n",
    "    if (not trade.is_called) and (not trade.is_callable):\n",
    "        yield_to_maturity = get_price_caller(trade.maturity_date, redemption_value_at_maturity)\n",
    "        return yield_to_maturity, trade.maturity_date, 0, 0 ,0 ,  2\n",
    "    elif trade.is_called:\n",
    "        end_date = end_date_for_called_bond(trade)\n",
    "\n",
    "        if compare_dates(end_date, trade.settlement_date) < 0:\n",
    "            print(f\"Bond (CUSIP: {trade.cusip}, RTRS: {trade.rtrs_control_number}) has an end date ({end_date}) which is after the settlement date ({trade.settlement_date}).\")    # printing instead of raising an error to not disrupt processing large quantities of trades\n",
    "            # raise ValueError(f\"Bond (CUSIP: {trade.cusip}, RTRS: {trade.rtrs_control_number}) has an end date ({end_date}) which is after the settlement date ({trade.settlement_date}).\")\n",
    "        \n",
    "        redemption_value_at_refund = refund_price_for_called_bond(trade)\n",
    "        return get_price_caller(end_date, redemption_value_at_refund), end_date, 0, 0 ,0 , 3\n",
    "    else:\n",
    "        next_price, to_par_price, maturity_price = float('inf'), float('inf'), float('inf')\n",
    "\n",
    "        if not pd.isnull(trade.par_call_date):\n",
    "            to_par_price = get_price_caller(trade.par_call_date, trade.par_call_price)\n",
    "        if not pd.isnull(trade.next_call_date):\n",
    "            next_price = get_price_caller(trade.next_call_date, trade.next_call_price)\n",
    "        maturity_price = get_price_caller(trade.maturity_date, redemption_value_at_maturity)\n",
    "\n",
    "        prices_and_dates = [(next_price, trade.next_call_date), \n",
    "                            (to_par_price, trade.par_call_date), \n",
    "                            (maturity_price, trade.maturity_date)]\n",
    "        calc_price, calc_date = min(prices_and_dates, key=lambda pair: pair[0]) # this function is stable and will choose the pair which appears first in the case of ties for the lowest price\n",
    "    if calc_date == trade.next_call_date:\n",
    "        calc_date_selection = 0\n",
    "    elif calc_date == trade.par_call_date:\n",
    "        calc_date_selection = 1\n",
    "    elif calc_date == trade.maturity_date:\n",
    "        calc_date_selection = 2\n",
    "    elif calc_date == trade.refund_date:\n",
    "        calc_date_selection = 3\n",
    "    else:\n",
    "        calc_date_selection = 4      \n",
    "    return calc_price, calc_date, next_price,to_par_price,maturity_price,calc_date_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a457bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trade_data(bqclient,begin_date,next_date):\n",
    "    query = f'''\n",
    "    SELECT\n",
    "                IFNULL(settlement_date, assumed_settlement_date) AS settlement_date,\n",
    "                trade_date,\n",
    "                cusip,\n",
    "                accrual_date,\n",
    "                dollar_price,\n",
    "                issue_price,\n",
    "                current_coupon_rate as coupon,\n",
    "                interest_payment_frequency,\n",
    "                next_call_date,\n",
    "                par_call_date,\n",
    "                next_call_price,\n",
    "                par_call_price,\n",
    "                maturity_date,\n",
    "                previous_coupon_payment_date,\n",
    "                next_coupon_payment_date,\n",
    "                first_coupon_date,\n",
    "                coupon_type,\n",
    "                muni_security_type,\n",
    "                called_redemption_type,\n",
    "                refund_date,\n",
    "                refund_price,\n",
    "                is_callable,\n",
    "                is_called,\n",
    "                call_timing,\n",
    "                yield,\n",
    "                called_redemption_date,\n",
    "                rtrs_control_number,\n",
    "                has_zero_coupons,\n",
    "                last_period_accrues_from_date,\n",
    "                is_lop_or_takedown,\n",
    "                when_issued,\n",
    "                is_non_transaction_based_compensation,\n",
    "                brokers_broker,\n",
    "                trade_datetime,\n",
    "                publish_datetime,\n",
    "                issue_key,\n",
    "                sequence_number,\n",
    "                par_traded,\n",
    "                series_name,\n",
    "                case when series_name is null then cast(issue_key as string) else\n",
    "                concat(issue_key,series_name) end as series_id\n",
    "                FROM `eng-reactor-287421.auxiliary_views.trades_with_ref_data_pd`\n",
    "                WHERE\n",
    "                publish_datetime BETWEEN '{begin_date}' AND '{next_date}'\n",
    "                and rtrs_control_number <> 2021030407690800 and rtrs_control_number <> 2022042012330500 \n",
    "                and rtrs_control_number <> 2022042012332500 and rtrs_control_number <> 2022032507376100\n",
    "                '''\n",
    "    dataframe = bqclient.query(query).result().to_dataframe()\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10dc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "def get_latest_publish_datetime():\n",
    "    query = f'''\n",
    "    SELECT\n",
    "    publish_datetime\n",
    "    FROM\n",
    "    `eng-reactor-287421.auxiliary_views.calculated_price_with_accrual_date`\n",
    "    order by publish_datetime desc  limit 1\n",
    "    '''\n",
    "    query_job = bqclient.query(query).result().to_dataframe()\n",
    "    query_job = query_job.values[0][0]\n",
    "    query_job = datetime.datetime.utcfromtimestamp(query_job.tolist()/1e9)\n",
    "    return query_job\n",
    "\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas\n",
    "import pytz\n",
    "\n",
    "def getSchema():\n",
    "    schema = [  bigquery.SchemaField(\"rtrs_control_number\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"trade_datetime\", \"DATETIME\"),\n",
    "                bigquery.SchemaField(\"cusip\", \"STRING\"),\n",
    "                bigquery.SchemaField('calc_price',\"FLOAT\"),\n",
    "                bigquery.SchemaField('price_to_next_call',\"FLOAT\"),\n",
    "                bigquery.SchemaField('price_to_par_call',\"FLOAT\"),\n",
    "                bigquery.SchemaField('price_to_maturity',\"FLOAT\"),\n",
    "                bigquery.SchemaField('calc_date',\"DATE\"),\n",
    "                bigquery.SchemaField(\"calc_date_selection\", \"INTEGER\"),\n",
    "                bigquery.SchemaField('price_delta', \"FLOAT\"),\n",
    "                bigquery.SchemaField('publish_datetime', \"DATETIME\"),\n",
    "                bigquery.SchemaField('when_issued', \"BOOLEAN\"),\n",
    "                bigquery.SchemaField(\"issue_key\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"sequence_number\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"par_traded\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"series_name\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"series_id\", \"STRING\")\n",
    "              \n",
    "            ]\n",
    "    return schema\n",
    "\n",
    "\n",
    "def uploadData(vanilla):\n",
    "    client = bigquery.Client(project=PROJECT_ID, location=\"US\")\n",
    "    useful_columns = vanilla[[\"rtrs_control_number\", \"trade_datetime\", \"cusip\",'calc_price','price_to_next_call','price_to_par_call', 'price_to_maturity','calc_date','price_delta','publish_datetime',\"when_issued\", \"calc_date_selection\",\"issue_key\",\"sequence_number\",\"par_traded\",\"series_name\",\"series_id\"]]\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(schema = getSchema(),\n",
    "                                       write_disposition=\"WRITE_APPEND\"\n",
    "                                       )\n",
    "    \n",
    "    job = client.load_table_from_dataframe(useful_columns, TABLE_ID,job_config=job_config)\n",
    "    \n",
    "    try:\n",
    "        job.result()\n",
    "        print(\"Upload Successful\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to Upload\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92507b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01 2019-01-06\n",
      "CPU times: user 345 ms, sys: 224 ms, total: 569 ms\n",
      "Wall time: 46.7 s\n",
      "Dataframe is not empty\n",
      "91102\n",
      "Upload Successful\n",
      "2019-01-06 2019-01-11\n",
      "CPU times: user 380 ms, sys: 238 ms, total: 618 ms\n",
      "Wall time: 40.3 s\n",
      "Dataframe is not empty\n",
      "131152\n",
      "Upload Successful\n",
      "2019-01-11 2019-01-16\n",
      "CPU times: user 300 ms, sys: 227 ms, total: 527 ms\n",
      "Wall time: 53.3 s\n",
      "Dataframe is not empty\n",
      "90778\n",
      "Upload Successful\n",
      "2019-01-16 2019-01-21\n",
      "CPU times: user 298 ms, sys: 227 ms, total: 525 ms\n",
      "Wall time: 45.8 s\n",
      "Dataframe is not empty\n",
      "90073\n",
      "Upload Successful\n",
      "2019-01-21 2019-01-26\n",
      "CPU times: user 400 ms, sys: 311 ms, total: 711 ms\n",
      "Wall time: 1min 7s\n",
      "Dataframe is not empty\n",
      "120057\n",
      "Upload Successful\n",
      "2019-01-26 2019-01-31\n",
      "CPU times: user 290 ms, sys: 200 ms, total: 490 ms\n",
      "Wall time: 57.7 s\n",
      "Dataframe is not empty\n",
      "89515\n",
      "Upload Successful\n",
      "2019-01-31 2019-02-05\n",
      "CPU times: user 274 ms, sys: 241 ms, total: 516 ms\n",
      "Wall time: 44.8 s\n",
      "Dataframe is not empty\n",
      "84707\n",
      "Upload Successful\n",
      "2019-02-05 2019-02-10\n",
      "CPU times: user 377 ms, sys: 284 ms, total: 661 ms\n",
      "Wall time: 44.7 s\n",
      "Dataframe is not empty\n",
      "123150\n",
      "Upload Successful\n",
      "2019-02-10 2019-02-15\n",
      "CPU times: user 340 ms, sys: 238 ms, total: 578 ms\n",
      "Wall time: 43.6 s\n",
      "Dataframe is not empty\n",
      "118213\n",
      "Upload Successful\n",
      "2019-02-15 2019-02-20\n",
      "CPU times: user 240 ms, sys: 207 ms, total: 447 ms\n",
      "Wall time: 52.4 s\n",
      "Dataframe is not empty\n",
      "56422\n",
      "Upload Successful\n",
      "2019-02-20 2019-02-25\n",
      "CPU times: user 292 ms, sys: 206 ms, total: 498 ms\n",
      "Wall time: 39.4 s\n",
      "Dataframe is not empty\n",
      "89398\n",
      "Upload Successful\n",
      "2019-02-25 2019-03-02\n",
      "CPU times: user 409 ms, sys: 271 ms, total: 679 ms\n",
      "Wall time: 41.6 s\n",
      "Dataframe is not empty\n",
      "146760\n",
      "Upload Successful\n",
      "2019-03-02 2019-03-07\n",
      "CPU times: user 308 ms, sys: 284 ms, total: 592 ms\n",
      "Wall time: 53.7 s\n",
      "Dataframe is not empty\n",
      "93516\n",
      "Upload Successful\n",
      "2019-03-07 2019-03-12\n",
      "CPU times: user 283 ms, sys: 226 ms, total: 509 ms\n",
      "Wall time: 47.1 s\n",
      "Dataframe is not empty\n",
      "82704\n",
      "Upload Successful\n",
      "2019-03-12 2019-03-17\n",
      "CPU times: user 334 ms, sys: 266 ms, total: 599 ms\n",
      "Wall time: 40 s\n",
      "Dataframe is not empty\n",
      "111504\n",
      "Upload Successful\n",
      "2019-03-17 2019-03-22\n",
      "CPU times: user 302 ms, sys: 209 ms, total: 511 ms\n",
      "Wall time: 45.5 s\n",
      "Dataframe is not empty\n",
      "111359\n",
      "Upload Successful\n",
      "2019-03-22 2019-03-27\n",
      "CPU times: user 292 ms, sys: 226 ms, total: 518 ms\n",
      "Wall time: 43.6 s\n",
      "Dataframe is not empty\n",
      "81385\n",
      "Upload Successful\n",
      "2019-03-27 2019-04-01\n",
      "CPU times: user 341 ms, sys: 260 ms, total: 602 ms\n",
      "Wall time: 53.8 s\n",
      "Dataframe is not empty\n",
      "84003\n",
      "Upload Successful\n",
      "2019-04-01 2019-04-06\n",
      "CPU times: user 385 ms, sys: 288 ms, total: 674 ms\n",
      "Wall time: 45.8 s\n",
      "Dataframe is not empty\n",
      "139842\n",
      "Upload Successful\n",
      "2019-04-06 2019-04-11\n",
      "CPU times: user 289 ms, sys: 255 ms, total: 544 ms\n",
      "Wall time: 45.6 s\n",
      "Dataframe is not empty\n",
      "85292\n",
      "Upload Successful\n",
      "2019-04-11 2019-04-16\n",
      "CPU times: user 296 ms, sys: 215 ms, total: 511 ms\n",
      "Wall time: 43.8 s\n",
      "Dataframe is not empty\n",
      "78594\n",
      "Upload Successful\n",
      "2019-04-16 2019-04-21\n",
      "CPU times: user 256 ms, sys: 178 ms, total: 434 ms\n",
      "Wall time: 49.2 s\n",
      "Dataframe is not empty\n",
      "48101\n",
      "Upload Successful\n",
      "2019-04-21 2019-04-26\n",
      "CPU times: user 354 ms, sys: 249 ms, total: 603 ms\n",
      "Wall time: 37.8 s\n",
      "Dataframe is not empty\n",
      "113479\n",
      "Upload Successful\n",
      "2019-04-26 2019-05-01\n",
      "CPU times: user 311 ms, sys: 282 ms, total: 593 ms\n",
      "Wall time: 45.1 s\n",
      "Dataframe is not empty\n",
      "80078\n",
      "Upload Successful\n",
      "2019-05-01 2019-05-06\n",
      "CPU times: user 347 ms, sys: 254 ms, total: 601 ms\n",
      "Wall time: 43.5 s\n",
      "Dataframe is not empty\n",
      "83379\n",
      "Upload Successful\n",
      "2019-05-06 2019-05-11\n",
      "CPU times: user 412 ms, sys: 299 ms, total: 711 ms\n",
      "Wall time: 1min 36s\n",
      "Dataframe is not empty\n",
      "132265\n",
      "Upload Successful\n",
      "2019-05-11 2019-05-16\n",
      "CPU times: user 320 ms, sys: 264 ms, total: 584 ms\n",
      "Wall time: 40.2 s\n",
      "Dataframe is not empty\n",
      "87533\n",
      "Upload Successful\n",
      "2019-05-16 2019-05-21\n",
      "CPU times: user 365 ms, sys: 246 ms, total: 611 ms\n",
      "Wall time: 39.7 s\n",
      "Dataframe is not empty\n",
      "80054\n",
      "Upload Successful\n",
      "2019-05-21 2019-05-26\n",
      "CPU times: user 336 ms, sys: 221 ms, total: 557 ms\n",
      "Wall time: 1min 2s\n",
      "Dataframe is not empty\n",
      "104214\n",
      "Upload Successful\n",
      "2019-05-26 2019-05-31\n",
      "CPU times: user 265 ms, sys: 220 ms, total: 485 ms\n",
      "Wall time: 43 s\n",
      "Dataframe is not empty\n",
      "86264\n",
      "Upload Successful\n",
      "2019-05-31 2019-06-05\n",
      "CPU times: user 247 ms, sys: 170 ms, total: 417 ms\n",
      "Wall time: 36.3 s\n",
      "Dataframe is not empty\n",
      "84032\n",
      "Upload Successful\n",
      "2019-06-05 2019-06-10\n",
      "CPU times: user 308 ms, sys: 207 ms, total: 515 ms\n",
      "Wall time: 39.4 s\n",
      "Dataframe is not empty\n",
      "87779\n",
      "Upload Successful\n",
      "2019-06-10 2019-06-15\n",
      "CPU times: user 542 ms, sys: 295 ms, total: 837 ms\n",
      "Wall time: 1min 9s\n",
      "Dataframe is not empty\n",
      "132433\n",
      "Upload Successful\n",
      "2019-06-15 2019-06-20\n",
      "CPU times: user 399 ms, sys: 252 ms, total: 650 ms\n",
      "Wall time: 46.1 s\n",
      "Dataframe is not empty\n",
      "87809\n",
      "Upload Successful\n",
      "2019-06-20 2019-06-25\n",
      "CPU times: user 386 ms, sys: 220 ms, total: 606 ms\n",
      "Wall time: 46 s\n",
      "Dataframe is not empty\n",
      "76916\n",
      "Upload Successful\n",
      "2019-06-25 2019-06-30\n",
      "CPU times: user 306 ms, sys: 218 ms, total: 524 ms\n",
      "Wall time: 45.6 s\n",
      "Dataframe is not empty\n",
      "111983\n",
      "Upload Successful\n",
      "2019-06-30 2019-07-05\n",
      "CPU times: user 273 ms, sys: 219 ms, total: 491 ms\n",
      "Wall time: 57.3 s\n",
      "Dataframe is not empty\n",
      "73648\n",
      "Upload Successful\n",
      "2019-07-05 2019-07-10\n",
      "CPU times: user 236 ms, sys: 159 ms, total: 395 ms\n",
      "Wall time: 43 s\n",
      "Dataframe is not empty\n",
      "66097\n",
      "Upload Successful\n",
      "2019-07-10 2019-07-15\n",
      "CPU times: user 275 ms, sys: 196 ms, total: 471 ms\n",
      "Wall time: 43.1 s\n",
      "Dataframe is not empty\n",
      "80554\n",
      "Upload Successful\n",
      "2019-07-15 2019-07-20\n",
      "CPU times: user 327 ms, sys: 206 ms, total: 533 ms\n",
      "Wall time: 43.3 s\n",
      "Dataframe is not empty\n",
      "124343\n",
      "Upload Successful\n",
      "2019-07-20 2019-07-25\n",
      "CPU times: user 257 ms, sys: 188 ms, total: 445 ms\n",
      "Wall time: 43.5 s\n",
      "Dataframe is not empty\n",
      "74646\n",
      "Upload Successful\n",
      "2019-07-25 2019-07-30\n",
      "CPU times: user 223 ms, sys: 183 ms, total: 406 ms\n",
      "Wall time: 38.3 s\n",
      "Dataframe is not empty\n",
      "67034\n",
      "Upload Successful\n",
      "2019-07-30 2019-08-04\n",
      "CPU times: user 319 ms, sys: 249 ms, total: 568 ms\n",
      "Wall time: 39 s\n",
      "Dataframe is not empty\n",
      "97546\n",
      "Upload Successful\n",
      "2019-08-04 2019-08-09\n",
      "CPU times: user 369 ms, sys: 269 ms, total: 638 ms\n",
      "Wall time: 43.9 s\n",
      "Dataframe is not empty\n",
      "101200\n",
      "Upload Successful\n",
      "2019-08-09 2019-08-14\n",
      "CPU times: user 227 ms, sys: 170 ms, total: 397 ms\n",
      "Wall time: 43.5 s\n",
      "Dataframe is not empty\n",
      "62997\n",
      "Upload Successful\n",
      "2019-08-14 2019-08-19\n",
      "CPU times: user 236 ms, sys: 183 ms, total: 419 ms\n",
      "Wall time: 40.1 s\n",
      "Dataframe is not empty\n",
      "72646\n",
      "Upload Successful\n",
      "2019-08-19 2019-08-24\n",
      "CPU times: user 319 ms, sys: 274 ms, total: 593 ms\n",
      "Wall time: 41 s\n",
      "Dataframe is not empty\n",
      "115450\n",
      "Upload Successful\n",
      "2019-08-24 2019-08-29\n",
      "CPU times: user 260 ms, sys: 186 ms, total: 446 ms\n",
      "Wall time: 46.3 s\n",
      "Dataframe is not empty\n",
      "70555\n",
      "Upload Successful\n",
      "2019-08-29 2019-09-03\n",
      "CPU times: user 195 ms, sys: 162 ms, total: 356 ms\n",
      "Wall time: 50.4 s\n",
      "Dataframe is not empty\n",
      "37399\n",
      "Upload Successful\n",
      "2019-09-03 2019-09-08\n",
      "CPU times: user 301 ms, sys: 223 ms, total: 524 ms\n",
      "Wall time: 39.3 s\n",
      "Dataframe is not empty\n",
      "93815\n",
      "Upload Successful\n",
      "2019-09-08 2019-09-13\n",
      "CPU times: user 391 ms, sys: 234 ms, total: 625 ms\n",
      "Wall time: 45.2 s\n",
      "Dataframe is not empty\n",
      "97898\n",
      "Upload Successful\n",
      "2019-09-13 2019-09-18\n",
      "CPU times: user 353 ms, sys: 226 ms, total: 579 ms\n",
      "Wall time: 42.2 s\n",
      "Dataframe is not empty\n",
      "74324\n",
      "Upload Successful\n",
      "2019-09-18 2019-09-23\n",
      "CPU times: user 325 ms, sys: 195 ms, total: 520 ms\n",
      "Wall time: 49 s\n",
      "Dataframe is not empty\n",
      "73806\n",
      "Upload Successful\n",
      "2019-09-23 2019-09-28\n",
      "CPU times: user 259 ms, sys: 207 ms, total: 466 ms\n",
      "Wall time: 40.5 s\n",
      "Dataframe is not empty\n",
      "119382\n",
      "Upload Successful\n",
      "2019-09-28 2019-10-03\n",
      "CPU times: user 196 ms, sys: 188 ms, total: 384 ms\n",
      "Wall time: 37.9 s\n",
      "Dataframe is not empty\n",
      "72971\n",
      "Upload Successful\n",
      "2019-10-03 2019-10-08\n",
      "CPU times: user 270 ms, sys: 191 ms, total: 461 ms\n",
      "Wall time: 40.3 s\n",
      "Dataframe is not empty\n",
      "71560\n",
      "Upload Successful\n",
      "2019-10-08 2019-10-13\n",
      "CPU times: user 280 ms, sys: 208 ms, total: 488 ms\n",
      "Wall time: 48.2 s\n",
      "Dataframe is not empty\n",
      "90908\n",
      "Upload Successful\n",
      "2019-10-13 2019-10-18\n",
      "CPU times: user 317 ms, sys: 220 ms, total: 538 ms\n",
      "Wall time: 47.5 s\n",
      "Dataframe is not empty\n",
      "80555\n",
      "Upload Successful\n",
      "2019-10-18 2019-10-23\n",
      "CPU times: user 348 ms, sys: 245 ms, total: 592 ms\n",
      "Wall time: 40.9 s\n",
      "Dataframe is not empty\n",
      "70030\n",
      "Upload Successful\n",
      "2019-10-23 2019-10-28\n",
      "CPU times: user 308 ms, sys: 179 ms, total: 487 ms\n",
      "Wall time: 37.9 s\n",
      "Dataframe is not empty\n",
      "72197\n",
      "Upload Successful\n",
      "2019-10-28 2019-11-02\n",
      "CPU times: user 349 ms, sys: 255 ms, total: 604 ms\n",
      "Wall time: 43.1 s\n",
      "Dataframe is not empty\n",
      "121310\n",
      "Upload Successful\n",
      "2019-11-02 2019-11-07\n",
      "CPU times: user 210 ms, sys: 181 ms, total: 391 ms\n",
      "Wall time: 31.2 s\n",
      "Dataframe is not empty\n",
      "78269\n",
      "Upload Successful\n",
      "2019-11-07 2019-11-12\n",
      "CPU times: user 267 ms, sys: 183 ms, total: 450 ms\n",
      "Wall time: 49 s\n",
      "Dataframe is not empty\n",
      "51381\n",
      "Upload Successful\n",
      "2019-11-12 2019-11-17\n",
      "CPU times: user 482 ms, sys: 280 ms, total: 762 ms\n",
      "Wall time: 45.5 s\n",
      "Dataframe is not empty\n",
      "114768\n",
      "Upload Successful\n",
      "2019-11-17 2019-11-22\n",
      "CPU times: user 474 ms, sys: 290 ms, total: 765 ms\n",
      "Wall time: 47.1 s\n",
      "Dataframe is not empty\n",
      "114357\n",
      "Upload Successful\n",
      "2019-11-22 2019-11-27\n",
      "CPU times: user 204 ms, sys: 189 ms, total: 392 ms\n",
      "Wall time: 32.6 s\n",
      "Dataframe is not empty\n",
      "76554\n",
      "Upload Successful\n",
      "2019-11-27 2019-12-02\n",
      "CPU times: user 165 ms, sys: 104 ms, total: 269 ms\n",
      "Wall time: 44.5 s\n",
      "Dataframe is not empty\n",
      "24837\n",
      "Upload Successful\n",
      "2019-12-02 2019-12-07\n",
      "CPU times: user 391 ms, sys: 263 ms, total: 654 ms\n",
      "Wall time: 57.2 s\n",
      "Dataframe is not empty\n",
      "148675\n",
      "Upload Successful\n",
      "2019-12-07 2019-12-12\n",
      "CPU times: user 369 ms, sys: 248 ms, total: 617 ms\n",
      "Wall time: 51.3 s\n",
      "Dataframe is not empty\n",
      "81666\n",
      "Upload Successful\n",
      "2019-12-12 2019-12-17\n",
      "CPU times: user 368 ms, sys: 198 ms, total: 565 ms\n",
      "Wall time: 39.2 s\n",
      "Dataframe is not empty\n",
      "77583\n",
      "Upload Successful\n",
      "2019-12-17 2019-12-22\n",
      "CPU times: user 489 ms, sys: 277 ms, total: 767 ms\n",
      "Wall time: 1min 8s\n",
      "Dataframe is not empty\n",
      "108933\n",
      "Upload Successful\n",
      "2019-12-22 2019-12-27\n",
      "CPU times: user 200 ms, sys: 178 ms, total: 378 ms\n",
      "Wall time: 42 s\n",
      "Dataframe is not empty\n",
      "40733\n",
      "Upload Successful\n",
      "2019-12-27 2020-01-01\n",
      "CPU times: user 195 ms, sys: 116 ms, total: 311 ms\n",
      "Wall time: 44.6 s\n",
      "Dataframe is not empty\n",
      "40485\n",
      "Upload Successful\n",
      "2020-01-01 2020-01-06\n",
      "CPU times: user 232 ms, sys: 152 ms, total: 383 ms\n",
      "Wall time: 34.5 s\n",
      "Dataframe is not empty\n",
      "45833\n",
      "Upload Successful\n",
      "2020-01-06 2020-01-11\n",
      "CPU times: user 377 ms, sys: 268 ms, total: 644 ms\n",
      "Wall time: 39.4 s\n",
      "Dataframe is not empty\n",
      "136031\n",
      "Upload Successful\n",
      "2020-01-11 2020-01-16\n",
      "CPU times: user 303 ms, sys: 236 ms, total: 539 ms\n",
      "Wall time: 42.5 s\n",
      "Dataframe is not empty\n",
      "76963\n",
      "Upload Successful\n",
      "2020-01-16 2020-01-21\n",
      "CPU times: user 261 ms, sys: 136 ms, total: 397 ms\n",
      "Wall time: 34.2 s\n",
      "Dataframe is not empty\n",
      "52506\n",
      "Upload Successful\n",
      "2020-01-21 2020-01-26\n",
      "CPU times: user 364 ms, sys: 248 ms, total: 612 ms\n",
      "Wall time: 44.2 s\n",
      "Dataframe is not empty\n",
      "104942\n",
      "Upload Successful\n",
      "2020-01-26 2020-01-31\n",
      "CPU times: user 477 ms, sys: 290 ms, total: 767 ms\n",
      "Wall time: 56.7 s\n",
      "Dataframe is not empty\n",
      "100583\n",
      "Upload Successful\n",
      "2020-01-31 2020-02-05\n",
      "CPU times: user 386 ms, sys: 218 ms, total: 604 ms\n",
      "Wall time: 42.1 s\n",
      "Dataframe is not empty\n",
      "69971\n",
      "Upload Successful\n",
      "2020-02-05 2020-02-10\n",
      "CPU times: user 431 ms, sys: 290 ms, total: 721 ms\n",
      "Wall time: 40.5 s\n",
      "Dataframe is not empty\n",
      "77904\n",
      "Upload Successful\n",
      "2020-02-10 2020-02-15\n",
      "CPU times: user 386 ms, sys: 293 ms, total: 679 ms\n",
      "Wall time: 45.6 s\n",
      "Dataframe is not empty\n",
      "124732\n",
      "Upload Successful\n",
      "2020-02-15 2020-02-20\n",
      "CPU times: user 231 ms, sys: 162 ms, total: 394 ms\n",
      "Wall time: 40.7 s\n",
      "Dataframe is not empty\n",
      "54387\n",
      "Upload Successful\n",
      "2020-02-20 2020-02-25\n",
      "CPU times: user 253 ms, sys: 171 ms, total: 424 ms\n",
      "Wall time: 37.1 s\n",
      "Dataframe is not empty\n",
      "77175\n",
      "Upload Successful\n",
      "2020-02-25 2020-03-01\n",
      "CPU times: user 318 ms, sys: 231 ms, total: 549 ms\n",
      "Wall time: 32.3 s\n",
      "Dataframe is not empty\n",
      "107112\n",
      "Upload Successful\n",
      "2020-03-01 2020-03-06\n",
      "CPU times: user 372 ms, sys: 291 ms, total: 663 ms\n",
      "Wall time: 38.1 s\n",
      "Dataframe is not empty\n",
      "121387\n",
      "Upload Successful\n",
      "2020-03-06 2020-03-11\n",
      "CPU times: user 256 ms, sys: 235 ms, total: 491 ms\n",
      "Wall time: 42.2 s\n",
      "Dataframe is not empty\n",
      "77262\n",
      "Upload Successful\n",
      "2020-03-11 2020-03-16\n",
      "CPU times: user 319 ms, sys: 229 ms, total: 548 ms\n",
      "Wall time: 37.1 s\n",
      "Dataframe is not empty\n",
      "98498\n",
      "Upload Successful\n",
      "2020-03-16 2020-03-21\n",
      "CPU times: user 530 ms, sys: 311 ms, total: 842 ms\n",
      "Wall time: 43.4 s\n",
      "Dataframe is not empty\n",
      "234203\n",
      "Upload Successful\n",
      "2020-03-21 2020-03-26\n",
      "CPU times: user 486 ms, sys: 396 ms, total: 882 ms\n",
      "Wall time: 43.1 s\n",
      "Dataframe is not empty\n",
      "186612\n",
      "Upload Successful\n",
      "2020-03-26 2020-03-31\n",
      "CPU times: user 341 ms, sys: 307 ms, total: 648 ms\n",
      "Wall time: 48.8 s\n",
      "Dataframe is not empty\n",
      "123540\n",
      "Upload Successful\n",
      "2020-03-31 2020-04-05\n",
      "CPU times: user 632 ms, sys: 332 ms, total: 964 ms\n",
      "Wall time: 49.9 s\n",
      "Dataframe is not empty\n",
      "156032\n",
      "Upload Successful\n",
      "2020-04-05 2020-04-10\n",
      "CPU times: user 614 ms, sys: 371 ms, total: 985 ms\n",
      "Wall time: 46.4 s\n",
      "Dataframe is not empty\n",
      "140053\n",
      "Upload Successful\n",
      "2020-04-10 2020-04-15\n",
      "CPU times: user 283 ms, sys: 260 ms, total: 543 ms\n",
      "Wall time: 41.1 s\n",
      "Dataframe is not empty\n",
      "71664\n",
      "Upload Successful\n",
      "2020-04-15 2020-04-20\n",
      "CPU times: user 372 ms, sys: 224 ms, total: 596 ms\n",
      "Wall time: 47.6 s\n",
      "Dataframe is not empty\n",
      "97686\n",
      "Upload Successful\n",
      "2020-04-20 2020-04-25\n",
      "CPU times: user 472 ms, sys: 285 ms, total: 757 ms\n",
      "Wall time: 39.6 s\n",
      "Dataframe is not empty\n",
      "170638\n",
      "Upload Successful\n",
      "2020-04-25 2020-04-30\n",
      "CPU times: user 514 ms, sys: 336 ms, total: 851 ms\n",
      "Wall time: 39.1 s\n",
      "Dataframe is not empty\n",
      "111745\n",
      "Upload Successful\n",
      "2020-04-30 2020-05-05\n",
      "CPU times: user 473 ms, sys: 301 ms, total: 774 ms\n",
      "Wall time: 36.8 s\n",
      "Dataframe is not empty\n",
      "107444\n",
      "Upload Successful\n",
      "2020-05-05 2020-05-10\n",
      "CPU times: user 549 ms, sys: 343 ms, total: 892 ms\n",
      "Wall time: 45.7 s\n",
      "Dataframe is not empty\n",
      "134256\n",
      "Upload Successful\n",
      "2020-05-10 2020-05-15\n",
      "CPU times: user 354 ms, sys: 309 ms, total: 663 ms\n",
      "Wall time: 34.6 s\n",
      "Dataframe is not empty\n",
      "128829\n",
      "Upload Successful\n",
      "2020-05-15 2020-05-20\n",
      "CPU times: user 303 ms, sys: 288 ms, total: 591 ms\n",
      "Wall time: 59 s\n",
      "Dataframe is not empty\n",
      "89574\n",
      "Upload Successful\n",
      "2020-05-20 2020-05-25\n",
      "CPU times: user 336 ms, sys: 255 ms, total: 591 ms\n",
      "Wall time: 41.1 s\n",
      "Dataframe is not empty\n",
      "80489\n",
      "Upload Successful\n",
      "2020-05-25 2020-05-30\n",
      "CPU times: user 400 ms, sys: 296 ms, total: 696 ms\n",
      "Wall time: 38.5 s\n",
      "Dataframe is not empty\n",
      "116211\n",
      "Upload Successful\n",
      "2020-05-30 2020-06-04\n",
      "CPU times: user 325 ms, sys: 263 ms, total: 588 ms\n",
      "Wall time: 33.2 s\n",
      "Dataframe is not empty\n",
      "91066\n",
      "Upload Successful\n",
      "2020-06-04 2020-06-09\n",
      "CPU times: user 333 ms, sys: 258 ms, total: 591 ms\n",
      "Wall time: 45.7 s\n",
      "Dataframe is not empty\n",
      "81508\n",
      "Upload Successful\n",
      "2020-06-09 2020-06-14\n",
      "CPU times: user 363 ms, sys: 255 ms, total: 617 ms\n",
      "Wall time: 38.3 s\n",
      "Dataframe is not empty\n",
      "112535\n",
      "Upload Successful\n",
      "2020-06-14 2020-06-19\n",
      "CPU times: user 390 ms, sys: 289 ms, total: 679 ms\n",
      "Wall time: 38.4 s\n",
      "Dataframe is not empty\n",
      "114195\n",
      "Upload Successful\n",
      "2020-06-19 2020-06-24\n",
      "CPU times: user 309 ms, sys: 239 ms, total: 548 ms\n",
      "Wall time: 41 s\n",
      "Dataframe is not empty\n",
      "70388\n",
      "Upload Successful\n",
      "2020-06-24 2020-06-29\n",
      "CPU times: user 335 ms, sys: 232 ms, total: 568 ms\n",
      "Wall time: 41 s\n",
      "Dataframe is not empty\n",
      "77048\n",
      "Upload Successful\n",
      "2020-06-29 2020-07-04\n",
      "CPU times: user 343 ms, sys: 199 ms, total: 542 ms\n",
      "Wall time: 35.6 s\n",
      "Dataframe is not empty\n",
      "98213\n",
      "Upload Successful\n",
      "2020-07-04 2020-07-09\n",
      "CPU times: user 336 ms, sys: 243 ms, total: 579 ms\n",
      "Wall time: 44 s\n",
      "Dataframe is not empty\n",
      "86732\n",
      "Upload Successful\n",
      "2020-07-09 2020-07-14\n",
      "CPU times: user 342 ms, sys: 213 ms, total: 555 ms\n",
      "Wall time: 42 s\n",
      "Dataframe is not empty\n",
      "79454\n",
      "Upload Successful\n",
      "2020-07-14 2020-07-19\n",
      "CPU times: user 388 ms, sys: 218 ms, total: 606 ms\n",
      "Wall time: 36.1 s\n",
      "Dataframe is not empty\n",
      "107086\n",
      "Upload Successful\n",
      "2020-07-19 2020-07-24\n",
      "CPU times: user 387 ms, sys: 258 ms, total: 645 ms\n",
      "Wall time: 40.2 s\n",
      "Dataframe is not empty\n",
      "103071\n",
      "Upload Successful\n",
      "2020-07-24 2020-07-29\n",
      "CPU times: user 393 ms, sys: 212 ms, total: 605 ms\n",
      "Wall time: 35.6 s\n",
      "Dataframe is not empty\n",
      "71227\n",
      "Upload Successful\n",
      "2020-07-29 2020-08-03\n",
      "CPU times: user 417 ms, sys: 256 ms, total: 673 ms\n",
      "Wall time: 47.4 s\n",
      "Dataframe is not empty\n",
      "72330\n",
      "Upload Successful\n",
      "2020-08-03 2020-08-08\n",
      "CPU times: user 622 ms, sys: 348 ms, total: 970 ms\n",
      "Wall time: 1min 7s\n",
      "Dataframe is not empty\n",
      "121092\n",
      "Upload Successful\n",
      "2020-08-08 2020-08-13\n",
      "CPU times: user 243 ms, sys: 151 ms, total: 394 ms\n",
      "Wall time: 35 s\n",
      "Dataframe is not empty\n",
      "51201\n",
      "Upload Successful\n",
      "2020-08-13 2020-08-18\n",
      "CPU times: user 359 ms, sys: 244 ms, total: 603 ms\n",
      "Wall time: 47.4 s\n",
      "Dataframe is not empty\n",
      "73129\n",
      "Upload Successful\n",
      "2020-08-18 2020-08-23\n",
      "CPU times: user 398 ms, sys: 304 ms, total: 702 ms\n",
      "Wall time: 53.2 s\n",
      "Dataframe is not empty\n",
      "101477\n",
      "Upload Successful\n",
      "2020-08-23 2020-08-28\n",
      "CPU times: user 410 ms, sys: 301 ms, total: 711 ms\n",
      "Wall time: 1min 33s\n",
      "Dataframe is not empty\n",
      "99178\n",
      "Upload Successful\n",
      "2020-08-28 2020-09-02\n",
      "CPU times: user 314 ms, sys: 257 ms, total: 571 ms\n",
      "Wall time: 58.6 s\n",
      "Dataframe is not empty\n",
      "72299\n",
      "Upload Successful\n",
      "2020-09-02 2020-09-07\n",
      "CPU times: user 366 ms, sys: 252 ms, total: 618 ms\n",
      "Wall time: 1min 3s\n",
      "Dataframe is not empty\n",
      "77187\n",
      "Upload Successful\n",
      "2020-09-07 2020-09-12\n",
      "CPU times: user 396 ms, sys: 280 ms, total: 676 ms\n",
      "Wall time: 48.5 s\n",
      "Dataframe is not empty\n",
      "102942\n",
      "Upload Successful\n",
      "2020-09-12 2020-09-17\n",
      "CPU times: user 385 ms, sys: 259 ms, total: 644 ms\n",
      "Wall time: 1min 1s\n",
      "Dataframe is not empty\n",
      "84838\n",
      "Upload Successful\n",
      "2020-09-17 2020-09-22\n",
      "CPU times: user 350 ms, sys: 236 ms, total: 586 ms\n",
      "Wall time: 52.2 s\n",
      "Dataframe is not empty\n",
      "74491\n",
      "Upload Successful\n",
      "2020-09-22 2020-09-27\n",
      "CPU times: user 381 ms, sys: 270 ms, total: 652 ms\n",
      "Wall time: 45 s\n",
      "Dataframe is not empty\n",
      "105894\n",
      "Upload Successful\n",
      "2020-09-27 2020-10-02\n",
      "CPU times: user 394 ms, sys: 275 ms, total: 669 ms\n",
      "Wall time: 42.5 s\n",
      "Dataframe is not empty\n",
      "110210\n",
      "Upload Successful\n",
      "2020-10-02 2020-10-07\n",
      "CPU times: user 316 ms, sys: 241 ms, total: 557 ms\n",
      "Wall time: 58.1 s\n",
      "Dataframe is not empty\n",
      "80327\n",
      "Upload Successful\n",
      "2020-10-07 2020-10-12\n",
      "CPU times: user 350 ms, sys: 229 ms, total: 580 ms\n",
      "Wall time: 38.7 s\n",
      "Dataframe is not empty\n",
      "84203\n",
      "Upload Successful\n",
      "2020-10-12 2020-10-17\n",
      "CPU times: user 461 ms, sys: 290 ms, total: 750 ms\n",
      "Wall time: 43.1 s\n",
      "Dataframe is not empty\n",
      "125371\n",
      "Upload Successful\n",
      "2020-10-17 2020-10-22\n",
      "CPU times: user 326 ms, sys: 255 ms, total: 581 ms\n",
      "Wall time: 44.6 s\n",
      "Dataframe is not empty\n",
      "86715\n",
      "Upload Successful\n",
      "2020-10-22 2020-10-27\n",
      "CPU times: user 345 ms, sys: 239 ms, total: 584 ms\n",
      "Wall time: 44.1 s\n",
      "Dataframe is not empty\n",
      "83486\n",
      "Upload Successful\n",
      "2020-10-27 2020-11-01\n",
      "CPU times: user 416 ms, sys: 294 ms, total: 711 ms\n",
      "Wall time: 49.9 s\n",
      "Dataframe is not empty\n",
      "119933\n",
      "Upload Successful\n",
      "2020-11-01 2020-11-06\n",
      "CPU times: user 363 ms, sys: 347 ms, total: 711 ms\n",
      "Wall time: 44.4 s\n",
      "Dataframe is not empty\n",
      "105154\n",
      "Upload Successful\n",
      "2020-11-06 2020-11-11\n",
      "CPU times: user 317 ms, sys: 271 ms, total: 588 ms\n",
      "Wall time: 43.6 s\n",
      "Dataframe is not empty\n",
      "69046\n",
      "Upload Successful\n",
      "2020-11-11 2020-11-16\n",
      "CPU times: user 309 ms, sys: 195 ms, total: 503 ms\n",
      "Wall time: 45.7 s\n",
      "Dataframe is not empty\n",
      "63424\n",
      "Upload Successful\n",
      "2020-11-16 2020-11-21\n",
      "CPU times: user 433 ms, sys: 294 ms, total: 727 ms\n",
      "Wall time: 37.4 s\n",
      "Dataframe is not empty\n",
      "149968\n",
      "Upload Successful\n",
      "2020-11-21 2020-11-26\n",
      "CPU times: user 330 ms, sys: 215 ms, total: 544 ms\n",
      "Wall time: 37.4 s\n",
      "Dataframe is not empty\n",
      "72851\n",
      "Upload Successful\n",
      "2020-11-26 2020-12-01\n",
      "CPU times: user 232 ms, sys: 181 ms, total: 413 ms\n",
      "Wall time: 48.2 s\n",
      "Dataframe is not empty\n",
      "32649\n",
      "Bond (CUSIP: 708292EL7, RTRS: 2020113005663100) has an end date (2020-12-01) which is after the settlement date (2020-12-02).\n",
      "Bond (CUSIP: 708292EL7, RTRS: 2020113005663900) has an end date (2020-12-01) which is after the settlement date (2020-12-02).\n",
      "Upload Successful\n",
      "2020-12-01 2020-12-06\n",
      "CPU times: user 433 ms, sys: 271 ms, total: 704 ms\n",
      "Wall time: 47.3 s\n",
      "Dataframe is not empty\n",
      "123706\n",
      "Upload Successful\n",
      "2020-12-06 2020-12-11\n",
      "CPU times: user 398 ms, sys: 331 ms, total: 729 ms\n",
      "Wall time: 46.9 s\n",
      "Dataframe is not empty\n",
      "123525\n",
      "Upload Successful\n",
      "2020-12-11 2020-12-16\n",
      "CPU times: user 337 ms, sys: 272 ms, total: 609 ms\n",
      "Wall time: 36.9 s\n",
      "Dataframe is not empty\n",
      "88928\n",
      "Upload Successful\n",
      "2020-12-16 2020-12-21\n",
      "CPU times: user 341 ms, sys: 240 ms, total: 581 ms\n",
      "Wall time: 35.9 s\n",
      "Dataframe is not empty\n",
      "93291\n",
      "Upload Successful\n",
      "2020-12-21 2020-12-26\n",
      "CPU times: user 340 ms, sys: 192 ms, total: 533 ms\n",
      "Wall time: 40.4 s\n",
      "Dataframe is not empty\n",
      "87905\n",
      "Upload Successful\n",
      "2020-12-26 2020-12-31\n",
      "CPU times: user 341 ms, sys: 207 ms, total: 549 ms\n",
      "Wall time: 44.5 s\n",
      "Dataframe is not empty\n",
      "58017\n",
      "Upload Successful\n",
      "2020-12-31 2021-01-05\n",
      "CPU times: user 225 ms, sys: 155 ms, total: 380 ms\n",
      "Wall time: 47.2 s\n",
      "Dataframe is not empty\n",
      "34504\n",
      "Upload Successful\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "begin_date = datetime.datetime(2019,1,1) \n",
    "next_date = datetime.datetime(2019,1,1)\n",
    "end_date = datetime.datetime(2021,1,1)\n",
    "\n",
    "PROJECT_ID = \"eng-reactor-287421\"\n",
    "TABLE_ID = \"eng-reactor-287421.auxiliary_views.calc_date_and_price\"\n",
    "\n",
    "while begin_date <= end_date:\n",
    "    next_date = begin_date + datetime.timedelta(days=5)\n",
    "    print(begin_date.strftime('%Y-%m-%d'),next_date.strftime('%Y-%m-%d'))\n",
    "    %time df = get_trade_data(bqclient,begin_date.strftime('%Y-%m-%d'),next_date.strftime('%Y-%m-%d'))\n",
    "    vanilla = transform_reference_data(df) \n",
    "    vanilla['anomaly'] = (vanilla.par_traded < 5000) | (vanilla['yield'] < 0) \n",
    "    vanilla['anomaly'] = vanilla['anomaly'] | pd.isnull(vanilla.settlement_date) | pd.isnull(vanilla.first_coupon_date) & (vanilla.coupon > 0)\n",
    "    vanilla['alert'] = False # vanilla.cusip == \"89386FAD5\" # vanilla.redemption_type == 5 # vanilla.cusip == \"803093AM5\" # \n",
    "    #print (vanilla.head()) \n",
    "    if df.empty:\n",
    "        print (\"Dataframe is empty!\")\n",
    "        begin_date = next_date\n",
    "    else:\n",
    "        print (\"Dataframe is not empty\")\n",
    "        print(len(vanilla))\n",
    "        vanilla['calc_price'], vanilla['calc_date'],vanilla['price_to_next_call'],vanilla['price_to_par_call'],vanilla['price_to_maturity'],vanilla['calc_date_selection'] = zip(*vanilla.apply(lambda x: compute_price(x),axis=1))\n",
    "        vanilla['price_delta'] = abs(vanilla.calc_price - vanilla.dollar_price)\n",
    "        \n",
    "#         for key in vanilla[\"issue_key\"]:\n",
    "#             if pd.isnull(key):\n",
    "#                     print(vanilla[\"cusip\"], vanilla[\"rtrs_control_number\"])\n",
    "#         for key in vanilla[\"sequence_number\"]:\n",
    "#             if pd.isnull(key):\n",
    "#                     print(vanilla[\"cusip\"], vanilla[\"rtrs_control_number\"])\n",
    "        uploadData(vanilla)\n",
    "#         print(\"Data uploaded\")\n",
    "        begin_date = next_date\n",
    "        begin_date = next_date\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ea799",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in vanilla[\"issue_key\"]:\n",
    "    if pd.isnull(key):\n",
    "            print(vanilla[\"cusip\"], vanilla[\"rtrs_control_number\"])\n",
    "    else:\n",
    "        print(\"hi\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc67f1c",
   "metadata": {},
   "source": [
    "### vanilla.plot.scatter(x='dollar_price', y='calc_price', c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02120b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sum of errors: {}\".format(np.sum(vanilla['price_delta'])))\n",
    "print(\"Mean of errors: {}\".format(np.mean(vanilla['price_delta'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vanilla[vanilla[\"price_delta\"]> 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['rtrs_control_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8534cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.to_datetime('2000-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8c9a5e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2000-01-01 00:00:00')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
