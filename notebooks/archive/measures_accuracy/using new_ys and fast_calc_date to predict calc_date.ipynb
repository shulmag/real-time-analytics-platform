{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This module independently:\n",
    "let a model predict new_ys, which is the estimated YS now assuming last_duration\n",
    "\n",
    "add new_ficc_ycl and get predicted YTW\n",
    "\n",
    "predict calc_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# Author: Gil\n",
    "# Date: 2022-01-03\n",
    "# Last Modified by: Gil\n",
    "# Last Modified time: 2023-01-18\n",
    "\n",
    "# imports:\n",
    "\n",
    "import gcsfs\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  \n",
    "import torch\n",
    "import sklearn\n",
    "import ficc.utils.globals as globals\n",
    "import seaborn as sns\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from datetime import timedelta ,datetime\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from tensorflow import keras\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib.colors import to_rgb, to_rgba\n",
    "\n",
    "from ficc.utils.yield_curve import get_ficc_ycl,yield_curve_level\n",
    "from ficc.utils.gcp_storage_functions import download_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, IDENTIFIERS, CATEGORICAL_FEATURES, NON_CAT_FEATURES, BINARY\n",
    "from ficc.models import get_model_instance\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.pricing.auxiliary_functions import transform_reference_data\n",
    "from ficc.pricing.price import compute_price\n",
    "from calendars import get_day_before\n",
    "\n",
    "from ficc.utils.diff_in_days import diff_in_days_two_dates\n",
    "from ficc.utils.auxiliary_variables import NUM_OF_DAYS_IN_YEAR\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(rc={'figure.figsize':(12,9)})\n",
    "\n",
    "# Globals:\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/gil/git/ficc/creds.json\"\n",
    "\n",
    "calc_date_cat_dict = {0:'next_call_date',\n",
    "    1:'par_call_date',\n",
    "    2:'maturity_date',\n",
    "    3:'refund_date'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the latest attention model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-24 13:13:38.941681: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Model Trained Until end of 2022:\n",
    "yield_spread_model = keras.models.load_model('/Users/gil/git/ficc/notebooks/measures_accuracy/model_jan_18_new_ys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions:\n",
    "\n",
    "def create_input(df):\n",
    "    global encoders\n",
    "    datalist = []\n",
    "    datalist.append(np.stack(df['trade_history'].to_numpy()))\n",
    "    datalist.append(np.stack(df['target_attention_features'].to_numpy()))\n",
    "\n",
    "    noncat_and_binary = []\n",
    "    for f in NON_CAT_FEATURES + BINARY:\n",
    "        noncat_and_binary.append(np.expand_dims(df[f].to_numpy().astype('float32'), axis=1))\n",
    "    datalist.append(np.concatenate(noncat_and_binary, axis=-1))\n",
    "    \n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        print(f)\n",
    "        encoded = encoders[f].transform(df[f])\n",
    "        datalist.append(encoded.astype('float32'))\n",
    "    \n",
    "    return datalist\n",
    "\n",
    "def get_spread(df):\n",
    "\n",
    "    '''\n",
    "    This function takes a dataframe, encodes the features, and returns yield spread estimates.\n",
    "    NB: This is only used by get_prediction_from_individual_pricing.  In order to be DRY, get_BB11_table and get_ytw_curve\n",
    "    should also use this function. \n",
    "    '''\n",
    "    \n",
    "    inputs = create_input(df)\n",
    "    global yield_spread_model\n",
    "    preds = yield_spread_model.predict(inputs)\n",
    "    preds = preds.reshape(len(preds))\n",
    "    return preds\n",
    "\n",
    "# plot points with transparency depending on size of trade\n",
    "def drawpoints(preds, target, test_dataframe):\n",
    "    # >> Only draw Dealer-Dealer trades <<\n",
    "    r, g, b = to_rgb('purple')\n",
    "    keep = (10**test_dataframe.quantity > threshold)  # save time by not plotting points that would be invisible\n",
    "    w = np.minimum( np.array(10**test_dataframe.quantity[keep]), threshold)\n",
    "    opacity = w/threshold\n",
    "    color = [(r, g, b, alpha) for alpha in opacity]\n",
    "    plt.scatter(preds[keep], target[keep], s=5, c=color)\n",
    "\n",
    "def category_to_calc_date(row):\n",
    "    if row.ficc_calc_date_cat == 0:\n",
    "        if not row.is_callable and not row.is_called:\n",
    "            return row['maturity_date']\n",
    "        elif not row.is_callable and row.is_called:  \n",
    "            return row.refund_date\n",
    "        else:  \n",
    "            return row['next_call_date']\n",
    "    elif row.ficc_calc_date_cat == 1:\n",
    "        return row['par_call_date']\n",
    "    elif row.ficc_calc_date_cat == 2:\n",
    "        return row['maturity_date']\n",
    "    elif row.ficc_calc_date_cat == 3:\n",
    "        if not row.is_called:\n",
    "            return row.maturity_date\n",
    "        else:\n",
    "            return row.refund_date\n",
    "    else:\n",
    "        print(row.ficc_calc_date_cat)\n",
    "        raise ValueError(\"Calculation date not found\")\n",
    "\n",
    "def get_trade_price(trade):\n",
    "    # compute price does not need to return the calc_date, if we are using the calc_date model: \n",
    "    final, _ = compute_price(trade, trade.ficc_ytw)\n",
    "    return final\n",
    "\n",
    "def target_trade_processing_for_attention(row):\n",
    "    trade_mapping = {'D':[0,0], 'S':[0,1], 'P':[1,0]}\n",
    "    target_trade_features = []\n",
    "    target_trade_features.append(row['quantity'])\n",
    "    target_trade_features = target_trade_features + trade_mapping[row['trade_type']]\n",
    "    return np.tile(target_trade_features, (5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data below should start after the date for which the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from ficc.data.process_data import process_data\n",
    "\n",
    "SEQUENCE_LENGTH = 5\n",
    "NUM_FEATURES = 6\n",
    "\n",
    "DATA_QUERY = '''\n",
    "  SELECT\n",
    "    * except(most_recent_event)\n",
    "  FROM\n",
    "    `eng-reactor-287421.auxiliary_views.materialized_trade_history`\n",
    "  WHERE\n",
    "    trade_date >= '2022-11-01'\n",
    "    AND trade_date <= '2022-11-05'\n",
    "    AND msrb_valid_to_date > current_date -- condition to remove cancelled trades\n",
    "  ORDER BY\n",
    "    trade_datetime desc\n",
    "LIMIT 1000\n",
    "'''\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "# trade_data = process_data(DATA_QUERY, \n",
    "#                 bq_client,\n",
    "#                 SEQUENCE_LENGTH,\n",
    "#                 NUM_FEATURES,\n",
    "#                 'data.pkl',\n",
    "#                 'FICC_NEW',\n",
    "#                 estimate_calc_date=False,\n",
    "#                 remove_short_maturity=False,\n",
    "#                 remove_non_transaction_based=False,\n",
    "#                 remove_trade_type = [],\n",
    "#                 trade_history_delay = 0,\n",
    "#                 min_trades_in_history = 0,\n",
    "#                 process_ratings=False,\n",
    "#                 treasury_spread = True,\n",
    "#                 add_previous_treasury_rate=True,\n",
    "#                 add_previous_treasury_difference=True,\n",
    "#                 use_last_duration=False,\n",
    "#                 add_flags=False)\n",
    "\n",
    "# trade_data.to_pickle(\"processed_data.pkl\")\n",
    "\n",
    "trade_data = pd.read_pickle(\"ahmad_jan_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trade_data['yield'] = trade_data['yield']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = trade_data[trade_data.trade_date >= \"2023-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trade_data['ttypes'] = (trade_data.last_trade_type.astype(str) + trade_data.trade_type.astype(str)).astype('category')\n",
    "# if 'ttypes' not in CATEGORICAL_FEATURES:\n",
    "#     CATEGORICAL_FEATURES.append('ttypes')\n",
    "#     PREDICTORS.append('ttypes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the attention model\n",
    "trade_data['target_attention_features'] = trade_data.apply(target_trade_processing_for_attention, axis = 1)\n",
    "\n",
    "if 'target_attention_features' not in PREDICTORS:\n",
    "    PREDICTORS.append('target_attention_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rating': LabelEncoder(), 'incorporated_state_code': LabelEncoder(), 'trade_type': LabelEncoder(), 'purpose_class': LabelEncoder()}\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/gil/git/ficc/notebooks/measures_accuracy/encoders.pkl','rb') as f:\n",
    "    encoders = pickle.load(f)\n",
    "    \n",
    "print(encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trade_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently cover fixed coupon municipals with the following exceptions:\n",
    "\n",
    "Variable coupon\n",
    "Derivatives \n",
    "Zeros*\n",
    "Term bonds \n",
    "Territories (VI, GU, PR)\n",
    "Called bonds*\n",
    "Crossover refunding and partially pre-refunded\n",
    "Maturity less than a year in the future and more than 30 years in the future\n",
    "Callable less than a year in the future \n",
    "Restructured debt\n",
    "Defaulted securities \n",
    "Private placement/subject to SEC regulation 144A\n",
    "Purpose Types:\n",
    "    \"Assisted_living\"\n",
    "    \"Continuing Care Retirement Center\"\n",
    "    \"Convention centers\"\n",
    "    \"Correctional facilities\"\n",
    "    “Harbor/chanel\"\n",
    "    \"Mall\"\n",
    "    \"Single family housing\"\n",
    "    “Real Estate”\n",
    "\n",
    "\n",
    "*Verify that these are necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "incorporated_state_code\n",
      "trade_type\n",
      "purpose_class\n"
     ]
    }
   ],
   "source": [
    "# data = data[(data.days_to_call == 0) | (data.days_to_call > np.log10(400))]\n",
    "# data = data[(data.days_to_refund == 0) | (data.days_to_refund > np.log10(400))]\n",
    "# data = data[data.days_to_maturity < np.log10(30000)]\n",
    "\n",
    "# data = data[data.incorporated_state_code != 'PR']\n",
    "# data = data[data.incorporated_state_code != 'VI']\n",
    "# data = data[data.incorporated_state_code != 'GU']\n",
    "\n",
    "# data = data[~data.purpose_sub_class.isin([6, 20, 22, 44, 57, 90])]\n",
    "# data = data[~data.called_redemption_type.isin([18, 19])]\n",
    "# data = data[~data.purpose_class.isin([44,35])]\n",
    "\n",
    "# data = data.loc[:,~data.columns.duplicated()].copy()\n",
    "\n",
    "df = data\n",
    "\n",
    "df = df[df.rating != 'CCC']\n",
    "\n",
    "if 'ficc_treasury_spread' not in PREDICTORS:\n",
    "    PREDICTORS.append('ficc_treasury_spread')\n",
    "    NON_CAT_FEATURES.append('ficc_treasury_spread')\n",
    "\n",
    "predicted_spreads = get_spread(df[PREDICTORS])\n",
    "df = df.copy()\n",
    "df['ficc_spreads'] = predicted_spreads #new_ys NOT ficc_spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbt_pred = model.predict(gbmprep(df[PREDICTORS]) )    \n",
    "# df['ficc_ytw'] = np.round(gbt_pred[0]/100,2) #ytw\n",
    "# df['yield'] = np.round(gbt_pred[0]/100,2) #ytw\n",
    "# df['interest_payment_frequency'] = df.orig_interest_payment_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['error'] =  np.abs(df.yield_spread - df.ficc_spreads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2023-01-03 00:00:00: 11.881063001285256\n",
      "MAE for 2023-01-04 00:00:00: 12.42232913836055\n",
      "MAE for 2023-01-05 00:00:00: 12.798877314662677\n",
      "MAE for 2023-01-06 00:00:00: 12.219683121773924\n",
      "MAE for 2023-01-09 00:00:00: 13.02212610147729\n",
      "MAE for 2023-01-10 00:00:00: 13.322046271377035\n",
      "MAE for 2023-01-11 00:00:00: 13.200449730294975\n",
      "MAE for 2023-01-12 00:00:00: 13.30796034974636\n",
      "MAE for 2023-01-13 00:00:00: 14.104495795494389\n",
      "MAE for 2023-01-17 00:00:00: 15.089556052859555\n",
      "MAE for 2023-01-18 00:00:00: 14.381677841671948\n",
      "MAE for 2023-01-19 00:00:00: 13.828820007578914\n",
      "MAE for 2023-01-20 00:00:00: 13.98624007385416\n",
      "\n",
      "All Rated YS MAE: 13.114\n",
      "\n",
      "Missing Rating only YS MAE: 13.93\n",
      "\n",
      "All Not Rated, MR & NRs YS MAE: 14.145\n",
      "\n",
      "All Trades Yield Spread Preds MAE: 13.3\n",
      "\n",
      "True-Mid DD Yield Spread Preds MAE: 8.582\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#df = df[(df.trade_type == 'D') & (df.quantity >= np.log10(500000))]\n",
    "\n",
    "daily_maes = []\n",
    "dates = []\n",
    "for d in [d for d in pd.date_range(start=\"01/01/2023\",end=\"01/20/2023\",freq='D')]:\n",
    "    next_day = df[df.trade_date == d].copy()\n",
    "    error = next_day.yield_spread - next_day.ficc_spreads\n",
    "    MAE = np.mean(np.abs(error))\n",
    "    daily_maes.append(MAE)\n",
    "    dates.append(d)\n",
    "    if not math.isnan(MAE):\n",
    "        print(f\"MAE for {d}: {MAE}\")\n",
    "\n",
    "rated = df[(df.rating != 'MR') & (df.rating != 'NR')].copy()\n",
    "error = rated.yield_spread - rated.ficc_spreads\n",
    "MAE = np.mean(np.abs(error))\n",
    "print(f\"\\nAll Rated YS MAE: {round(MAE,3)}\")\n",
    "\n",
    "not_rated = df[(df.rating == 'MR')].copy()\n",
    "error = not_rated.yield_spread - not_rated.ficc_spreads\n",
    "MAE = np.mean(np.abs(error))\n",
    "print(f\"\\nMissing Rating only YS MAE: {round(MAE,3)}\")\n",
    "\n",
    "not_rated = df[(df.rating == 'MR') | (df.rating == 'NR')].copy()\n",
    "error = not_rated.yield_spread - not_rated.ficc_spreads\n",
    "MAE = np.mean(np.abs(error))\n",
    "print(f\"\\nAll Not Rated, MR & NRs YS MAE: {round(MAE,3)}\")\n",
    "\n",
    "error = df.yield_spread - df.ficc_spreads\n",
    "MAE = np.mean(np.abs(error))\n",
    "print(f\"\\nAll Trades Yield Spread Preds MAE: {round(MAE,3)}\")\n",
    "\n",
    "dd_true_mid_df = df[(df.trade_type == 'D') & (df.quantity >= np.log10(500000))] #& (df.days_to_call >= np.log10(365))]\n",
    "\n",
    "error = dd_true_mid_df.yield_spread - dd_true_mid_df.ficc_spreads\n",
    "MAE = np.mean(np.abs(error))\n",
    "print(f\"\\nTrue-Mid DD Yield Spread Preds MAE: {round(MAE,3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calc_date Vs fast_calc_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calc_date(row):\n",
    "    if row.is_called:\n",
    "        return row.refund_date\n",
    "    elif row.is_called == False and row.is_callable is False:\n",
    "        return row.maturity_date\n",
    "    else:\n",
    "        cat = row.last_calc_day_cat\n",
    "        if cat == 0:\n",
    "            return row.next_call_date\n",
    "        elif cat == 1:\n",
    "            return row.par_call_date\n",
    "        elif cat == 2:\n",
    "            return row.maturity_date\n",
    "        else:\n",
    "            return row.refund_date\n",
    "        \n",
    "def assign(calc_date, which, date):\n",
    "    calc_date[which] = date[which]\n",
    "\n",
    "def fast_calc_date(df):\n",
    "    calc_date = df.par_call_date\n",
    "    assign(calc_date, df.last_calc_day_cat == 0,                 df.next_call_date)\n",
    "    assign(calc_date, df.ytw_pred > 100 * df.coupon,                  df.maturity_date)\n",
    "    assign(calc_date, df.deferred & (df.last_calc_day_cat == 0), df.next_call_date)\n",
    "    assign(calc_date, ~df.is_callable,                           df.maturity_date)\n",
    "    assign(calc_date, df.is_called,                              df.refund_date)\n",
    "    return calc_date\n",
    "\n",
    "def alt_calc_date(row):\n",
    "    if row.is_called:\n",
    "        return row.refund_date\n",
    "    elif not row.is_callable:\n",
    "        return row.maturity_date   \n",
    "    elif (row.coupon == 0) and (row.last_calc_day_cat == 0):\n",
    "        return row.next_call_date\n",
    "    elif (row.ytw > 100 * row.coupon):\n",
    "        return row.maturity_date \n",
    "    elif row.last_calc_day_cat == 0:\n",
    "        return row.next_call_date\n",
    "    else:                \n",
    "        return row.par_call_date\n",
    "\n",
    "def get_yield_for_last_duration(row):\n",
    "    if row['last_calc_date'] is None or row['last_trade_date'] is None:\n",
    "        return None\n",
    "    # temp_date = get_day_before(row['trade_date'])\n",
    "    duration =  diff_in_days_two_dates(row['last_calc_date'],row['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    ycl = yield_curve_level(duration, row['trade_date'], nelson_params, scalar_params, shape_parameter)/100\n",
    "    return ycl\n",
    "\n",
    "def sqltodf(sql, bq_client):\n",
    "    bqr = bq_client.query(sql).result()\n",
    "    return bqr.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning of calc date model investigation:\n",
    "(Remove) The below is a debug cell to better understand when the labels are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground truth: \n",
    "df[\"calc_date_label\"] = df.calc_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nelson_params = sqltodf(\"select * from `eng-reactor-287421.yield_curves_v2.nelson_siegel_coef_daily` order by date desc\", bq_client)\n",
    "nelson_params.set_index(\"date\", drop=True, inplace=True)\n",
    "nelson_params = nelson_params[~nelson_params.index.duplicated(keep='first')]\n",
    "\n",
    "scalar_params = sqltodf(\"select * from`eng-reactor-287421.yield_curves_v2.standardscaler_parameters_daily` order by date desc\", bq_client)\n",
    "scalar_params.set_index(\"date\", drop=True, inplace=True)\n",
    "scalar_params = scalar_params[~scalar_params.index.duplicated(keep='first')]\n",
    "\n",
    "shape_parameter  = sqltodf(\"SELECT *  FROM `eng-reactor-287421.yield_curves_v2.shape_parameters` order by Date desc\", bq_client)\n",
    "shape_parameter.set_index(\"Date\", drop=True, inplace=True)\n",
    "shape_parameter = shape_parameter[~shape_parameter.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_trade_date'] = df['last_trade_datetime'].dt.date\n",
    "df['new_ficc_ycl'] = df[['last_calc_date','last_settlement_date','trade_date','last_trade_date']].parallel_apply(get_yield_for_last_duration, axis=1)\n",
    "df['new_ficc_ycl'] = df['new_ficc_ycl'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of fast_calc_date function using MSRB yield: 0.9990261258817725\n"
     ]
    }
   ],
   "source": [
    "df['ytw_pred'] = df['yield']\n",
    "df['calc_date'] = fast_calc_date(df)\n",
    "print(f\"accuracy of fast_calc_date function using MSRB yield: {len(df[df.calc_date == df.calc_date_label])/len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['ytw_pred'] = df.last_ytw\n",
    "# df['calc_date'] = fast_calc_date(df)\n",
    "# print(f\"accuracy of fast_calc_date function using MSRB yield: {len(df[df.calc_date == df.calc_date_label])/len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of fast_calc_date function using ytw_pred: 0.9566113452063396\n"
     ]
    }
   ],
   "source": [
    "df['ytw_pred'] = df.new_ficc_ycl + df.ficc_spreads #new_ys\n",
    "df['calc_date'] = fast_calc_date(df)\n",
    "print(f\"accuracy of fast_calc_date function using ytw_pred: {len(df[df.calc_date == df.calc_date_label])/len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of calc_date function: 0.9476115523681586\n",
      "468233\n"
     ]
    }
   ],
   "source": [
    "# this is the old calc_date func: \n",
    "df['calc_date'] = df.apply(get_calc_date,axis=1) \n",
    "print(f\"accuracy of calc_date function: {len(df[df.calc_date == df.calc_date_label])/len(df)}\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delta'] = df.ytw_pred - df['yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.921498606208303"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.abs(df['delta']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9809fc321f8d05d8d96d2933fc3e9b51b9e0542186ce5429a67c2726e9a8489"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
