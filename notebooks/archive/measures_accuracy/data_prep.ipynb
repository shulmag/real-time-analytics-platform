{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26536f86",
   "metadata": {},
   "source": [
    "## Data Preparationn For Models (Gil)\n",
    "This notebook is used to process data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367d631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import redis\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, NON_CAT_FEATURES, BINARY, CATEGORICAL_FEATURES, IDENTIFIERS\n",
    "from ficc.utils.gcp_storage_functions import upload_data, download_data\n",
    "from ficc.utils.nelson_siegel_model import yield_curve_level\n",
    "from ficc.utils.diff_in_days import diff_in_days_two_dates\n",
    "from ficc.utils.auxiliary_variables import NUM_OF_DAYS_IN_YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244027c7",
   "metadata": {},
   "source": [
    "\n",
    "Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0097539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/gil/git/ficc/creds.json\"\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7fac74",
   "metadata": {},
   "source": [
    "Declaring parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030d8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 5\n",
    "NUM_FEATURES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ef6e0",
   "metadata": {},
   "source": [
    "Initializing BigQuery and storage client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b2ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac3d78",
   "metadata": {},
   "source": [
    "#### Query to fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85229e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_QUERY = '''  SELECT\n",
    "    * except(most_recent_event)\n",
    "  FROM\n",
    "    `eng-reactor-287421.auxiliary_views.materialized_trade_history`\n",
    "  WHERE\n",
    "    yield IS NOT NULL\n",
    "    AND yield > 0\n",
    "    AND par_traded >= 10000\n",
    "    AND trade_date >= '2023-01-01'\n",
    "    AND trade_date <= '2023-01-16'\n",
    "    AND maturity_description_code = 2\n",
    "    AND coupon_type in (8, 4, 10, 17)\n",
    "    AND capital_type <> 10\n",
    "    AND default_exists <> TRUE\n",
    "    AND most_recent_default_event IS NULL\n",
    "    AND default_indicator IS FALSE\n",
    "    AND msrb_valid_to_date > current_date -- condition to remove cancelled trades\n",
    "    AND settlement_date is not null\n",
    "  ORDER BY\n",
    "    trade_datetime desc\n",
    "    LIMIT 5000\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d4d84",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "We grab the data from BigQuery and converts it into a format suitable for input to the model. We save the processed data as a pickle file. If the file already exists we read it from the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e97de3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_timestamp = datetime.now().strftime('%Y-%m-%d-%H:%M')\n",
    "processed_file = f\"processed_data_{file_timestamp}.pkl\"\n",
    "# processed_file = f\"processed_data_dec.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410f8e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'processed_data_2023-01-18-20:12.pkl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee3214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with\n",
      " remove_short_maturity:True\n",
      " trade_history_delay:1\n",
      " min_trades_in_hist:0\n",
      " process_ratings:False\n",
      " add_flags:False\n",
      "Grabbing yield curve params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gil/base/lib/python3.9/site-packages/ficc/utils/get_treasury_rate.py:23: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  globals.treasury_rate = globals.treasury_rate.transpose().to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing data from BigQuery\n",
      "Saving query and data to raw_data_2023-01-18-20:12.pkl\n",
      "Raw data contains 5000 samples\n",
      "Creating trade history\n",
      "Removing trades with shorter maturity\n",
      "Removing trades less than 1 minutes in the history\n",
      "Trade history created\n",
      "Getting last trade features\n",
      "Restricting the trade history to the 5 most recent trades\n",
      "Padding history\n",
      "Minimum number of trades required in the history 0\n",
      "Padding completed\n",
      "Processed trade history contain 5000 samples\n",
      "Calculating yield spread using ficc yield curve\n",
      "Yield spread calculated\n",
      "Fetiching treasury rates\n",
      "Difference in treasury rates calculated\n",
      "Processing features\n",
      "Removing trades which are settled more than a month from trade date\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gil/base/lib/python3.9/site-packages/pandas/core/arraylike.py:405: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of samples 4709\n",
      "CPU times: user 9.88 s, sys: 2.61 s, total: 12.5 s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# with exclusions\n",
    "data = process_data(DATA_QUERY, \n",
    "                    bq_client,\n",
    "                    SEQUENCE_LENGTH,\n",
    "                    NUM_FEATURES,\n",
    "                    f\"raw_data_{file_timestamp}.pkl\",\n",
    "                    'FICC_NEW',\n",
    "                    estimate_calc_date=False,\n",
    "                    remove_short_maturity=True,\n",
    "                    remove_non_transaction_based=False,\n",
    "                    remove_trade_type = [],\n",
    "                    trade_history_delay = 1,\n",
    "                    min_trades_in_history = 0,\n",
    "                    process_ratings=False,\n",
    "                    treasury_spread = True,\n",
    "                    add_previous_treasury_rate=True,\n",
    "                    add_previous_treasury_difference=True,\n",
    "                    add_flags=False)\n",
    "\n",
    "# # without any exclusions\n",
    "# data = process_data(DATA_QUERY, \n",
    "#                     bq_client,\n",
    "#                     SEQUENCE_LENGTH,\n",
    "#                     NUM_FEATURES,\n",
    "#                     f\"raw_data_{file_timestamp}.pkl\",\n",
    "#                     'FICC_NEW',\n",
    "#                     estimate_calc_date=False,\n",
    "#                     remove_short_maturity=False,\n",
    "#                     remove_non_transaction_based=False,\n",
    "#                     remove_trade_type = [],\n",
    "#                     trade_history_delay = 0,\n",
    "#                     min_trades_in_history = 0,\n",
    "#                     process_ratings=False,\n",
    "#                     treasury_spread = True,\n",
    "#                     add_previous_treasury_rate=True,\n",
    "#                     add_previous_treasury_difference=True,\n",
    "#                     use_last_duration=False,\n",
    "#                     add_flags=False)\n",
    "data.to_pickle(processed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ec0fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4709"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb578f1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'processed_data_2023-01-14-22:09.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_data_2023-01-14-22:09.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/base/lib/python3.9/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/base/lib/python3.9/site-packages/pandas/io/common.py:866\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    858\u001b[0m             handle,\n\u001b[1;32m    859\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    862\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    863\u001b[0m         )\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    869\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'processed_data_2023-01-14-22:09.pkl'"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle(\"processed_data_2023-01-14-22:09.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.purpose_sub_class.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7ff34",
   "metadata": {},
   "source": [
    "## Adding target trade features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_mapping = {'D':[0,0], 'S':[0,1], 'P':[1,0]}\n",
    "def target_trade_processing_for_attention(row):\n",
    "    target_trade_features = []\n",
    "    target_trade_features.append(row['quantity'])\n",
    "    target_trade_features = target_trade_features + trade_mapping[row['trade_type']]\n",
    "    return np.tile(target_trade_features, (SEQUENCE_LENGTH,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36728c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['target_attention_features'] = data.parallel_apply(target_trade_processing_for_attention, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06396c63",
   "metadata": {},
   "source": [
    "## Replacing the ratings with the stand alone ratings. This is done to exclude enhancements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd52087",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.sp_stand_alone.isna(), 'sp_stand_alone'] = 'NR'\n",
    "\n",
    "data.rating = data.rating.astype('str')\n",
    "data.sp_stand_alone = data.sp_stand_alone.astype('str')\n",
    "\n",
    "data.loc[(data.sp_stand_alone != 'NR'),'rating'] = data[(data.sp_stand_alone != 'NR')]['sp_stand_alone'].loc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da287347",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['yield'] = data['yield'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(processed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='recent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle('processed_data_2022-11-28-18:12_recent.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload_data(storage_client, 'ficc_training_data_latest',procssed_file)\n",
    "# upload_data(storage_client, 'ahmad_data','processed_data_2022-11-28-18:12_recent.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30ece3",
   "metadata": {},
   "source": [
    "# Adding yield curve for every possible candidate calc date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqltodf(sql, bq_client):\n",
    "    bqr = bq_client.query(sql).result()\n",
    "    return bqr.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(processed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nelson_params = sqltodf(\"select * from `eng-reactor-287421.yield_curves_v2.nelson_siegel_coef_daily` order by date desc\", bq_client)\n",
    "nelson_params.set_index(\"date\", drop=True, inplace=True)\n",
    "nelson_params = nelson_params[~nelson_params.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5936bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_params = sqltodf(\"select * from`eng-reactor-287421.yield_curves_v2.standardscaler_parameters_daily` order by date desc\", bq_client)\n",
    "scalar_params.set_index(\"date\", drop=True, inplace=True)\n",
    "scalar_params = scalar_params[~scalar_params.index.duplicated(keep='first')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705da609",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_parameter  = sqltodf(\"SELECT *  FROM `eng-reactor-287421.yield_curves_v2.shape_parameters` order by Date desc\", bq_client)\n",
    "shape_parameter.set_index(\"Date\", drop=True, inplace=True)\n",
    "shape_parameter = shape_parameter[~shape_parameter.index.duplicated(keep='first')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yield_for_date(row):\n",
    "    ficc_ycl_dates = []\n",
    "    for i in ['maturity_date', 'next_call_date', 'par_call_date', 'refund_date']:\n",
    "        if pd.isnull(row[i]):\n",
    "            ficc_ycl_dates.append(np.nan)\n",
    "            continue\n",
    "        target_date = row[i]\n",
    "        duration =  diff_in_days_two_dates(target_date,row['trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "        ficc_ycl_dates.append(yield_curve_level(duration, row['trade_date'].date(), nelson_params, scalar_params, shape_parameter))\n",
    "\n",
    "    return ficc_ycl_dates[0], ficc_ycl_dates[1], ficc_ycl_dates[2], ficc_ycl_dates[3] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ad869",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_df = data.parallel_apply(get_yield_for_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['ficc_ycl_to_maturity','ficc_ycl_to_next_call','ficc_ycl_to_par_call', 'ficc_ycl_to_refund']] = pd.DataFrame(temp_df.to_list(), index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7d874e",
   "metadata": {},
   "source": [
    "# Adding yield curve level for previous calc date candiates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['last_trade_date'] = data['last_trade_datetime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0219a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yield_for_last_date(row):\n",
    "    ficc_ycl_dates = []\n",
    "    for i in ['last_maturity_date', 'last_next_call_date', 'last_par_call_date', 'last_refund_date']:\n",
    "        if pd.isnull(row[i]):\n",
    "            ficc_ycl_dates.append(np.nan)\n",
    "            continue\n",
    "        target_date = row[i]\n",
    "        duration =  diff_in_days_two_dates(target_date.date(),row['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "        if row['last_trade_date'] < datetime(2021, 8, 2).date():\n",
    "            ficc_ycl_dates.append(yield_curve_level(duration, datetime(2021, 8, 3).date(), nelson_params, scalar_params, shape_parameter))\n",
    "        else:\n",
    "            ficc_ycl_dates.append(yield_curve_level(duration, row['last_trade_date'], nelson_params, scalar_params, shape_parameter))\n",
    "\n",
    "    return ficc_ycl_dates[0], ficc_ycl_dates[1], ficc_ycl_dates[2], ficc_ycl_dates[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4676e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = data.parallel_apply(get_yield_for_last_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bd40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['last_ficc_ycl_to_maturity','last_ficc_ycl_to_next_call','last_ficc_ycl_to_par_call', 'last_ficc_ycl_to_refund']] = pd.DataFrame(temp_df.to_list(), index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a136de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(processed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f99f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload_data(storage_client, 'ahmad_data',processed_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3643d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload_data(storage_client, 'ficc_training_data_latest','raw_data_2022-12-01-19:45.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c2d89",
   "metadata": {},
   "source": [
    "## Adding last treasury spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa10824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqltodf(sql, bq_client):\n",
    "    bqr = bq_client.query(sql).result()\n",
    "    return bqr.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de812586",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''SELECT * FROM `eng-reactor-287421.treasury_yield.daily_yield_rate` order by Date desc;'''\n",
    "treasury_rate = sqltodf(query, bq_client)\n",
    "treasury_rate.set_index(\"Date\", drop=True, inplace=True)\n",
    "treasury_rate = treasury_rate.transpose().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b61797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_treasury_rate(trade):\n",
    "    treasury_maturities = np.array([1,2,3,5,7,10,20,30])\n",
    "    if trade['last_calc_date'] is None or trade['last_settlement_date'] is None or trade['last_trade_date'] is None:\n",
    "        return None\n",
    "    time_to_maturity = diff_in_days_two_dates(trade['last_calc_date'],trade['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    maturity = min(treasury_maturities, key=lambda x:abs(x-time_to_maturity))\n",
    "    maturity = 'year_'+str(maturity)\n",
    "    t_rate = treasury_rate[trade['last_trade_date']][maturity]\n",
    "    return t_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee932bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# data['last_treasury_rate'] = data[['last_trade_date','last_calc_date','last_settlement_date']].parallel_apply(previous_treasury_rate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ae4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.last_trade_date.isna()]['rtrs_control_number']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65a85d",
   "metadata": {},
   "source": [
    "### Adding corporate yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "quandl.ApiConfig.api_key = 'C6tWjxHm29zz7L5BLQxW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeed5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corporate_yield = quandl.get(\"USTREASURY/HQMYC\")\n",
    "corporate_maturities = np.array(corporate_yield.columns).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f88b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding corporate yield with modified duration\n",
    "def get_corporate_spread(row):\n",
    "    if row['last_calc_date'] is None or row['last_trade_date'] is None:\n",
    "        return None\n",
    "#     duration =  diff_in_days_two_dates(row['last_calc_date'],row['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    duration =  diff_in_days_two_dates(row['calc_date'],row['trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    maturity = min(corporate_maturities, key=lambda x:abs(x-duration))\n",
    "    temp_corporate_yield = corporate_yield.iloc[corporate_yield.index.get_loc(row['trade_date'],method='pad')]\n",
    "    c_yield = temp_corporate_yield[str(maturity)]\n",
    "    return c_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a061c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['new_corporate_yield'] = data[['trade_date','last_settlement_date','last_calc_date','last_trade_date', 'calc_date']].parallel_apply(get_corporate_spread,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['corporate_spread'] = (data['ficc_ycl'] - data['corporate_yield']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_corporate_yield'] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74551acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_corporate_yield']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa78a4e",
   "metadata": {},
   "source": [
    "### Adding last corporate yield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding corporate yield with modified duration\n",
    "def get_last_corporate_spread(row):\n",
    "    if row['last_calc_date'] is None or row['last_trade_date'] is None or row['last_trade_datetime'] is None:\n",
    "        return None\n",
    "    duration =  diff_in_days_two_dates(row['last_calc_date'],row['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    maturity = min(corporate_maturities, key=lambda x:abs(x-duration))\n",
    "    temp_corporate_yield = corporate_yield.iloc[corporate_yield.index.get_loc(row['last_trade_datetime'],method='pad')]\n",
    "    c_yield = temp_corporate_yield[str(maturity)]\n",
    "    return c_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d623289",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# data['last_corporate_yield'] = data[['last_trade_datetime','last_trade_date','last_calc_date']].parallel_apply(get_last_corporate_spread,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.last_corporate_yield *= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a0c0a",
   "metadata": {},
   "source": [
    "### Modified yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdfc9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yield_for_last_duration(row):\n",
    "    if row['last_calc_date'] is None or row['last_trade_date'] is None:\n",
    "        return None\n",
    "    duration =  diff_in_days_two_dates(row['last_calc_date'],row['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    ycl = yield_curve_level(duration, row['trade_date'].date(), nelson_params, scalar_params, shape_parameter)/100\n",
    "    return ycl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8cd27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['new_ficc_ycl'] = data[['last_calc_date','last_settlement_date','trade_date','last_trade_date']].parallel_apply(get_yield_for_last_duration, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.new_ficc_ycl = data.new_ficc_ycl * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62734c15",
   "metadata": {},
   "source": [
    "### new treasury rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8622751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_treasury_rate(trade):\n",
    "    treasury_maturities = np.array([1,2,3,5,7,10,20,30])\n",
    "    if trade['last_calc_date'] is None or trade['last_settlement_date'] is None or trade['last_trade_date'] is None:\n",
    "        return None\n",
    "    time_to_maturity = diff_in_days_two_dates(trade['last_calc_date'],trade['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    maturity = min(treasury_maturities, key=lambda x:abs(x-time_to_maturity))\n",
    "    maturity = 'year_'+str(maturity)\n",
    "    t_rate = treasury_rate[trade['trade_date'].date()][maturity]\n",
    "    return t_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca52d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['new_treasury_rate'] = data[['last_trade_date','last_calc_date','last_settlement_date','trade_date']].parallel_apply(modified_treasury_rate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e8593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.new_treasury_rate = data.new_treasury_rate * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81858a",
   "metadata": {},
   "source": [
    "## Saving and uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb8652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(processed_file_0115)\n",
    "#upload_data(storage_client, 'ficc_training_data_latest',processed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce64d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c5e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.trade_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdecacc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.trade_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.new_ficc_ycl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ficc_ycl_1_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9d194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m78"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
