{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358ab8fd",
   "metadata": {},
   "source": [
    "### Estimating _calc_date_ with high accuracy based on reference data and on yield-to-worst\n",
    "\n",
    "Last modified by Charles on 2023/1/14.\n",
    "\n",
    "Summary of findings: \n",
    "The time to calculated estimated _calc_date_ for about one million trades is about 200 milliseconds.\n",
    "When using true yield to worst, accuracy in estimating _calc_date_ is around 99.98%,\n",
    "versus 98% with _ytw_preds_ and 95% when using _last_ytw_.\n",
    "\n",
    "General comments:\n",
    "For a recent previous version of this notebook, see https://github.com/Ficc-ai/ficc/blob/ficc_ml/ml_models/sequence_predictors/charles_20221212.ipynb.\n",
    "For a previous version that calculates flags for groups of trades, see https://github.com/Ficc-ai/ficc/blob/ficc_ml/ml_models/sequence_predictors/flags_20230106.ipynb.\n",
    "This version keeps many analyses and comments from that version and previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58de4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version 1.5.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(\"pandas version\", pd.__version__)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import os, gc, psutil, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e6955a-0d5c-4f23-8406-37e0144bf08a",
   "metadata": {},
   "source": [
    "#### Monitoring memory consumption\n",
    "\n",
    "The best measure of total memory used by the current Python process is unique set size (uss).\n",
    "The number of pages of memory fetched from disk is pageins.\n",
    "See https://stackoverflow.com/questions/938733/total-memory-used-by-python-process and elsewhere for explanations.\n",
    "The _uss()_ function works on my Macbook, but will likely not work on all operating systems.\n",
    "\n",
    "To do: Find out why memory used as reported by the Macbook Activity Monitor is many times the gigabytes reported by Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cda94dd-3e44-4a70-973c-b0a8b2569da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 72 new pageins\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.131661824"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevpageins = 0\n",
    "def uss():\n",
    "    global prevpageins\n",
    "    gc.collect()\n",
    "    info = psutil.Process().memory_full_info()\n",
    "    newpageins = info.pageins\n",
    "    diff = newpageins - prevpageins\n",
    "    if diff > 0:\n",
    "        print(f\"Warning: {diff} new pageins\")\n",
    "        prevpageins = newpageins\n",
    "    uss = info.uss / 1e9 \n",
    "    return uss\n",
    "\n",
    "uss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa692a2-811b-4c2b-8250-bf52c62222da",
   "metadata": {},
   "source": [
    "#### Comments on achieving efficient code\n",
    "\n",
    "Pandas keeps track of different versions of the same dataframe in an efficient way,\n",
    "using memory to store only changes. \n",
    "Dataframes should not be updated in-place, because then other dataframes that share the same memory are changed also,\n",
    "which is undesired behavior.\n",
    "Dataframes should also not be copied, because that increases memory usage dramatically,\n",
    "and is slow.\n",
    "\n",
    "Dataframes are stored with contiguous columns, not contiguous rows.\n",
    "Therefore, \"apply\" for every row of a dataframe is intrinsically slow compared to operations on entire columns.\n",
    "Where possible, avoid using \"apply\" at all.\n",
    "Instead, use operations that work on entire columns of a dataframe.\n",
    "\n",
    "Pandarallel is both slow and memory-intensive.\n",
    "\n",
    "We want to make it easy to release memory used by variables, in particular dataframes. \n",
    "However, memory can be garbage-collected only if all names that refer to it are out of scope.\n",
    "Therefore, we should minimize the number of new dataframe variables, since each one is an alias that may prevent garbage collection.\n",
    "\n",
    "To do: \n",
    "- Find a way to guarantee that all names referring to a given dataframe are out of scope.\n",
    "- Find out with certainty whether doing garbage collection after deleting all aliases for a dataframe is successful in reclaiming memory.\n",
    "- Verify that it is never optimal to use _.copy(_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c11246",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None            # disable warnings about too many changes to a dataframe, but these warnings can still appear\n",
    "pd.options.display.precision = 3\n",
    "pd.options.display.width = 160\n",
    "pd.options.display.max_rows = 300\n",
    "pd.options.display.min_rows = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f86daed-8ecb-453b-96ec-0d4ee9bfc10a",
   "metadata": {},
   "source": [
    "#### Loading data from a local pickle file\n",
    "\n",
    "We download the data manually from a GCP bucket to a local file, then load that into pandas.\n",
    "Depending on garbage collection, loading the data may sometimes seem to use negative memory.\n",
    "\n",
    "This lets us try different ideas in feature engineering and model design far quicker.\n",
    "Just as important, it makes downstream work more pleasant and \n",
    "makes us much more motivated to find and fix errors. \n",
    "<!-- Fast data processing is absolutely crucial, in particular, when a bug causes the Python kernel to crash,\n",
    "and all previous computation in the notebook is lost. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c7302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 1390496 rows from /Users/gil/git/ficc/notebooks/measures_accuracy/gbm_processed_file_0119.pkl using 4.541 gigabytes in 4.673 total gigabytes\n",
      "CPU times: user 7.97 s, sys: 3.13 s, total: 11.1 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "before = uss()\n",
    "\n",
    "prefix = \"/Users/gil/git/ficc/notebooks/measures_accuracy/\"\n",
    "name = \"gbm_processed_file_0119.pkl\"\n",
    "\n",
    "limitation = \"\"\n",
    "path = f\"{prefix}{limitation}{name}\"\n",
    "\n",
    "f = open(path, 'rb')\n",
    "data = pd.read_pickle(f)\n",
    "\n",
    "after = uss()\n",
    "print(f\"\\nLoaded {len(data)} rows from {path} using {after - before:.3f} gigabytes in {after:.3f} total gigabytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f82d44-a258-4257-84ab-c9bd8c64981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['publish_seconds'] = (data.publish_datetime - data.trade_datetime).dt.total_seconds()\n",
    "data['settlement_days'] = (data.settlement_date - data.trade_datetime).dt.total_seconds() / 86400\n",
    "\n",
    "dt = pd.to_datetime(data.trade_datetime).dt\n",
    "data['month'] = dt.month\n",
    "data['day_of_year'] = dt.day_of_year\n",
    "\n",
    "data['hour_of_day'] = dt.hour.astype('category')\n",
    "# print( data.hour_of_day.value_counts().sort_index() )\n",
    "\n",
    "data['weekday'] = dt.day_name().astype('category')\n",
    "# data.weekday.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab9f0c-0706-4e6c-ac67-f327f3e44b9a",
   "metadata": {},
   "source": [
    "#### Making a pandas dataframe smaller\n",
    "\n",
    "The following function reduces memory usage by more than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4e8980-0752-46cc-824b-01174f3ddbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact(data):\n",
    "    ocols = data.select_dtypes(['object']).columns\n",
    "    for col in ocols:\n",
    "        try:\n",
    "            data[col] = data[col].astype('category')\n",
    "        except Exception as e: \n",
    "            print(f\"   *** exception {e} for {col} ***\")   \n",
    "            \n",
    "    fcols = data.select_dtypes(['float']).columns\n",
    "    for col in fcols: \n",
    "        try:\n",
    "            if data[col].abs().max() > 100: continue\n",
    "            if data[col].nunique() > 100: continue\n",
    "            if not data[col].equals(data[col] // 1): continue\n",
    "            # print(f\"converting {col} to int8\")\n",
    "            data[col] = data[col].fillna(-99).astype(np.int8)\n",
    "        except Exception as e: \n",
    "            print(f\"   *** exception {e} for {col} ***\")\n",
    "            \n",
    "    icols = data.select_dtypes('integer').columns\n",
    "    data[icols] = data[icols].apply(pd.to_numeric, downcast='integer')\n",
    "    \n",
    "    fcols = data.select_dtypes('float').columns\n",
    "    data[fcols] = data[fcols].apply(pd.to_numeric, downcast='float')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96e0922-93f2-4b1b-8c7c-6a4cdec520e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compacting 978710 rows\n",
      "   *** exception unhashable type: 'numpy.ndarray' for trade_history ***\n",
      "   *** exception unhashable type: 'numpy.ndarray' for target_attention_features ***\n",
      "CPU times: user 38.1 s, sys: 15.7 s, total: 53.9 s\n",
      "Wall time: 53.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.585923584"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest = 9\n",
    "data = data[data.month >= earliest]\n",
    "print(f\"compacting {len(data)} rows\")\n",
    "%time data = compact(data)\n",
    "uss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36847aeb-408e-4703-9b6c-8ce7d11d0c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 978710 entries, 438685 to 1477105\n",
      "Columns: 284 entries, MSRB_maturity_date to weekday\n",
      "dtypes: bool(35), category(58), datetime64[ns, UTC](4), datetime64[ns](43), float32(77), float64(7), int16(2), int32(5), int64(1), int8(50), object(2)\n",
      "memory usage: 1.5 GB\n",
      "CPU times: user 608 ms, sys: 26.3 ms, total: 634 ms\n",
      "Wall time: 635 ms\n"
     ]
    }
   ],
   "source": [
    "%time data.info(verbose=False, show_counts=True, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9028e67-2f4c-4384-9cb9-7dcc80f910e1",
   "metadata": {},
   "source": [
    "#### Features for supply and demand\n",
    "\n",
    "The _cumsum_ features measure the cumulative volume of each cusip in each direction on each day.\n",
    "To make the cumulative sum start in the morning and increase during the day,\n",
    "we must sort the rows by increasing datetime.\n",
    "Note that sums are in hundreds of dollars, because of _rounded_.\n",
    "To do: Fix the logic here and elsewhere to take into account publish times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac47f5e6-9938-427c-a1da-2a43e4d05455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 s, sys: 519 ms, total: 1.95 s\n",
      "Wall time: 1.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rounded = 100\n",
    "data = data.sort_values(by='trade_datetime', ascending=True).copy()\n",
    "qty = np.round(10**data.quantity / rounded)\n",
    "    \n",
    "data['S_qty'] = (data.trade_type == \"S\") * qty\n",
    "data['P_qty'] = (data.trade_type == \"P\") * qty\n",
    "data['D_qty'] = (data.trade_type == \"D\") * qty\n",
    "\n",
    "g = data.groupby(['day_of_year', 'cusip'], observed=True)\n",
    "data['cumsum_S'] = g.S_qty.cumsum()\n",
    "data['cumsum_P'] = g.P_qty.cumsum()\n",
    "data['cumsum_D'] = g.D_qty.cumsum()\n",
    "data['diff_cumsum'] = data.cumsum_S - data.cumsum_P\n",
    "data['tot_cumsum'] = data.cumsum_S + data.cumsum_P + data.cumsum_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c68f6-aa5f-4b52-b237-790ccfadba8b",
   "metadata": {},
   "source": [
    "#### YCL to refund is meaningless when _called_redemption_type_ is 19, or _refund_date_ is none or in the past\n",
    "\n",
    "The refund date is in the past when _called_redemption_type_ is 19, because these bonds are refunding, not refunded,\n",
    "and _refund_date_ refers to the refund date of the refunded bond.\n",
    "The distributions of the four _ycl_to_refund_ columns look reasonable after these restrictions.\n",
    "However, we find below that _last_real_time_ficc_ycl_to_refund_ has anomalies.\n",
    "\n",
    "To do: Understand bonds with refund dates far in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89e8166-db6b-44ee-ad2c-975bda0c8da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3643\n",
      "3641\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "s = (data.called_redemption_type == 19) & ~data.ficc_ycl_to_refund.isna()\n",
    "print(s.sum())\n",
    "data.loc[s,['ficc_ycl_to_refund']] = np.nan\n",
    "\n",
    "s = (data.called_redemption_type == 19) & ~data.last_ficc_ycl_to_refund.isna()\n",
    "print(s.sum())\n",
    "data.loc[s,['last_ficc_ycl_to_refund']] = np.nan\n",
    "\n",
    "days_to_refund = (data.refund_date - data.settlement_date).dt.days\n",
    "s = (days_to_refund <= 0) & ~data.ficc_ycl_to_refund.isna()\n",
    "print(s.sum())\n",
    "data.loc[s,['ficc_ycl_to_refund']] = np.nan\n",
    "\n",
    "last_days_to_refund = (data.last_refund_date - data.last_settlement_date).dt.days\n",
    "s = (last_days_to_refund <= 0) & ~data.last_ficc_ycl_to_refund.isna()\n",
    "print(s.sum())\n",
    "data.loc[s,['last_ficc_ycl_to_refund']] = np.nan\n",
    "\n",
    "s = data.last_refund_date.isna() & ~data.last_ficc_ycl_to_refund.isna()\n",
    "print(s.sum())\n",
    "data.loc[s,['last_ficc_ycl_to_refund']] = np.nan\n",
    "\n",
    "s = data.refund_date.isna() & ~data.ficc_ycl_to_refund.isna()\n",
    "print(s.sum())\n",
    "data.loc[s,['ficc_ycl_to_refund']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca5d497d-064b-4639-ae19-06081a87decf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(data.trade_date, data.ficc_ycl, s=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8cee6-eda2-4fd1-a4e3-20d59dc1bd54",
   "metadata": {},
   "source": [
    "#### Preprocessing features for interest rates\n",
    "\n",
    "We log-transform columns if needed, create the yield-to-worst label if needed, and check that it is correct.\n",
    "Reminder: \"size\" and \"yield\" are special words in Python, so we cannot write data.yield, and data.size is a scalar, not a column.\n",
    "The columns par_traded and quantity both contain the size of the current trade.\n",
    "Also, we convert all interest rates and spreads to basis points: \n",
    "if the standard deviation before conversion is less than 10, then values are multiplied by 100.\n",
    "\n",
    "The 20 year Treasury rate is above the 30 year rate, because the 20 year bonds are unpopular with investors; see https://www.ustreasuryyieldcurve.com/.\n",
    "To do: Investigate _delta_ycl_ and _real_time_spread_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00ad2718-a875-431f-a3c0-6cf5772e622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "par_traded 149162.93624771383\n",
      "quantity 4.6266853688835585\n",
      "last_size 154690.92254381804\n",
      "last_seconds_ago 1966613.3949357853\n",
      "MSRB_coupon_rate                         float64       0.00   419.90  2000.00\n",
      "yield                                    float32      40.00  35402.72  743530.00\n",
      "current_coupon_rate                      float64       0.00   419.90  2000.00\n",
      "original_yield                           float64       8.00   246.66  1043.50\n",
      "last_yield_spread                        float32    -409.56    57.82  8818.27\n",
      "last_yield                               float64       0.10   352.69  9117.50\n",
      "ficc_ycl                                 float32     252.83   295.46   545.93\n",
      "ficc_ycl_3_month                         float32     270.51   290.06   310.40\n",
      "ficc_ycl_1_month                         float32     272.76   293.33   314.35\n",
      "yield_spread                             float32    -386.99    58.57  7122.56\n",
      "treasury_rate                            float64     342.00   388.70   477.00\n",
      "ficc_treasury_spread                     float32    -217.60   -93.24   174.49\n",
      "t_rate_1                                 float64     460.00   467.98   477.00\n",
      "t_rate_2                                 float64     417.00   428.35   441.00\n",
      "t_rate_3                                 float64     391.00   403.72   422.00\n",
      "t_rate_5                                 float64     361.00   374.99   399.00\n",
      "t_rate_7                                 float64     354.00   370.26   397.00\n",
      "t_rate_10                                float64     342.00   359.79   388.00\n",
      "t_rate_20                                float64     366.00   384.97   414.00\n",
      "t_rate_30                                float64     342.00   363.74   398.00\n",
      "ficc_ycl_to_maturity                     float32     252.83   315.08   545.93\n",
      "ficc_ycl_to_next_call                    float32     252.83   276.06   545.72\n",
      "ficc_ycl_to_par_call                     float32     252.83   276.09   545.72\n",
      "ficc_ycl_to_refund                       float32     252.83   276.31   316.30\n",
      "last_ficc_ycl_to_maturity                float32      16.82   315.29   563.24\n",
      "last_ficc_ycl_to_next_call               float32      -3.74   275.38   542.12\n",
      "last_ficc_ycl_to_par_call                float32      -3.74   275.45   542.12\n",
      "last_ficc_ycl_to_refund                  float32       9.49   274.18   374.64\n",
      "new_corporate_yield                      float32     494.00   529.11   577.00\n",
      "new_ficc_ycl                             float32     252.83   295.47   545.93\n",
      "new_treasury_rate                        float32     342.00   388.04   477.00\n",
      "ytw                                      float32      40.00  35402.72  743530.00\n",
      "CPU times: user 1.47 s, sys: 692 ms, total: 2.16 s\n",
      "Wall time: 2.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.775853568"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for col in ['par_traded', 'quantity', 'last_size', 'last_seconds_ago']:\n",
    "    data[col] = data[col].astype('float64')\n",
    "    avg = np.mean(data[col])\n",
    "    print(col, avg)\n",
    "    if avg > 10:\n",
    "        low = data[col].min()\n",
    "        if low >= 1:\n",
    "            data[col] = np.log10( data[col] )\n",
    "        elif low >= 0:\n",
    "            data[col] = np.log10( data[col] + 1 )\n",
    "        else:\n",
    "            print(f\"   *** minimum value of {col} is {low}\")\n",
    "        \n",
    "if not 'ytw' in data.columns:\n",
    "    data['ytw'] = data['yield']\n",
    "            \n",
    "for col in data.columns:\n",
    "    candidate = \"rate\" in col or \"ycl\" in col or \"ytw\" in col or \"yield\" in col or \"spread\" in col\n",
    "    others = \"state\" in col or \"exists\" in col or \"error\" in col or \"diff\" in col\n",
    "    others = others or \"has_\" in col or \"_preds\" in col or \"_err\" in col or \"_ae\" in col\n",
    "    if candidate and not others:\n",
    "        vals = data[col].astype('float64')\n",
    "        if vals.std() < 10:\n",
    "            vals = vals * 100\n",
    "            data[col] = vals\n",
    "        print( f\"{col:40} {data[col].dtype}    {vals.min():7.2f}  {vals.mean():7.2f}  {vals.max():7.2f}\" )\n",
    "        \n",
    "data['ted_spread'] = (data.t_rate_10 - data.t_rate_2)\n",
    "uss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4437a1-2f6f-4a01-90e9-a8fe4531d1d0",
   "metadata": {},
   "source": [
    "#### Creating new predictors and new targets\n",
    "\n",
    "The general idea is that we want predictors based on the last trade to be consistent with targets:\n",
    "- ideally, both should use real-time yield curve levels (YCLs)\n",
    "- the target should use the categorical _calc_day_cat_ of the last trade (this is the prefix _same_)\n",
    "- further, the target should use the same duration as the last trade (this is the prefix _new_).\n",
    "\n",
    "The prefix _rt_ means real-time and the prefix _dur_ means using the same duration.\n",
    "The column _rt_last_ficc_ycl_ is unreliable because the values of _last_real_time_ficc_ycl_to_XXX_ need to be fixed.\n",
    "The prefixes _last_ and _trans_ use the same _calc_day_cat_, but not the exact same duration for _trans_.\n",
    "\n",
    "Reminder: The values of _calc_day_cat_ are 0, next_call_date; 1, par_call_date; 2, maturity_date; or 3, refund_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ac29a1-7400-4bee-a195-bf56b9ed8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the correlation and MAE between two columns, ignoring NaN values\n",
    "def corrmae(df,u,v):\n",
    "    names = u + \" & \" + v\n",
    "    mae = (df[u] - df[v]).abs().mean()\n",
    "    avg = df[v].mean()\n",
    "    print( f\"{names:>40}:  corr {mycorr(df,u,v):5.3f}   mae {mae:6.2f}\" )\n",
    "\n",
    "# create yield curve levels as of the last trade; use the cutoff to remove outlier real-time values\n",
    "def mklastycl(df, cutoff = 5):\n",
    "    last_ficc_ycl = 0 * df.last_yield_spread\n",
    "    # rt_last_ficc_ycl = 0 * df.last_yield_spread\n",
    "    \n",
    "    trans_ficc_ycl = 0 * df.last_yield_spread          # YCL translated to now for duration now of calc_day_cat for last trade\n",
    "    # rt_trans_ficc_ycl = 0 * df.last_yield_spread\n",
    "    \n",
    "    sub = df.last_calc_day_cat == 0                    # can't make this a loop over [0,1,2,3]\n",
    "    last_ficc_ycl[sub]     = df[sub].last_ficc_ycl_to_next_call\n",
    "    # rt_last_ficc_ycl[sub]  = df[sub].last_real_time_ficc_ycl_to_next_call\n",
    "    trans_ficc_ycl[sub]    = df[sub].ficc_ycl_to_next_call\n",
    "    # rt_trans_ficc_ycl[sub] = df[sub].real_time_ficc_ycl_to_next_call\n",
    "\n",
    "    sub = df.last_calc_day_cat == 1\n",
    "    last_ficc_ycl[sub]     = df[sub].last_ficc_ycl_to_par_call\n",
    "    # rt_last_ficc_ycl[sub]  = df[sub].last_real_time_ficc_ycl_to_par_call\n",
    "    trans_ficc_ycl[sub]    = df[sub].ficc_ycl_to_par_call\n",
    "    # rt_trans_ficc_ycl[sub] = df[sub].real_time_ficc_ycl_to_par_call\n",
    "\n",
    "    sub = df.last_calc_day_cat == 2\n",
    "    last_ficc_ycl[sub]     = df[sub].last_ficc_ycl_to_maturity\n",
    "    # rt_last_ficc_ycl[sub]  = df[sub].last_real_time_ficc_ycl_to_maturity    # this is where the error is\n",
    "    trans_ficc_ycl[sub]    = df[sub].ficc_ycl_to_maturity\n",
    "    # rt_trans_ficc_ycl[sub] = df[sub].real_time_ficc_ycl_to_maturity\n",
    "\n",
    "    sub = df.last_calc_day_cat == 3\n",
    "    last_ficc_ycl[sub]     = df[sub].last_ficc_ycl_to_refund\n",
    "    # rt_last_ficc_ycl[sub]  = df[sub].last_real_time_ficc_ycl_to_refund\n",
    "    trans_ficc_ycl[sub]    = df[sub].ficc_ycl_to_refund\n",
    "    # rt_trans_ficc_ycl[sub] = df[sub].real_time_ficc_ycl_to_refund\n",
    "\n",
    "    # fix errors in rt_last_ficc_ycl approximately    \n",
    "    # tofix = (rt_last_ficc_ycl - last_ficc_ycl).abs() >= cutoff\n",
    "    # rt_last_ficc_ycl[tofix] = last_ficc_ycl[tofix] \n",
    "    \n",
    "    return last_ficc_ycl, trans_ficc_ycl\n",
    "\n",
    "# create alternative predictors; remember that last_yield_spread and last_ficc_ycl are not real-time\n",
    "def mkcols(data):\n",
    "    data['last_ytw']   = data.last_yield_spread + data.last_ficc_ycl        # reconstructing the MSRB labels from non-real-time columns\n",
    "    # data['rt_last_ys'] = data.last_ytw - data.rt_last_ficc_ycl              # real-time yield spread of the last trade; error propagates here\n",
    "\n",
    "    data['adj_last_ytw']        = data.last_ytw - data.last_ficc_ycl    + data.trans_ficc_ycl               # not real-time, categorical calc day\n",
    "    # data['rt_adj_last_ytw']     = data.last_ytw - data.rt_last_ficc_ycl + data.rt_trans_ficc_ycl            # the error propagates here\n",
    "    data['dur_adj_last_ytw']    = data.last_ytw - data.last_ficc_ycl    + data.new_ficc_ycl \n",
    "    # data['rt_dur_adj_last_ytw'] = data.last_ytw - data.rt_last_ficc_ycl + data.new_real_time_ficc_ycl     # the error propagates here\n",
    "\n",
    "    # create alternative targets\n",
    "    data['new_ys']     = data.ytw - data.new_ficc_ycl                       # using last_duration but not real-time; has error from new_ficc_ycl\n",
    "    # data['rt_new_ys']  = data.ytw - data.new_real_time_ficc_ycl           # should be the best: real-time and using last_duration!\n",
    "\n",
    "    data['same_ys']    = data.ytw - data.trans_ficc_ycl                     # using categorical last calc date\n",
    "    # data['rt_same_ys'] = data.ytw - data.rt_trans_ficc_ycl\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be68e038-a8e1-484b-a36d-b1f31a0892c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['last_ficc_ycl'], data['trans_ficc_ycl'] = mklastycl(data)\n",
    "data = mkcols(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017df55-6937-4a16-bb9d-aafe950265bd",
   "metadata": {},
   "source": [
    "The data file from September 12 has many fewer columns than earlier files.\n",
    "This is fixed in the September 27 file and later. However, that file leads to worse accuracy,\n",
    "despite similar preprocessing in this notebook.\n",
    "To do: Investigate why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d1386-eaa2-486d-9d08-4d9f71a9c906",
   "metadata": {},
   "source": [
    "#### Removing duplicate columns\n",
    "\n",
    "We drop some columns if they are confirmed to be exact duplicates. \n",
    "To do: \n",
    "- Check efficiently for every pair of columns whether they have identical values. \n",
    "In principle, this can be done with data.T.drop_duplicates().T, but there are problems in practice, including but not limited to inefficiency.\n",
    "- Remove columns that are duplicates but with different types, or with different numerical precision, such as the coupon columns.\n",
    "- Write code that computes mutual information efficiently, to identify columns that contain the same information\n",
    "but coded with different values.\n",
    "- Fix errors in the types of the coupon columns, and in \"dropdupcol(data, 'coupon', 'MSRB_coupon_rate')\".\n",
    "\n",
    "MSRB_coupon_rate and coupon should be identical, but have different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e8c78c2-ee3a-4301-b510-b76deac8f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropdupcol(df,a,b):\n",
    "    if not a in df.columns:\n",
    "        print(\"absent column\", a)\n",
    "        return df\n",
    "    if not b in df.columns:\n",
    "        print(\"absent column\", b)\n",
    "        return df    \n",
    "    if df[a].equals(df[b]):\n",
    "        print(f\"dropping column {b} and keeping identical {a}\")\n",
    "        df = df.drop([b], axis=1)\n",
    "    else:\n",
    "        print(f\"\\ncolumns {a} and {b} are different:\")\n",
    "        print(df[a].value_counts(dropna=False)[0:5], \"\\n\", df[b].value_counts(dropna=False)[0:5])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8496fef3-8602-494e-b7c0-6c457fdf91cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absent column issue_key_copy\n",
      "dropping column callable and keeping identical is_callable\n",
      "dropping column called and keeping identical is_called\n",
      "dropping column msrb_cusip and keeping identical cusip\n",
      "\n",
      "columns has_zero_coupons and zerocoupon are different:\n",
      "False    966650\n",
      "True      12060\n",
      "Name: has_zero_coupons, dtype: int64 \n",
      " False    966477\n",
      "True      12233\n",
      "Name: zerocoupon, dtype: int64\n",
      "CPU times: user 864 ms, sys: 367 ms, total: 1.23 s\n",
      "Wall time: 1.23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.749004288"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = dropdupcol(data, 'issue_key', 'issue_key_copy')\n",
    "data = dropdupcol(data, 'is_callable', 'callable')\n",
    "data = dropdupcol(data, 'is_called', 'called')\n",
    "data = dropdupcol(data, 'cusip', 'msrb_cusip')\n",
    "data = dropdupcol(data, 'has_zero_coupons', 'zerocoupon') \n",
    "uss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3212f35-c8a9-4d93-ba44-9f23de23a075",
   "metadata": {},
   "source": [
    "To do: Figure out why the coupon columns are not identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e3e8a-000a-4bad-b994-036048b0b6bf",
   "metadata": {},
   "source": [
    "#### Letting the model learn the effect of changes in the direction of the trade\n",
    "\n",
    "_ttypes_ is the cross-product of the direction (D, P, or S) of the last trade and the target trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c952f3d7-5278-42f3-8058-58e1cb035ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(a,b):\n",
    "    return (a.astype(str) + b.astype(str)).astype('category')\n",
    "\n",
    "def mkttypes(df):\n",
    "    df['ttypes'] = concat(df.last_trade_type, df.trade_type)\n",
    "    return df\n",
    "\n",
    "data = mkttypes(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ca959-de0d-4298-833a-8b36d98f59a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### A few additional predictors\n",
    "\n",
    "The existing field _when_issued_ is almost identical with _new_issue_. \n",
    "The exceptions include trades in a refunding bond, cusip 455054BH8, and we know that these bonds are complicated.\n",
    "To do: \n",
    "- Write a function that automatically analyzes cells with small counts in a cross-tabulation.\n",
    "- Add a team member's answers why _when_issued_ and _new_issue_ are not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bab8bc0-8760-4961-9152-7f2395abb882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when_issued   False  True \n",
      "new_issue                 \n",
      "False        971226      0\n",
      "True              0   7484 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data['par_issue'] = data.issue_price == 100\n",
    "data['prev_trade_today'] = (data.last_seconds_ago > 0) & (data.last_seconds_ago <= 4.5)\n",
    "\n",
    "if 'is_lop_or_takedown' in data.columns:\n",
    "    data['is_takedown'] = data.is_lop_or_takedown & (data.dollar_price < data.issue_price)\n",
    "    data['is_lop'] = data.is_lop_or_takedown & (data.dollar_price == data.issue_price)\n",
    "\n",
    "if 'primary_market_settlement_date' in data.columns:\n",
    "    data['new_issue'] = data.trade_date < data.primary_market_settlement_date\n",
    "    print( pd.crosstab(data.new_issue, data.when_issued), \"\\n\" )\n",
    "    data['days_from_issue'] = (data.trade_date - data.primary_market_settlement_date).dt.days\n",
    "    \n",
    "mindays = 10**data.days_to_maturity\n",
    "earlier = (data.days_to_call > 0) & (10**data.days_to_call < mindays)\n",
    "mindays[earlier] = 10**data.days_to_call\n",
    "earlier = (data.days_to_refund > 0) & (10**data.days_to_refund < mindays)\n",
    "mindays[earlier] = 10**data.days_to_refund\n",
    "data['mindays'] = mindays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71774c6d-9e79-4ae9-9678-4efc14f99cbf",
   "metadata": {},
   "source": [
    "#### Dropping constant columns\n",
    "\n",
    "Next, we drop all columns that are constant. \n",
    "The argument _dropna=False_ for the method _nunique_ allows NaN to be a possible unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2922fbcb-be3a-4383-be99-7c4663ffcebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   *** exception unhashable type: 'numpy.ndarray' for trade_history ***\n",
      "   *** exception unhashable type: 'numpy.ndarray' for target_attention_features ***\n",
      "CPU times: user 7.31 s, sys: 2.56 s, total: 9.87 s\n",
      "Wall time: 9.87 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.757073408"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for col in data.columns:\n",
    "    try: \n",
    "        if data[col].nunique(dropna=False) <= 1:\n",
    "            # print(col)\n",
    "            data = data.drop(col, axis=1)\n",
    "    except Exception as e: \n",
    "        print(f\"   *** exception {e} for {col} ***\")\n",
    "uss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee7f3b-3f60-4d1d-9371-7102aa389580",
   "metadata": {},
   "source": [
    "#### Fixing data types\n",
    "\n",
    "We make sure that dates and times have the right type. To do: Make all include an explicit timezone..\n",
    "\n",
    "To do: Identify and fix all remaining erroneous types, and warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c2296be-5d43-4e82-8afa-8c5899ec0486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   *** exception Cannot cast object dtype to datetime64[ns] for time_of_trade ***\n",
      "   *** exception Cannot cast object dtype to datetime64[ns] for publish_time ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4p/6gk1pj4j1439gxdnw_vb8prw0000gn/T/ipykernel_59685/455803093.py:5: FutureWarning: Using .astype to convert from timezone-aware dtype to timezone-naive dtype is deprecated and will raise in a future version.  Use obj.tz_localize(None) or obj.tz_convert('UTC').tz_localize(None) instead\n",
      "  data[col] = data[col].astype(timetype)\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    timetype = 'datetime64[ns]'\n",
    "    if col.startswith(\"time\") or col.endswith(\"time\") or col.endswith(\"date\"):\n",
    "        try:\n",
    "            data[col] = data[col].astype(timetype)\n",
    "            # print(col)\n",
    "        except Exception as e: \n",
    "            print(f\"   *** exception {e} for {col} ***\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb5de315-716e-4cac-b12c-8f7bf274c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSINGVAL = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3224620-937d-488c-9efc-aa762258530d",
   "metadata": {},
   "source": [
    "Columns with exactly two values are converted into Booleans.\n",
    "To do: Look at columns with two truth values, and missing values. \n",
    "Convert some to Boolean, and make others into one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19e69b8b-70d6-4da1-9611-6202cf037aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   *** exception unhashable type: 'numpy.ndarray' for trade_history ***\n",
      "   *** exception unhashable type: 'numpy.ndarray' for target_attention_features ***\n",
      "CPU times: user 2.32 s, sys: 522 ms, total: 2.84 s\n",
      "Wall time: 2.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.796141056"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for col in data.columns:\n",
    "    try:\n",
    "        if data[col].nunique(dropna=False) == 2:\n",
    "            # print(col)\n",
    "            data[col] = data[col].astype('bool')\n",
    "    except Exception as e: \n",
    "        print(f\"   *** exception {e} for {col} ***\")    \n",
    "uss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159ac9c-bf42-4da6-86bc-85a3f979740c",
   "metadata": {},
   "source": [
    "Many numerical fields are actually categorical, so we convert them.\n",
    "Dictionaries explaining the values of categorical fields are in https://docs.google.com/spreadsheets/d/172OKmkParOjg9r-N4qWjoTdPxQIZoJ1z/edit#gid=655976637.\n",
    "For example, \"use of proceeds = 31\" means \"Lifecare/retirement centers.\"\n",
    "To do: Design a more sophisticated way to identify which features are categorical, versus numerical.\n",
    "\n",
    "Note that in the 12/28 data file, some values of _last_calc_day_cat_ are invalid. This is a bug that was fixed months ago.\n",
    "The value -99 is the replacement for _np.nan_ used in the datatype _int8_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7d1eea8-d2ad-4595-89a2-2ab53e32c004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2     560425\n",
       " 0     381297\n",
       " 3      36404\n",
       " 1        466\n",
       "-99       118\n",
       "Name: last_calc_day_cat, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.last_calc_day_cat.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d9c2c24-dee3-4018-b489-419ff644ce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.32 s, sys: 749 ms, total: 3.07 s\n",
      "Wall time: 3.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.813024768"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "minvalues = 25\n",
    "\n",
    "candidates = data.select_dtypes(include=[np.number])\n",
    "exclude = { 'de_minimis_threshold', 'num_prev_messages', 'days_to_settle', 'last_yield_spread', 'month'}\n",
    "candidates = set(candidates.columns) - exclude\n",
    "\n",
    "for col in candidates:\n",
    "    nun = data[col].nunique(dropna=False)\n",
    "    if nun < minvalues and not \"refund\" in col and not \"ycl\" in col and not \"price\" in col and not \"rate\" in col \\\n",
    "                and not \"count\" in col and not \"days\" in col:\n",
    "        # print(col, nun)\n",
    "        data[col] = data[col].astype('category')\n",
    "uss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc2501-c874-4e26-9ece-428bd60241bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Features to capture changes in a bond's characteristics\n",
    "\n",
    "Changes in yield curve level have some slight predictive power.\n",
    "To do: Find out why, without \".copy()\" below, \"PerformanceWarning: DataFrame is highly fragmented\" occurs even though this warning has been turned off.\n",
    "\n",
    "using the 360/30 convention.\n",
    "This feature turns out to be an important predictor.\n",
    "Important: In the 12/16/22 data file, last duration is measured in days.\n",
    "In the 12/28/22 data file, last duration is missing, so I calculate it approximately, using calendar days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "576e0523-4fe2-42b2-ac62-016b9a6d5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.copy()\n",
    "data['diff_maturity'] = data.maturity_date != data.last_maturity_date\n",
    "data['diff_next_call'] = data.next_call_date != data.last_next_call_date\n",
    "data['diff_par_call'] = data.par_call_date != data.last_par_call_date\n",
    "data['diff_refund'] = data.refund_date != data.last_refund_date\n",
    "\n",
    "data['diff_ycl_to_maturity'] = data.ficc_ycl_to_maturity - data.last_ficc_ycl_to_maturity\n",
    "data['diff_ycl_to_next_call'] = data.ficc_ycl_to_next_call - data.last_ficc_ycl_to_next_call\n",
    "data['diff_ycl_to_par_call'] = data.ficc_ycl_to_par_call - data.last_ficc_ycl_to_par_call\n",
    "data['diff_ycl_to_refund'] = data.ficc_ycl_to_refund - data.last_ficc_ycl_to_refund\n",
    "\n",
    "data['diff_size'] = data.quantity - data.last_size\n",
    "\n",
    "data['issuer'] = data.cusip.str[:6].astype('category')\n",
    "data['last_duration'] = (data.last_calc_date - data.last_settlement_date).dt.days\n",
    "data['yrs_duration'] = np.round(data.last_duration / 365.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af60612-ffbc-4efa-8149-03ce92240875",
   "metadata": {},
   "source": [
    "#### Creating features for absolute values\n",
    "\n",
    "If a numerical feature is predictive, then its unsigned value may be predictive also.\n",
    "If a feature is flagged as a leaker, then code below flags its _abs__ version also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ba28cbf-b98c-4c81-9c18-e78b2524f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 3 new pageins\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.986584576"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESH = 0.001\n",
    "ds = data.select_dtypes(include=[np.number])\n",
    "thresh = 0\n",
    "for col in ds.columns:\n",
    "    newcol = 'abs_' + col\n",
    "    if newcol in set(data.columns): continue\n",
    "    vals = data[col]\n",
    "    # vals = vals[vals != MISSINGVAL]\n",
    "    if ((vals < 0).mean() > THRESH) and ((vals > 0).mean() > THRESH):\n",
    "        # print(newcol)\n",
    "        data[newcol] = np.abs(vals)\n",
    "uss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b294a203-b38b-4894-8b02-2f89c79ee4fc",
   "metadata": {},
   "source": [
    "#### Functions to evaluate and display the accuracy of a model\n",
    "\n",
    "For _maeval_, _extra_ is a list of additional predictors.\n",
    "The dataframe columns added by _maeval_ persist after this function finishes,\n",
    "in order to enable comparisons between the predictions of different models.\n",
    "\n",
    "The MAE printed by _drawpoints_ is for dealer-dealer trades of \\$500,000 or more, \n",
    "which are what we call \"true mid.\"\n",
    "To increase the sample size, we can optionally include dealer-sells trades,\n",
    "which empirically have slightly smaller MAE than dealer-dealer trades.\n",
    "\n",
    "To do: Fix missing legends on extreme points in the plot from _drawpoints_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b62c74b9-5ef8-4c7e-b799-8f59351c15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column \"name\" if needed, then assign values to it for certain rows\n",
    "def extend(df, name, rows, vals):\n",
    "    assert len(df) == len(rows), \"*** len(df) != len(rows)\"\n",
    "    if len(vals) == len(df): \n",
    "        vals = vals[rows]\n",
    "    assert len(vals) == np.sum(rows), \"*** len(vals) != np.sum(rows)\"\n",
    "    \n",
    "    if not name in df.columns: \n",
    "        df[name] = 0.0\n",
    "    df.loc[rows,name] = vals\n",
    "    return\n",
    "\n",
    "# extend certain rows of a dataframe with predicted values and errors\n",
    "def maeval(df, rows, model, label, extra=[], minus=[]):\n",
    "    print(np.sum(rows))\n",
    "\n",
    "    dfp = model.predict( gbmprep(df[rows], extra, minus) )\n",
    "    extend(df, label + \"_preds\", rows, dfp )\n",
    "\n",
    "    delta = df.loc[rows,label] - dfp\n",
    "    extend(df, label + \"_err\", rows, delta )\n",
    "    \n",
    "    da = delta.abs()\n",
    "    extend(df, label + \"_ae\", rows, da )\n",
    "\n",
    "    n = len(da)\n",
    "    base = f\"\\n{label} {n} {extra} bias {delta.mean():5.2f}\\t MAE {da.mean():5.2f} +/- {da.std():.2f}\"\n",
    "    print( base + f\" ({da.std()/np.sqrt(n):.2f})\\t median {da.median():5.2f}\" )\n",
    "    return df\n",
    "\n",
    "threshold = 2.5e6\n",
    "directions = ['D']\n",
    "\n",
    "# show predicted versus actual, and trades with the largest value of the error metric \"sortby\"\n",
    "# label should be the column name for true values, also called the target\n",
    "def drawpoints(df, rows, label, showplot=True, sortby=\"\"):\n",
    "    df = df[rows]\n",
    "    label_preds = label + \"_preds\"\n",
    "    label_ae = label + \"_ae\"\n",
    "        \n",
    "    # keep = (10**df.quantity >= threshold/5)    # removes too many rows due to imprecise arithmetic\n",
    "    keep = (10**df.quantity > threshold/5 - 1)\n",
    "    # keep = (df.par_traded >= threshold/5)\n",
    "    keep = keep & df.trade_type.isin(directions)\n",
    "    df = df[keep]\n",
    "    \n",
    "    if label   == 'new_ys':       ytw_preds = df[label_preds] + df.new_ficc_ycl\n",
    "    elif label == 'same_ys':      ytw_preds = df[label_preds] + df.trans_ficc_ycl\n",
    "    elif label == 'diff_ys':      ytw_preds = df[label_preds] + df.new_ficc_ycl + df.last_yield_spread\n",
    "    elif label == 'yield_spread': ytw_preds = df[label_preds] + df.ficc_ycl\n",
    "    elif label == 'ytw':          ytw_preds = df[label_preds]\n",
    "    else: ytw_preds = df.ytw\n",
    "    \n",
    "    ytw_ae = (df.ytw - ytw_preds).abs().mean()\n",
    "    \n",
    "    r, g, b = colors.to_rgb('red')\n",
    "    w = np.minimum( np.array(10**df.quantity), threshold)\n",
    "    opacity = w / threshold\n",
    "    color = [(r, g, b, alpha) for alpha in opacity]\n",
    "\n",
    "    if showplot:\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.scatter(df[label], df[label_preds], s=5, c=color)\n",
    "\n",
    "    da = df[label_ae]\n",
    "    n = len(da)\n",
    "    print( f\"\\nLarge {directions} n={n}\\t {label} MAE = {da.mean():.2f} +/- \"\\\n",
    "          + f\"{da.std():.2f} ({da.std()/np.sqrt(n):.2f}) median {da.median():.2f}     YTW MAE = {ytw_ae:.2f}\" )\n",
    "    if sortby == \"\": \n",
    "        sortby = label_ae\n",
    "        name = label\n",
    "    else:\n",
    "        name = sortby\n",
    "    kern = 60 + len(name)*7\n",
    "\n",
    "    top = df.sort_values(by=[sortby], ascending=False).iloc[:100,:]\n",
    "    top = top.drop_duplicates(['issuer'])\n",
    "\n",
    "    for (bond, d, x, y, lastytw, ytw, err, lastdp, dp, side, lastside, days, lastys, back, lastsize, nowsize, n) in \\\n",
    "                zip( top.cusip, top.trade_datetime, top[label], top[label_preds], top.last_ytw, top.ytw, top[sortby], \\\n",
    "                     top.last_dollar_price, top.dollar_price, top.trade_type, top.last_trade_type, top.last_duration, \\\n",
    "                     top.last_yield_spread, top.last_seconds_ago, top.last_size, top.par_traded, range(100) ):\n",
    "        if n >= 5: break\n",
    "        seconds_ago = 10**back\n",
    "        if seconds_ago > 43200:\n",
    "            ago = str(int(np.ceil(seconds_ago / 86400))) + \"d\"\n",
    "        else:\n",
    "            ago = str(int(np.floor(seconds_ago / 60))) + \"min\"\n",
    "      \n",
    "        print( f\"{bond:9} {d:%m-%d}  back {ago:>6}: {10**lastsize/1000:5.0f}K {lastside:1}{lastytw:4.0f} ${lastdp:6.2f} dur {days:5.0f} \" \\\n",
    "              + f\"ys {lastys:4.0f}  now: {10**nowsize/1000:5.0f}K {side:1}{ytw:4.0f} ${dp:6.2f}  true {x:7.2f} {y:7.2f} diff {x-y:7.2f}\" )\n",
    "                \n",
    "        if showplot:\n",
    "            plt.scatter(x,y, s=40, c = 'green')\n",
    "            if (x < y): \n",
    "                plt.annotate(name + \" \" + bond, (x-kern,y-2.5))\n",
    "            else:\n",
    "                plt.annotate(name + \" \" + bond, (x+10,y-2.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764ec72-dec8-404c-874b-07e5f5eaa2a5",
   "metadata": {},
   "source": [
    "#### Features not to use\n",
    "\n",
    "Print a representative value for columns that have discrete values.\n",
    "Do not use features with more than _maxdiscrete_ discrete values.\n",
    "To do: Design a way to get predictive power from high-cardinality discrete features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03b6c1a2-f11a-45b6-ad03-a248ec960517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'series_id', 'series_name', 'cusip', 'additional_project_txt', 'use_of_proceeds_supplementary', 'project_name', 'issue_text', 'escrow_obligation_agent', 'time_of_trade', 'issuer', 'instrument_primary_name', 'ice_organization_id', 'publish_time', 'organization_primary_name', 'security_description'}\n"
     ]
    }
   ],
   "source": [
    "maxdiscrete = 70\n",
    "TOOMANY = { 'ice_organization_id' }\n",
    "\n",
    "for col in data.select_dtypes(include='category').columns:\n",
    "    nun = data[col].nunique()\n",
    "    vc = data[col].value_counts(dropna=False)\n",
    "    vals = vc.index.to_numpy()\n",
    "    if nun >= 3:\n",
    "        third = vals[2]\n",
    "    else:\n",
    "        third = vals[0]\n",
    "    # print(f\"{col:32s} {nun:10}   {str(third):20s}\")\n",
    "    if nun >= maxdiscrete: TOOMANY = TOOMANY | {col}\n",
    "print(TOOMANY)\n",
    "\n",
    "BASIC = { 'calc_date', 'calc_day_cat', 'calc_date_month', 'days_to_calc', 'yrs_to_calc', 'last_rtrs_control_number', \\\n",
    "          'duration', 'status', 'floor', 'scary', 'spread', 'calc_price', 'trade_history', 'rough' }\n",
    "\n",
    "TARGETS = {'yield', 'ytw', 'yield_spread', 'ys', 'same_ys', 'new_ys', \n",
    "           'maturity_ys', 'ys_at_maturity', 'call_ys', 'ficc_ycl', 'delta', 'delta_ycl', \\\n",
    "           'dollar_price', 'price_to_maturity', 'price_to_next_call', 'price_to_par_call' }\n",
    "\n",
    "def mkleakers(TARGETS):\n",
    "    BASE = BASIC | TARGETS\n",
    "    EXTENDED = BASE\n",
    "\n",
    "    for col in BASE: EXTENDED = EXTENDED | { \"rt_\" + col }\n",
    "    for col in BASE: EXTENDED = EXTENDED | { \"real_time_\" + col }\n",
    "    for col in BASE: EXTENDED = EXTENDED | { \"diff_\" + col }\n",
    "    for col in BASE: EXTENDED = EXTENDED | { col + \"_diff\" }\n",
    "    for col in BASE: EXTENDED = EXTENDED | { col + \"_ae\" }\n",
    "    \n",
    "    BASE = EXTENDED\n",
    "    for col in BASE: EXTENDED = EXTENDED | { col + \"_preds\" }\n",
    "    for col in BASE: EXTENDED = EXTENDED | { col + \"_err\" }\n",
    "    for col in BASE: EXTENDED = EXTENDED | { col + \"_ae\" }\n",
    "\n",
    "    BASE = EXTENDED\n",
    "    for col in BASE: EXTENDED = EXTENDED | { \"abs_\" + col }\n",
    "    return EXTENDED\n",
    "\n",
    "def gbmprep(df, plus, minus):\n",
    "    LEAKERS = mkleakers(TARGETS)\n",
    "    USECOLS = set(df.select_dtypes(include=['category','bool','number']).columns) - (LEAKERS | TOOMANY)\n",
    "    return df[ list( ( USECOLS | set(plus) ) - set(minus) ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421474c-c034-4438-b163-5cdc18e2e1e9",
   "metadata": {},
   "source": [
    "#### LightGBM benchmark models\n",
    "\n",
    "We use LightGBM for exploration, because it is fast.\n",
    "This can reveal whether some predictors are obvious leakers,\n",
    "and whether a neural network is likely to provide decent accuracy.\n",
    "_myLGBM_ has hyperparameters that informally balance between underfitting and overfitting for this domain.\n",
    "Different random seed values can give models with accuracies that vary by more than one basis point.\n",
    "Subsampling guarantees randomness in training even with small training sets.\n",
    "\n",
    "The choice of random seed influences strongly the accuracy achieved by a single LightGBM model.\n",
    "To reduce this variability, we train an ensemble of multiple models.\n",
    "With _n_ = 4 models, the standard error should be reduced by 50\\%,\n",
    "and by 68\\% with 10 models.\n",
    "By training in parallel, the time to train 10 models is only about 3x the time for one model, on my Macbook M1.\n",
    "\n",
    "Importance plots based on gain are more fine-grained, \n",
    "and agree better with intuition about the relative predictive power provided by different features.\n",
    "\n",
    "#### Splitting the data into training and testing sets\n",
    "\n",
    "For November 2022 as test set, previous months are used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddb92a70-b01a-4a3e-80b6-a7360871f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "defaultdepth = 8\n",
    "defaultseed = 77\n",
    "defaultloss = 'mae'\n",
    "\n",
    "def myLGBM(seed = defaultseed, depth = defaultdepth, loss = defaultloss):\n",
    "    return LGBMRegressor(max_depth=depth, num_leaves=depth*10, n_estimators=depth*30, objective=loss, verbosity=-1, \\\n",
    "                        subsample = 0.5, subsample_freq = 10, random_state = seed) \n",
    "\n",
    "def mkensemble(n = 10, seed = defaultseed, depth = defaultdepth, loss = defaultloss):\n",
    "    regressors = []\n",
    "    for j in range(0,n):\n",
    "        regressors = regressors + [( 'm'+str(j), myLGBM(seed+j, depth, loss) )]\n",
    "    njobs = 4\n",
    "    return VotingRegressor( regressors, n_jobs=njobs, verbose=False )\n",
    "\n",
    "def traintest(df, TARGET, n=3, seed = defaultseed, depth = defaultdepth, loss = defaultloss, extra=[], minus=[], showplot=False):\n",
    "    global TARGETS\n",
    "    TARGETS = TARGETS | { TARGET }\n",
    "    \n",
    "    train_rows = (df.month == 12) & (df[TARGET] != MISSINGVAL)\n",
    "    test_rows = (df.month >= 1) & (df[TARGET] != MISSINGVAL)\n",
    "\n",
    "    ens = mkensemble(n, seed, depth)\n",
    "    print(f\"Training {n} models with depth {depth} on {np.sum(train_rows)} examples and evaluating on {np.sum(test_rows)} examples\")\n",
    "\n",
    "    ens.fit( gbmprep(df[train_rows], extra, minus), df.loc[train_rows,TARGET] )\n",
    "    uss()\n",
    "\n",
    "    maeval(df, train_rows, ens, TARGET, extra, minus)\n",
    "    maeval(df, test_rows, ens, TARGET, extra, minus)\n",
    "    drawpoints(df, test_rows, TARGET, showplot)     \n",
    "    return ens\n",
    "\n",
    "def myplotimportance(model, nfeatures = 30):\n",
    "    if isinstance( model, LGBMRegressor ): \n",
    "        m = model\n",
    "    elif isinstance( model.estimators_[0], LGBMRegressor ): \n",
    "        m = model.estimators_[-1]\n",
    "    else: \n",
    "        print(\"*** not a valid model\")\n",
    "    lightgbm.plot_importance(m, importance_type=\"gain\", precision=0, ignore_zero=False,\\\n",
    "                             max_num_features=nfeatures, figsize=(12,np.floor(nfeatures/6)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a4622-d37e-4702-b60e-cbd78bb89f33",
   "metadata": {},
   "source": [
    "#### Predicting new yield spread\n",
    "\n",
    "This should be the target that we can predict with best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87b9964e-c6cc-4e1a-a403-ad821d4690ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn [29], line 20\u001b[0m, in \u001b[0;36mtraintest\u001b[0;34m(df, TARGET, n, seed, depth, loss, extra, minus, showplot)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m TARGETS\n\u001b[1;32m     18\u001b[0m TARGETS \u001b[38;5;241m=\u001b[39m TARGETS \u001b[38;5;241m|\u001b[39m { TARGET }\n\u001b[0;32m---> 20\u001b[0m train_rows \u001b[38;5;241m=\u001b[39m (\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonth\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m12\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[TARGET] \u001b[38;5;241m!=\u001b[39m MISSINGVAL)\n\u001b[1;32m     21\u001b[0m test_rows \u001b[38;5;241m=\u001b[39m (df\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[TARGET] \u001b[38;5;241m!=\u001b[39m MISSINGVAL)\n\u001b[1;32m     23\u001b[0m ens \u001b[38;5;241m=\u001b[39m mkensemble(n, seed, depth)\n",
      "File \u001b[0;32m~/base/lib/python3.9/site-packages/pandas/core/generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5901\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5902\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5903\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5904\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5905\u001b[0m ):\n\u001b[1;32m   5906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'month'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TARGET = 'new_ys'\n",
    "nysmodel = traintest(data, TARGET, n = 1)\n",
    "myplotimportance(nysmodel,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f401533-4dd4-4867-92fd-a5c0f310fa36",
   "metadata": {},
   "source": [
    "As discussed in email, when the label is _new_ys_ then the predicted YTW is simply _new_ys_preds + new_ficc_ycl_.\n",
    "Because _new_ys_ is based on _last_calc_date_, no prediction of the target calc date is needed in order to obtain the predicted YTW.\n",
    "The function _drawpoints_ above confirms that MAE when predicting _ytw_ is the same as MAE when predicting _new_ys_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a7e032d-06e5-4f64-b718-093ab50eaa18",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'new_ys_preds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mytw_preds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnew_ys_preds \u001b[38;5;241m+\u001b[39m data\u001b[38;5;241m.\u001b[39mnew_ficc_ycl\n",
      "File \u001b[0;32m~/base/lib/python3.9/site-packages/pandas/core/generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5901\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5902\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5903\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5904\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5905\u001b[0m ):\n\u001b[1;32m   5906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'new_ys_preds'"
     ]
    }
   ],
   "source": [
    "data['ytw_preds'] = data.new_ys_preds + data.new_ficc_ycl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84e3a4-e2cf-47e0-a654-5e8dd9a5ffc6",
   "metadata": {},
   "source": [
    "#### Trying to improve _calc_date_\n",
    "\n",
    "Although _calc_date_ is not needed in order to predict YTW, it is interesting,\n",
    "and it may be needed in order to predict dollar price.\n",
    "\n",
    "Our old function to guess the calc date of the current trade is _get_calc_date_.\n",
    "An improved version is _alt_calc_date_.\n",
    "The return value _code_ is used to understand errors in each alternative output.\n",
    "The function _fast_calc_date_ has identical logic but is perhaps 1000 times faster,\n",
    "because it operates on columns instead of on rows.\n",
    "\n",
    "_basic_yield_ is the interest that accrues annually for a bond.\n",
    "If the bond has a coupon, then this is the basic yield.\n",
    "If the bond is callable at compound accreted value, i.e., interest is deferred and accumulated,\n",
    "then _basic_yield_ is the original yield of the bond.\n",
    "\n",
    "EPSILON is the tolerance for when the current yield is equal to the interest that accrues, so the bond is priced at par.\n",
    "This tolerance is set tight, at 5% of one basis point.\n",
    "In this case, _calc_date_ is indeterminate because it can equally well be the maturity date or the call date.\n",
    "Therefore we set the estimated calc date to be the same as the calc date in the data,\n",
    "because it is not an error if the estimated calc date is the other one of maturity date and call date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f0e1f7-65a1-44fc-b0a7-c4c9513fe01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calc_date(row):\n",
    "    if row.is_called:\n",
    "        return row.refund_date, 10\n",
    "    elif row.is_called == False and row.is_callable is False:\n",
    "        return row.maturity_date, 11\n",
    "    else:\n",
    "        cat = row.last_calc_day_cat\n",
    "        if cat == 0:\n",
    "            return row.next_call_date, 12\n",
    "        elif cat == 1:\n",
    "            return row.par_call_date, 13\n",
    "        elif cat == 2:\n",
    "            return row.maturity_date, 14\n",
    "        else:\n",
    "            return row.refund_date, 15\n",
    "\n",
    "def either(row):\n",
    "    if row.calc_date == row.maturity_date:\n",
    "        return row.maturity_date\n",
    "    else: \n",
    "        return row.par_call_date\n",
    "    \n",
    "EPSILON = 0.05\n",
    "\n",
    "def alt_calc_date(row):\n",
    "    if row.callable_at_cav:\n",
    "        basic_yield = row.original_yield\n",
    "    else:\n",
    "        basic_yield = 100 * row.coupon\n",
    "    \n",
    "    if row.is_called:\n",
    "        return row.refund_date, 10\n",
    "    elif not row.is_callable:\n",
    "        return row.maturity_date, 14  \n",
    "    elif np.abs(row[YTW] - basic_yield) < EPSILON:\n",
    "        return either(row), 15\n",
    "    elif row[YTW] > basic_yield:\n",
    "        return row.maturity_date, 16   \n",
    "    elif row.next_call_price <= 100:\n",
    "        return row.next_call_date, 17  \n",
    "    elif not pd.isnull(row.par_call_date):\n",
    "        return row.par_call_date, 18  \n",
    "    else:\n",
    "        return row.maturity_date, 19\n",
    "    \n",
    "def assign(est_date, which, date): est_date[which] = date[which] \n",
    "\n",
    "def fast_calc_date(df):\n",
    "    basic_yield = 100 * df.coupon\n",
    "    basic_yield[df.callable_at_cav] = df.original_yield\n",
    "    \n",
    "    either = (np.abs(df[YTW] - basic_yield) < EPSILON)\n",
    "    \n",
    "    est_date = df.maturity_date.copy()\n",
    "    assign(est_date, ~pd.isnull(df.par_call_date), df.par_call_date)\n",
    "    assign(est_date, (df.next_call_price <= 100), df.next_call_date)\n",
    "    assign(est_date, (df[YTW] > basic_yield), df.maturity_date)\n",
    "    assign(est_date, either & (df.calc_date == df.maturity_date), df.maturity_date)\n",
    "    assign(est_date, either & (df.calc_date == df.next_call_date), df.next_call_date)\n",
    "    assign(est_date, ~df.is_callable, df.maturity_date)\n",
    "    assign(est_date, df.is_called, df.refund_date)\n",
    "    return est_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4910e9f3-b6da-4dad-b4df-7106e1eca76f",
   "metadata": {},
   "source": [
    "_YTW_ is the name of the yield-to-worst column that should be used to estimate _calc_date_.\n",
    "The possible values are the true YTW, '_ytw_', predictions '_ytw_preds_', \n",
    "or the YTW of the most recent previous trade in the same bond, '_last_ytw_'.\n",
    "\n",
    "The following function measures the accuracy of estimated calc dates.\n",
    "If the number of mistakes for a given value of _code_ is small, the mistakes are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa375e96-9e5c-4f62-b45c-6278ff4a32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(df):\n",
    "    good = df.guess == df.calc_date\n",
    "    print(f\"accuracy using {YTW} is {100*good.mean():6.3f}%\")\n",
    "    \n",
    "    cols = ['when_issued', 'ytw', 'coupon', 'next_call_price', 'refund_price', \\\n",
    "        'guess', 'calc_date', 'next_call_date', 'par_call_date', 'maturity_date', 'refund_date']\n",
    "\n",
    "    for i in set(df.code):\n",
    "        w = df.code == i\n",
    "        guess = df[w].guess\n",
    "        actual = df[w].calc_date\n",
    "        good = w & (guess == actual)  \n",
    "        bad = w & (guess != actual)\n",
    "        print( f\"   {i:2} {w.sum():5} {good.sum():5} {bad.sum():5}\" )\n",
    "        if (bad.sum() > 0) and (bad.sum() <= 100): \n",
    "            print(df.loc[bad,cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9ec52a-9274-4b49-8f9f-87b2ca6bf7b1",
   "metadata": {},
   "source": [
    "First we measure accuracy using _fast_calc_date_.\n",
    "The time to calculated estimated _calc_date_ for about one million trades is about 200 milliseconds.\n",
    "Based on the true yield to worst, accuracy in estimating _calc_date_ is around 99.98%,\n",
    "versus 98% with _ytw_preds_ and 95% when using _last_ytw_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc2431-9088-4e97-997a-d146d315af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "small = data[data.month == TESTMONTH]\n",
    "small['code'] = 90\n",
    "\n",
    "YTW = 'ytw'\n",
    "%time small['guess'] = fast_calc_date(small)\n",
    "inspect(small)\n",
    "\n",
    "YTW = 'ytw_preds'\n",
    "small['guess'] = fast_calc_date(small)\n",
    "inspect(small)\n",
    "\n",
    "YTW = 'last_ytw'\n",
    "small['guess'] = fast_calc_date(small)\n",
    "inspect(small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11748219-e895-468b-a929-e725a6e4d03e",
   "metadata": {},
   "source": [
    "Next we confirm that _fast_calc_date_ and _alt_calc_date_ produce identical results.\n",
    "For this purpose, we make a smaller dataframe, since _.apply_ is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff832583-2a0d-4e99-848f-f0290322e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "small = data[(data.month == TESTMONTH) & (data.quantity >= 5)]\n",
    "\n",
    "YTW = 'ytw'\n",
    "%time small['guess'] = fast_calc_date(small)\n",
    "small['code'] = 90\n",
    "inspect(small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42372709-9aaf-4d83-a6df-37ec9a98fd31",
   "metadata": {},
   "source": [
    "On the smaller dataset of about 200,000 trades, there are 19 mistakes.\n",
    "The following box shows that _alt_calc_date_ also makes 19 mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59af495-cd29-4d00-b2a8-a292b76ec245",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df = small.apply(alt_calc_date, axis=1)\n",
    "small['guess'] = pd.DataFrame(df.tolist())[0].tolist()\n",
    "small['code'] = pd.DataFrame(df.tolist())[1].tolist()\n",
    "inspect(small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7987bd4-36fd-41b8-bb87-78c4a016b7c6",
   "metadata": {},
   "source": [
    "Using _.apply()_ makes _alt_calc_date_ close to 200 times slower than _fast_calc_date_.\n",
    "The outputs are identical.\n",
    "The slower function does let us print the mistakes separately for each alternative case, \n",
    "which is the debugging information needed in order to modify the function to improve its correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6538fb37-ca5a-43bb-bde3-d2561fac6b1c",
   "metadata": {},
   "source": [
    "The majority of mistakes are for bonds that look like they should be called,\n",
    "but where the next call price is above 100.\n",
    "In this case, a detailed calculation is needed to determine the correct call date.\n",
    "We get most of these correct heuristically, but not all.\n",
    "\n",
    "For about 13 trades per million, _calc_date_ is different from maturity date, next call date, par call date, and refund date.\n",
    "These trades require an even more complex calculation, and we get them all wrong.\n",
    "However, in most cases the true _calc_date_ is only days or one month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f6edb-f4ac-4916-a90b-dae7b0357e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cusip', 'trade_date', 'when_issued', 'ytw', 'coupon', 'next_call_price', 'refund_price', \\\n",
    "        'calc_date', 'next_call_date', 'par_call_date', 'maturity_date', 'refund_date']\n",
    "\n",
    "weird = (data.calc_date != data.maturity_date) & (data.calc_date != data.par_call_date) & (data.calc_date != data.next_call_date) \\\n",
    "            & (data.calc_date != data.refund_date) \n",
    "print(weird.sum(), weird.mean())\n",
    "print(data.loc[weird,cols])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m78"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2266f9d190a7b880f073f634cb88d3a7b9a2324a600bb63b91ff505e59b5d8d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
