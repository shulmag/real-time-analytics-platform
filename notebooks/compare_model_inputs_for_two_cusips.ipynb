{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing two CUSIPs\n",
    "Last updated by Developer on 12/26/2023.\n",
    "\n",
    "This notebook compares the inputs of two user-specified CUSIPs and determines which inputs are different. This notebook is most effective in the following example situation: CUSIP A prices at 110 and CUSIP B prices at 80, even though both CUSIPs have very similar features, and we want to determine which inputs to the model are different and what could be causing the large price discrepancy.\n",
    "\n",
    "The core idea is to use as much code that is deployed i.e., that in `app_engine/demo/server/modules/finance.py`, as possible to maintain consistencies to what is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "from modules.ficc.utils.auxiliary_variables import NON_CAT_FEATURES, \\\n",
    "                                                   BINARY, \\\n",
    "                                                   NON_CAT_FEATURES_DOLLAR_PRICE, \\\n",
    "                                                   BINARY_DOLLAR_PRICE\n",
    "\n",
    "\n",
    "__file__ = os.path.abspath('compare_model_inputs_for_two_cusips.ipynb')    # in a Jupyter Notebook, the `__file__` variable is not automatically defined because notebooks do not run as standard Python scripts\n",
    "server_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'app_engine', 'demo', 'server'))    # get the directory containing the 'app_engine/demo/server' package\n",
    "sys.path.append(server_dir)    # add the directory to sys.path\n",
    "\n",
    "\n",
    "from modules.get_creds import get_creds\n",
    "get_creds()\n",
    "\n",
    "\n",
    "from modules.auxiliary_variables import PRICE_BOTH_DIRECTIONS_TO_CORRECT_INVERSION, \\\n",
    "                                        NUMERICAL_ERROR, \\\n",
    "                                        YEAR_MONTH_DAY, \\\n",
    "                                        YEAR_MONTH_DAY_HOUR_MIN_SEC\n",
    "from modules.auxiliary_functions import get_current_datetime, \\\n",
    "                                        datetime_as_string, \\\n",
    "                                        get_settlement_date, \\\n",
    "                                        get_outstanding_amount\n",
    "from modules.pricing_functions import get_trade_price_from_yield_spread_model, \\\n",
    "                                      predict_spread, \\\n",
    "                                      predict_dollar_price\n",
    "from modules.data_preparation_for_pricing import process_data_for_pricing, \\\n",
    "                                                 get_data_from_redis, \\\n",
    "                                                 reverse_direction_concat, \\\n",
    "                                                 pre_processing, \\\n",
    "                                                 get_inputs_for_nn\n",
    "from modules.batch_pricing import add_ytw_price_calculationdate_coupon, \\\n",
    "                                  prepare_batch_pricing_results_for_logging, \\\n",
    "                                  prepare_batch_pricing_results_to_output_to_user\n",
    "from modules.exclusions import CUSIP_ERROR_MESSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `CUSIP_0` and `CUSIP_1` as the two CUSIPs to compare. Set the `QUANTITY` and `TRADE_TYPE` to be that of the target trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIP_0 = '64971XQM3'\n",
    "CUSIP_1 = '64971XDT2'\n",
    "QUANTITY = 500\n",
    "TRADE_TYPE = 'S'    # P: Purchase from Customer (Bid Side), S: Sale to Customer (Offered Side), D: Inter-Dealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSIP_LIST = [CUSIP_0, CUSIP_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify `price_cusips_list(...)` and associated functions in order to get the model inputs along with the priced CUSIPs. The model inputs are created in `get_inputs_for_nn(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAME_FOR_RESULTS_OF_GET_INPUTS_FOR_NN = 'inputs_for_nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_inversion_and_flip_prices_batch(df):\n",
    "    '''Inverts dealer buy and dealer sell prices, ytw and calc_date for a dataframe with both sides of the \n",
    "    trade priced. \n",
    "\n",
    "    Each original trade is indexed by the 'id' column, which is used to create a dictionary of price, ytw \n",
    "    and calc_date of the other side of the trade. Using 'id' as a key enables multiple trades to have the \n",
    "    same cusip without conflict. It is then referenced to invert predictions if predictions cross.'''\n",
    "    S_idx = df.trade_type == 'S'\n",
    "    P_idx = df.trade_type == 'P'\n",
    "    SP_idx = S_idx | P_idx\n",
    "    original_trades = df.original_trade\n",
    "    outputs_to_swap = ['price', 'ficc_ytw', 'calc_date', COLUMN_NAME_FOR_RESULTS_OF_GET_INPUTS_FOR_NN]    # this line was changed from the original function\n",
    "\n",
    "    opposite_side_dict = dict(zip(df[SP_idx & original_trades]['id'], \n",
    "                                  df[SP_idx & ~original_trades][outputs_to_swap].to_records(index=False)))\n",
    "\n",
    "    def invert_row(row):\n",
    "        '''Inverts the price of a single row if it crosses, taking reference from a dictionary of predicted \n",
    "        price, ytw and calc_date of the other side of the trade.'''\n",
    "        id = row['id']\n",
    "        trade_type = row['trade_type']\n",
    "        if trade_type == 'S':\n",
    "            S_price = row['price']\n",
    "            P_price, ytw, calc_date = opposite_side_dict[id]\n",
    "            if S_price < P_price:\n",
    "                row[outputs_to_swap] = P_price, ytw, calc_date\n",
    "        else:\n",
    "            P_price = row['price']\n",
    "            S_price, ytw, calc_date = opposite_side_dict[id]\n",
    "            if S_price < P_price:\n",
    "                row[outputs_to_swap] = S_price, ytw, calc_date\n",
    "        return row\n",
    "    \n",
    "    df_SP = df[SP_idx & original_trades].apply(invert_row, axis=1)\n",
    "    return pd.concat([df_SP, df[~SP_idx & original_trades]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ytw_dollar_price_for_list(df, current_datetime, quantity_list, trade_type, current_date, settlement_date):\n",
    "    '''Return a list of ytw values for a dataframe on `df`. The `reference_datetime` is used to get the \n",
    "    yield curve level.\n",
    "    NOTE: This was modified to handle inverted trades. This is done after `process_data(...)` is called \n",
    "    to minimize repeated data retrieval and processing.'''\n",
    "    df = process_data_for_pricing(df, quantity_list, trade_type, current_date, settlement_date, current_datetime, True)    # get reference data and feature engineering \n",
    "    \n",
    "    if PRICE_BOTH_DIRECTIONS_TO_CORRECT_INVERSION:\n",
    "        # separate 'S' and 'P' trades from 'D' trades\n",
    "        df_SP = df[df.trade_type != 'D']\n",
    "        df_D = df[df.trade_type == 'D']\n",
    "\n",
    "        df_SP['id'] = range(len(df_SP))    # index each 'S' or 'P' trade with an id for easier identification of rows at the trade-level rather than cusip-level\n",
    "        df_SP['original_trade'] = True     # `original_trade` flag is used to return only the trades that were priced initially, not the hypothetical prices for the other side of the trade\n",
    "        df_D['original_trade'] = True\n",
    "        \n",
    "        df_SP = reverse_direction_concat(df_SP)\n",
    "        df = pd.concat([df_SP, df_D])\n",
    "        del df_SP, df_D\n",
    "\n",
    "    df = pre_processing(df)\n",
    "\n",
    "    if type(df) == str: return df\n",
    "\n",
    "    use_yield_spread_model = df['model_used'] == 'yield_spread'\n",
    "    df_yield_spread = df[use_yield_spread_model]    # use the yield spread model on these CUSIPs\n",
    "    df_dollar_price = df[~use_yield_spread_model]    # use the dollar price model on these CUSIPs\n",
    "    del use_yield_spread_model\n",
    "    del df\n",
    "\n",
    "    if len(df_yield_spread) > 0:\n",
    "        df_list = get_inputs_for_nn(df_yield_spread, use_dollar_price_model=False)\n",
    "        ys = predict_spread(df_list)\n",
    "        ys = np.array(ys) / 100\n",
    "        ys = ys.ravel()    # `np.ravel` returns a contiguous flattened array\n",
    "        df_yield_spread['yield_spread'] = ys    # used for logging\n",
    "        yc = np.array(df_yield_spread['ficc_ycl']) / 100    # changing yield_curve_level to ficc_ycl. This now comes from the data package\n",
    "        ytw = np.add(ys, yc)\n",
    "        df_yield_spread['ficc_ytw'] = ytw\n",
    "        df_yield_spread['ficc_ycl'] = yc    # used for logging\n",
    "        df_yield_spread['price'], df_yield_spread['calc_date'] = zip(*df_yield_spread.apply(get_trade_price_from_yield_spread_model, axis=1))\n",
    "        df_yield_spread[COLUMN_NAME_FOR_RESULTS_OF_GET_INPUTS_FOR_NN] = df_list    # this line was added from the original function\n",
    "\n",
    "    if len(df_dollar_price) > 0:\n",
    "        df_list_dollar_price = get_inputs_for_nn(df_dollar_price, use_dollar_price_model=True)\n",
    "        estimated_dollar_price = predict_dollar_price(df_list_dollar_price)    \n",
    "        estimated_dollar_price = np.array(estimated_dollar_price).ravel()\n",
    "        df_dollar_price['price'] = estimated_dollar_price\n",
    "        # df_dollar_price['ficc_ytw'], df_dollar_price['calc_date'] = zip(*df_dollar_price.apply(get_estimated_yield, axis=1))    # converting the dollar price estimate from the dollar price model to ytw\n",
    "        df_dollar_price['ficc_ytw'] = None\n",
    "        df_dollar_price['calc_date'] = None\n",
    "        df_dollar_price['yield_spread'] = None\n",
    "        df_dollar_price['ficc_ycl'] = None\n",
    "        df_dollar_price[COLUMN_NAME_FOR_RESULTS_OF_GET_INPUTS_FOR_NN] = df_list_dollar_price    # this line was added from the original function\n",
    "    \n",
    "    df = pd.concat([df_yield_spread, df_dollar_price])\n",
    "    if PRICE_BOTH_DIRECTIONS_TO_CORRECT_INVERSION:\n",
    "        # df = df.sort_values(by='id', ascending=True)\n",
    "        df = check_inversion_and_flip_prices_batch(df)\n",
    "        df = df[df.original_trade]    # return only the original trades\n",
    "\n",
    "    return df.drop(columns=COLUMN_NAME_FOR_RESULTS_OF_GET_INPUTS_FOR_NN).sort_index(), df[[COLUMN_NAME_FOR_RESULTS_OF_GET_INPUTS_FOR_NN, 'model_used']]    # this line was changed from the original function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_cusips_list(cusip_list, quantity_list, trade_type_list, current_datetime=None):\n",
    "    '''This function takes a list of CUSIPs and returns price and YTW estimates for each. The optional \n",
    "    argument `current_datetime` is used for calling `price_cusips_list(...)` outside of the `finance.py` \n",
    "    and to manually put in a datetime of choice for point in time pricing.'''\n",
    "    cusips_can_be_priced_df, cusips_cannot_be_priced_df = get_data_from_redis(cusip_list)\n",
    "    if len(cusips_cannot_be_priced_df) != 0: print(cusips_cannot_be_priced_df)    # good to have this output to check why certain CUSIPs cannot be priced\n",
    "    quantity_list = np.array(quantity_list)    # converted to numpy list in order to easily index by list\n",
    "    trade_type_list = np.array(trade_type_list)    # converted to numpy list in order to easily index by list\n",
    "\n",
    "    cusip_indices_that_can_be_priced = list(cusips_can_be_priced_df.index.values)\n",
    "    quantities_for_cusips_that_can_be_priced = quantity_list[cusip_indices_that_can_be_priced]\n",
    "    cusips_can_be_priced_df['quantity'] = quantities_for_cusips_that_can_be_priced\n",
    "    cusips_can_be_priced_df['non_log_transformed_quantity'] = quantities_for_cusips_that_can_be_priced    # this is used for later restoring the non-log10 transformed quantities and quantities for CUSIPs not priced to the dataframe\n",
    "    cusips_can_be_priced_df['trade_type'] = trade_type_list[cusip_indices_that_can_be_priced]\n",
    "    \n",
    "    cusip_indices_that_cannot_be_priced = list(cusips_cannot_be_priced_df.index.values)\n",
    "    cusips_cannot_be_priced_df['quantity'] = quantity_list[cusip_indices_that_cannot_be_priced]\n",
    "    cusips_cannot_be_priced_df['trade_type'] = trade_type_list[cusip_indices_that_cannot_be_priced]\n",
    "\n",
    "    def _fill_basic_error_columns(df):\n",
    "        df['ytw'] = NUMERICAL_ERROR\n",
    "        df['ytw_LOGGING_PRECISION'] = NUMERICAL_ERROR\n",
    "        df['price'] = NUMERICAL_ERROR\n",
    "        df['yield_spread'] = NUMERICAL_ERROR\n",
    "        df['ficc_ycl'] = NUMERICAL_ERROR\n",
    "        df['coupon'] = pd.NA\n",
    "        df['security_description'] = pd.NA\n",
    "        df['maturity_date'] = pd.NA\n",
    "        df['model_used'] = None\n",
    "        df['reason_for_using_dollar_price_model'] = None\n",
    "        return df\n",
    "\n",
    "    def fill_error_columns(df, message_key, series_with_error_message_per_row=None):\n",
    "        if len(df) == 0: return df\n",
    "\n",
    "        if series_with_error_message_per_row is None:\n",
    "            message = CUSIP_ERROR_MESSAGE[message_key]\n",
    "        else:\n",
    "            message = series_with_error_message_per_row.apply(lambda error_message: CUSIP_ERROR_MESSAGE[message_key](error_message))\n",
    "        \n",
    "        df['yield_to_worst_date'] = message\n",
    "        return _fill_basic_error_columns(df)\n",
    "    \n",
    "    def fill_all_error_columns(df):\n",
    "        if len(df) == 0: return df\n",
    "        grouped_by_message = df.groupby('message')\n",
    "        df['yield_to_worst_date'] = grouped_by_message.message.transform(lambda x: CUSIP_ERROR_MESSAGE[x.name])    # assign a value to each group: https://stackoverflow.com/questions/69951813/groupby-specific-column-then-assign-new-values-base-on-conditions\n",
    "        return _fill_basic_error_columns(df)\n",
    "\n",
    "    if len(cusips_can_be_priced_df) != 0:\n",
    "        if current_datetime is None: current_datetime = get_current_datetime()    # `current_datetime` will only not be `None` if we are doing point in time pricing, and so will be passed in as an optional argument\n",
    "        current_date = datetime_as_string(current_datetime, precision='day')\n",
    "        current_datetime = datetime_as_string(current_datetime)\n",
    "        settlement_date = get_settlement_date(current_date)\n",
    "\n",
    "        settlement_date_after_maturity_date = cusips_can_be_priced_df['maturity_date'] <= settlement_date\n",
    "        cusips_can_be_priced_df_settlement_date_after_maturity_date = cusips_can_be_priced_df[settlement_date_after_maturity_date]\n",
    "        cusips_can_be_priced_df_settlement_date_after_maturity_date = fill_error_columns(cusips_can_be_priced_df_settlement_date_after_maturity_date, 'maturing_soon')\n",
    "        cusips_can_be_priced_df = cusips_can_be_priced_df[~settlement_date_after_maturity_date]\n",
    "\n",
    "        outstanding_amount = get_outstanding_amount(cusips_can_be_priced_df, batch_pricing=True)\n",
    "        outstanding_amount = outstanding_amount.fillna(np.inf)    # ensures that the condition of whether the quantity is greater than the amount outstanding will always be `False` if `outstanding_amount` does not exist\n",
    "        outstanding_amount = outstanding_amount.replace(0, np.inf)    # ensures that the condition of whether the quantity is greater than the amount outstanding will always be `False` if `outstanding_amount` is 0\n",
    "        quantity_greater_than_outstanding_amount = cusips_can_be_priced_df['quantity'] > outstanding_amount\n",
    "        cusips_can_be_priced_quantity_greater_than_outstanding_amount = cusips_can_be_priced_df[quantity_greater_than_outstanding_amount]\n",
    "        cusips_can_be_priced_quantity_greater_than_outstanding_amount = fill_error_columns(cusips_can_be_priced_quantity_greater_than_outstanding_amount, 'quantity_greater_than_outstanding_amount', outstanding_amount[quantity_greater_than_outstanding_amount])\n",
    "        cusips_can_be_priced_df = cusips_can_be_priced_df[~quantity_greater_than_outstanding_amount]\n",
    "        \n",
    "        if len(cusips_can_be_priced_df) > 0:    # only attempt to price cusips if there are any remaining after removing those where the settlement date is after the maturity date and where the quantity is lesser than the outstanding_amount\n",
    "            cusips_can_be_priced_df, inputs_for_nn_and_model = get_ytw_dollar_price_for_list(cusips_can_be_priced_df, \n",
    "                                                                                             pd.to_datetime(current_datetime, format=YEAR_MONTH_DAY_HOUR_MIN_SEC), \n",
    "                                                                                             cusips_can_be_priced_df['quantity'].values, \n",
    "                                                                                             cusips_can_be_priced_df['trade_type'].values, \n",
    "                                                                                             pd.to_datetime(current_date, format=YEAR_MONTH_DAY), \n",
    "                                                                                             settlement_date)    # this line was changed from the original function\n",
    "            # converting estimated yield to dollar price\n",
    "            cusips_can_be_priced_df = add_ytw_price_calculationdate_coupon(cusips_can_be_priced_df)\n",
    "\n",
    "            cusips_can_be_priced_df = pd.concat([cusips_can_be_priced_df, cusips_can_be_priced_df_settlement_date_after_maturity_date, cusips_can_be_priced_quantity_greater_than_outstanding_amount])\n",
    "            cusips_can_be_priced_df['quantity'] = cusips_can_be_priced_df['non_log_transformed_quantity']    # put the non-log10 transformed quantity back into the dataframe\n",
    "\n",
    "            # refuse to price CUSIPs within 60 days of the calc date\n",
    "            not_null_calc_date = cusips_can_be_priced_df['calc_date'].notnull()\n",
    "            if not_null_calc_date.sum() > 0:    # only enter if at least one CUSIP has a calc date\n",
    "                cusips_with_calc_date = cusips_can_be_priced_df[not_null_calc_date]\n",
    "                cusips_wo_calc_date = cusips_can_be_priced_df[~not_null_calc_date]\n",
    "                DAYS_TO_CALC_DATE_COLUMN_NAME = 'days_to_calc_date'\n",
    "                cusips_with_calc_date[DAYS_TO_CALC_DATE_COLUMN_NAME] = cusips_with_calc_date.apply(lambda row: diff_in_days_two_dates(row['calc_date'], row['settlement_date']), axis=1)\n",
    "                within_60_days_of_calc_date = cusips_with_calc_date[DAYS_TO_CALC_DATE_COLUMN_NAME] <= 60\n",
    "                cusips_with_calc_date = cusips_with_calc_date.drop(columns=DAYS_TO_CALC_DATE_COLUMN_NAME)\n",
    "                cusips_within_60_days_of_calc_date = cusips_with_calc_date[within_60_days_of_calc_date]\n",
    "                cusips_not_within_60_days_of_calc_date = cusips_with_calc_date[~within_60_days_of_calc_date]\n",
    "                cusips_within_60_days_of_calc_date = fill_error_columns(cusips_within_60_days_of_calc_date, 'maturing_soon')\n",
    "                cusips_can_be_priced_df = pd.concat([cusips_wo_calc_date, cusips_not_within_60_days_of_calc_date, cusips_within_60_days_of_calc_date])\n",
    "        else:    # all of the CUSIPs in the original `cusips_can_be_priced_df` are now in either `cusips_can_be_priced_df_settlement_date_after_maturity_date` or `cusips_can_be_priced_quantity_greater_than_outstanding_amount`\n",
    "            cusips_can_be_priced_df = pd.concat([cusips_can_be_priced_df_settlement_date_after_maturity_date, cusips_can_be_priced_quantity_greater_than_outstanding_amount])\n",
    "    cusips_cannot_be_priced_df = fill_all_error_columns(cusips_cannot_be_priced_df)\n",
    "    cusips_df = pd.concat([cusips_can_be_priced_df, cusips_cannot_be_priced_df])\n",
    "    return cusips_df.sort_index(), inputs_for_nn_and_model    # this line was changed from the original function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We batch price the CUSIPs in `CUSIP_LIST` at `QUANTITY` and `TRADE_TYPE` instead of individually pricing them one after the other to ensure that the trade datetime is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priced_df, inputs_for_nn_and_model = price_cusips_list(CUSIP_LIST, [QUANTITY] * 2, [TRADE_TYPE] * 2)\n",
    "priced_df = prepare_batch_pricing_results_to_output_to_user(prepare_batch_pricing_results_for_logging(priced_df))\n",
    "priced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs for NN and the model used and differences between the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_inputs(inputs_for_nn, model_used):\n",
    "    inputs_for_nn_0 = inputs_for_nn.iloc[0]\n",
    "    inputs_for_nn_1 = inputs_for_nn.iloc[1]\n",
    "    model_0, model_1 = model_used.tolist()\n",
    "    print(f'{CUSIP_0} using {model_0} model\\tvs\\t{CUSIP_1} using {model_1} model')\n",
    "    \n",
    "    if model_0 == model_1 == 'yield_spread':\n",
    "        non_cat_and_binary_features_labels = NON_CAT_FEATURES + BINARY\n",
    "    elif model_0 == model_1 == 'dollar_price':\n",
    "        non_cat_and_binary_features_labels = NON_CAT_FEATURES_DOLLAR_PRICE + BINARY_DOLLAR_PRICE\n",
    "    else:\n",
    "        print('Models are different')\n",
    "        return None\n",
    "    \n",
    "    for input_feature, input_value_0 in inputs_for_nn_0.items():\n",
    "        input_value_1 = inputs_for_nn_1[input_feature]\n",
    "        if input_feature == 'trade_history_input':\n",
    "            print(f'Trade history for {CUSIP_0}')\n",
    "            print(input_value_0)\n",
    "            print(f'Trade history for {CUSIP_1}')\n",
    "            print(inputs_for_nn_1[input_feature])\n",
    "        elif input_feature == 'target_attention_input':\n",
    "            target_attention_input_0 = input_value_0[0]    # since it is a one item list, we extract the value\n",
    "            target_attention_input_1 = input_value_1[0]    # since it is a one item list, we extract the value\n",
    "            for idx, item_0 in enumerate(target_attention_input_0):\n",
    "                item_1 = target_attention_input_1[idx]\n",
    "                if item_0 != item_1: print(f'{input_feature}[0][{idx}] is different:\\t{item_0} vs {item_1}')\n",
    "        elif input_feature == 'NON_CAT_AND_BINARY_FEATURES':\n",
    "            for idx, item_0 in enumerate(input_value_0):\n",
    "                item_1 = input_value_1[idx]\n",
    "                if item_0 != item_1: print(f'{non_cat_and_binary_features_labels[idx]} is different:\\t{item_0} vs {item_1}')\n",
    "        else:\n",
    "            if input_value_0 != input_value_1: print(f'{input_feature} is different:\\t{input_value_0} vs {input_value_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_for_nn, model_used = inputs_for_nn_and_model[COLUMN_NAME_FOR_RESULTS_OF_GET_INPUTS_FOR_NN], inputs_for_nn_and_model['model_used']\n",
    "compare_inputs(inputs_for_nn, model_used)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
