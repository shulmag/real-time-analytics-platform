{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last updated by Developer on 2024-12-30. This notebook creates the similar trade history redis from the same CUSIP trade history redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from functools import wraps\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import multiprocess as mp    # using `multiprocess` instead of `multiprocessing` because function to be called in `map` is in the same file as the function which is calling it: https://stackoverflow.com/questions/41385708/multiprocessing-example-giving-attributeerror\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from `cloud_functions/fast_trade_history_redis_update/main.py`\n",
    "MAX_NUM_TRADES_IN_SIMILAR_TRADE_HISTORY = 64    # wanted a value larger than 32 in case the last many trades were from the same CUSIP and so chose the next power of 2\n",
    "NUM_OF_DAYS_IN_YEAR = 360\n",
    "FEATURES_FOR_EACH_TRADE_IN_HISTORY = {'msrb_valid_from_date': 'DATETIME', \n",
    "                                      'msrb_valid_to_date': 'DATETIME', \n",
    "                                      'rtrs_control_number': 'INTEGER', \n",
    "                                      'trade_datetime': 'DATETIME', \n",
    "                                      'publish_datetime': 'DATETIME', \n",
    "                                      'yield': 'FLOAT', \n",
    "                                      'dollar_price': 'FLOAT', \n",
    "                                      'par_traded': 'NUMERIC', \n",
    "                                      'trade_type': 'STRING', \n",
    "                                      'is_non_transaction_based_compensation': 'BOOLEAN', \n",
    "                                      'is_lop_or_takedown': 'BOOLEAN', \n",
    "                                      'brokers_broker': 'STRING', \n",
    "                                      'is_alternative_trading_system': 'BOOLEAN', \n",
    "                                      'is_weighted_average_price': 'BOOLEAN', \n",
    "                                      'settlement_date': 'DATE', \n",
    "                                      'calc_date': 'DATE', \n",
    "                                      'calc_day_cat': 'INTEGER', \n",
    "                                      'maturity_date': 'DATE', \n",
    "                                      'next_call_date': 'DATE', \n",
    "                                      'par_call_date': 'DATE', \n",
    "                                      'refund_date': 'DATE', \n",
    "                                      'transaction_type': 'STRING', \n",
    "                                      'sequence_number': 'INTEGER'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_timer(function_to_time):\n",
    "    '''This function is to be used as a decorator. It will print out the execution time of `function_to_time`.'''\n",
    "    @wraps(function_to_time)    # used to ensure that the function name is still the same after applying the decorator when running tests: https://stackoverflow.com/questions/6312167/python-unittest-cant-call-decorated-test\n",
    "    def wrapper(*args, **kwargs):    # using the same formatting from https://docs.python.org/3/library/functools.html\n",
    "        print(f'BEGIN {function_to_time.__name__}')\n",
    "        start_time = time.time()\n",
    "        result = function_to_time(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f'END {function_to_time.__name__}. Execution time: {timedelta(seconds=end_time - start_time)}')\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data_redis_client = redis.Redis(host='10.108.4.36', port=6379, db=0)    # use read endpoint since use case is read-only allowing for lower latency and to not accidentally corrupt the redis by attempting to write to it\n",
    "trade_history_redis_client = redis.Redis(host='10.75.46.229', port=6379, db=0)    # use read endpoint since use case is read-only allowing for lower latency and to not accidentally corrupt the redis by attempting to write to it\n",
    "similar_trade_history_redis_client = redis.Redis(host='10.117.191.180', port=6379, db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_timer\n",
    "def delete_all_keys_in_redis(redis_client):\n",
    "    num_keys_before_deletion = redis_client.dbsize()\n",
    "    print(f'Attempting to delete {num_keys_before_deletion} keys')\n",
    "    for key in redis_client.scan_iter():\n",
    "        redis_client.delete(key)\n",
    "    num_keys_after_deletion = redis_client.dbsize()\n",
    "    assert num_keys_after_deletion == 0, f'Number of keys after deleting all of them is: {num_keys_after_deletion}, but should be 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from `cloud_functions/fast_trade_history_redis_update/main.py`\n",
    "def create_trade_history_numpy_array(trade_history_df, max_num_trades):\n",
    "    trade_history_df = trade_history_df.drop_duplicates(subset='rtrs_control_number', keep='first')    # keep the most recently published `rtrs_control_number` which we can assume is in descending order of 'publish_datetime' and 'sequence_number' due to the `.sort_values(...)` statement above\n",
    "    trade_history_df = trade_history_df[trade_history_df['transaction_type'] != 'C']    # drop all cancelled trades\n",
    "    trade_history_df = trade_history_df.sort_values(by=['trade_datetime', 'publish_datetime', 'sequence_number'], ascending=False)\n",
    "    return trade_history_df.head(max_num_trades).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from `cloud_functions/fast_trade_history_redis_update/main.py`\n",
    "def get_key_trade_history_pair(key, trade_history, redis_client, max_num_trades, key_transform_func=None, verbose=False, keep_cusip_in_trade_history=False):\n",
    "    '''`key_transform_func` is helpful in turning a tuple into a primitive type (e.g. string) that can be \n",
    "    used as a key for Redis. Redis does not allow tuples to be used as keys.'''\n",
    "    if key_transform_func is not None: key = key_transform_func(key)\n",
    "    if verbose: print(f'Calling get_key_trade_history_pair(...) with key={key} and trade_history:\\n{trade_history.to_markdown()}')\n",
    "    features_for_each_trade_in_history = list(FEATURES_FOR_EACH_TRADE_IN_HISTORY.keys())\n",
    "    if keep_cusip_in_trade_history: features_for_each_trade_in_history.append('cusip')\n",
    "    trade_history = trade_history[features_for_each_trade_in_history]    # this procedure cannot be done outside of this function since it removes the `cusip` field\n",
    "    if redis_client.exists(key):\n",
    "        old_trade_history = redis_client.get(key)\n",
    "        try:\n",
    "            old_trade_history = pd.DataFrame(pickle.loads(old_trade_history), columns=features_for_each_trade_in_history)\n",
    "        except Exception as e:\n",
    "            print('key:', key)\n",
    "            print('old_trade_history:\\n', pd.DataFrame(pickle.loads(old_trade_history)))\n",
    "            raise e\n",
    "        trade_history = pd.concat([trade_history, old_trade_history], ignore_index=True)\n",
    "    return key, create_trade_history_numpy_array(trade_history, max_num_trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from `cloud_functions/fast_trade_history_redis_update/main.py`\n",
    "def remove_negative_and_missing_yields(trades_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    num_trades_before_removal = len(trades_df)\n",
    "    trades_df = trades_df[~pd.isna(trades_df['yield'])]    # remove trades that have missing yields\n",
    "    trades_df = trades_df[trades_df['yield'] >= 0]    # remove trades that have negative yields\n",
    "    num_trades_after_removal = len(trades_df)\n",
    "    if num_trades_before_removal != num_trades_after_removal: print(f'Removed {num_trades_before_removal - num_trades_after_removal} trades for having negative or missing yields, leaving {num_trades_after_removal} trades')\n",
    "    return trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from `cloud_functions/fast_trade_history_redis_update/main.py`\n",
    "def upload_trade_history_to_redis(key, trade_history, redis_client):\n",
    "    '''Add `trade_history` to `redis_client` for a corresponding `key`. If we are in \n",
    "    testing mode, then we should wipe the redis before using it for production.\n",
    "    TODO: wipe redis before using for production.\n",
    "    NOTE: If the only new trade_message is a cancellation message and there is only one trade in the history \n",
    "    (for example), we will upload a trade_history with nothing in it. This is good and desirable, because this \n",
    "    will overwrite/replace a key/CUSIP with a trade_message that has subsequently been cancelled.'''\n",
    "    trade_history = pickle.dumps(trade_history, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    redis_client.set(key, trade_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from `cloud_functions/fast_trade_history_redis_update/main.py`\n",
    "@function_timer\n",
    "def upload_to_redis_from_upload_function(pairs, upload_function):\n",
    "    '''Upload each pair from `pairs` to the redis using the `upload_function`.'''\n",
    "    [upload_function(key, trade_history) for key, trade_history in pairs]\n",
    "    return pairs    # unused return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken directly from `cloud_functions/fast_trade_history_redis_update/main.py`\n",
    "@function_timer\n",
    "def update_similar_trade_history_redis(new_trades, verbose=False):\n",
    "    '''Update the redis corresponding to the similar trade history with the rows from `new_trades`. If the feature set \n",
    "    defining the related trade does not exist in the redis, then create the similar trade history starting from this \n",
    "    trade(s). If the feature set does exist, then check if there are new messages for old RTRS control numbers \n",
    "    and substitute those new messages for the old ones. If the `transaction_type` is 'C', remove the trade, \n",
    "    otherwise, replace the old message with the newest message. Add new trades to the dataframe in descending \n",
    "    order of `trade_datetime`. The definition of similar is one that matches on `issue_key`, `maturity_year_by_5`, \n",
    "    and `coupon_by_1`, where maturity_year_by_5 takes the maturity_year and floor divides it by 5 and coupon_by_1 \n",
    "    takes the coupon and floor divides it by 1.\n",
    "    NOTE: 'I' is an instruction or the first trade message. 'C' is to cancel the trade. We see here the trade messages \n",
    "    have the same information. 'M' and 'R' both indicate modification. 'R' is an MSRB modification (e.g., to fill in \n",
    "    par_traded when that value is initially null because of the `par_traded` over $5M rule).\n",
    "    NOTE: for a particular RTRS control number, there is a specific `trade_datetime`. A more recent message for that  \n",
    "    RTRS control number, such as a modify or a cancellation, would correspond to a more recent `publish_datetime`.\n",
    "    NOTE: Setting `verbose` to `True` provides detailed print output and is helpful for testing.'''\n",
    "    ## the below line is commented out because we already removed negative and missing yields when creating the all trades dataframe\n",
    "    # new_trades = remove_negative_and_missing_yields(new_trades)    # only keep trades with nonnegative yields\n",
    "    new_trades = new_trades.dropna(subset=['issue_key', 'maturity_date', 'trade_date', 'coupon'])    # remove trades that have null values for features that we need to determine similarity\n",
    "    if len(new_trades) == 0:\n",
    "        print('No trades to add to the similar trade history redis after removing trades with negative yields, and trades with null values for yield, issue_key, maturity_date, trade_date, or coupon.')\n",
    "        return None\n",
    "    # add features for definition of similar\n",
    "    new_trades['years_to_maturity_date_by_5'] = ((new_trades['maturity_date'] - new_trades['trade_date']).dt.days // NUM_OF_DAYS_IN_YEAR) // 5\n",
    "    new_trades['coupon_by_1'] = np.nan    # initialize the column\n",
    "    is_zero_coupon = new_trades['coupon'] == 0\n",
    "    new_trades.loc[is_zero_coupon, 'coupon_by_1'] = -1    # zero coupon has its own bucket\n",
    "    new_trades.loc[~is_zero_coupon, 'coupon_by_1'] = new_trades.loc[~is_zero_coupon, 'coupon'] // 1\n",
    "    new_trades = new_trades.astype({'issue_key': int, 'years_to_maturity_date_by_5': int, 'coupon_by_1': int})\n",
    "    if verbose: print(f'new_trades:\\n{new_trades.drop(columns=[\"recent\"]).to_markdown()}')    # drop `recent` column because it has a lot of data that makes it difficult to read the output\n",
    "\n",
    "    features_to_string = lambda features: '_'.join([str(feature) for feature in features])    # `features` should be a tuple or list; NOTE: this lambda function is identical to `similar_group_to_similar_key(...)` in `app_engine/demo/server/modules/finance.py`\n",
    "    get_features_similar_trade_history_pair_caller = lambda features, df: get_key_trade_history_pair(features, df, similar_trade_history_redis_client, MAX_NUM_TRADES_IN_SIMILAR_TRADE_HISTORY, features_to_string, verbose=verbose, keep_cusip_in_trade_history=True)\n",
    "    features_trade_history_pairs = [get_features_similar_trade_history_pair_caller(features, df_for_features) for features, df_for_features in new_trades.groupby(['issue_key', 'years_to_maturity_date_by_5', 'coupon_by_1'])]\n",
    "\n",
    "    upload_similar_trade_history_to_similar_trade_history_redis = lambda features, trade_history: upload_trade_history_to_redis(features, trade_history, similar_trade_history_redis_client)\n",
    "    upload_to_redis_from_upload_function(features_trade_history_pairs, upload_similar_trade_history_to_similar_trade_history_redis)\n",
    "    return features_trade_history_pairs    # return value is unused, but perhaps can be used later to store these values into bigquery for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trade_history_data(cusip):\n",
    "    if not reference_data_redis_client.exists(cusip): return None\n",
    "    trade_history_data = pd.DataFrame(pickle.loads(trade_history_redis_client.get(cusip)), columns=list(FEATURES_FOR_EACH_TRADE_IN_HISTORY.keys()))\n",
    "    reference_data = pickle.loads(reference_data_redis_client.get(cusip))[0]    # index 0 indicates the most recent snapshot of the reference data\n",
    "    trade_history_data[['coupon', 'issue_key']] = reference_data[['coupon', 'issue_key']]\n",
    "    trade_history_data['cusip'] = cusip.decode('utf-8')    # put cusip in the dataframe to use further downstream to filter the similar trades by removing the target CUSIP; decode with 'utf-8' is necessary since the keys are byte-strings; https://stackoverflow.com/questions/606191/convert-bytes-to-a-string-in-python-3\n",
    "    trade_history_data = trade_history_data.dropna(subset=['maturity_date', 'coupon', 'issue_key'])    # remove trades that have null values for features that we need to determine similarity\n",
    "    trade_history_data['issue_key'] = trade_history_data['issue_key'].astype(int)\n",
    "    return remove_negative_and_missing_yields(trade_history_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate all trades from the trade history redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trades = None\n",
    "num_cusips = 0    # set to a strictly positive value to cap the number of CUSIPs investigated to `num_cusips`; used primarily for testing\n",
    "\n",
    "if num_cusips > 0:\n",
    "    for cusip in trade_history_redis_client.scan_iter():\n",
    "        print(cusip)\n",
    "        trade_history_data = process_trade_history_data(cusip)\n",
    "        if trade_history_data is not None:\n",
    "            all_trades = pd.concat([all_trades, trade_history_data]) if all_trades is not None else trade_history_data\n",
    "            num_cusips -= 1\n",
    "            if num_cusips == 0: break\n",
    "else:    # apply parallelization\n",
    "    print('Using parallelization')\n",
    "    with mp.Pool() as pool_object:    # using template from https://docs.python.org/3/library/multiprocessing.html\n",
    "        all_trades = pool_object.map(process_trade_history_data, trade_history_redis_client.scan_iter())\n",
    "    all_trades = pd.concat([trades for trades in all_trades if trades is not None])\n",
    "\n",
    "all_trades.to_pickle('all_trades.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trades: 15621665\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msrb_valid_from_date</th>\n",
       "      <th>msrb_valid_to_date</th>\n",
       "      <th>rtrs_control_number</th>\n",
       "      <th>trade_datetime</th>\n",
       "      <th>publish_datetime</th>\n",
       "      <th>yield</th>\n",
       "      <th>dollar_price</th>\n",
       "      <th>par_traded</th>\n",
       "      <th>trade_type</th>\n",
       "      <th>is_non_transaction_based_compensation</th>\n",
       "      <th>...</th>\n",
       "      <th>calc_day_cat</th>\n",
       "      <th>maturity_date</th>\n",
       "      <th>next_call_date</th>\n",
       "      <th>par_call_date</th>\n",
       "      <th>refund_date</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>coupon</th>\n",
       "      <th>issue_key</th>\n",
       "      <th>cusip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-05 10:54:07</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021050501478900</td>\n",
       "      <td>2021-05-05 10:53:56</td>\n",
       "      <td>2021-05-05 10:54:07</td>\n",
       "      <td>0.564</td>\n",
       "      <td>101.235</td>\n",
       "      <td>10000.000000000</td>\n",
       "      <td>D</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>6343.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-05 10:54:02</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021050501478500</td>\n",
       "      <td>2021-05-05 10:53:56</td>\n",
       "      <td>2021-05-05 10:54:02</td>\n",
       "      <td>0.389</td>\n",
       "      <td>101.335</td>\n",
       "      <td>10000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>6341.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-27 11:26:03</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021042702071200</td>\n",
       "      <td>2021-04-27 11:25:31</td>\n",
       "      <td>2021-04-27 11:26:03</td>\n",
       "      <td>0.537</td>\n",
       "      <td>101.299</td>\n",
       "      <td>10000.000000000</td>\n",
       "      <td>D</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>9128.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-27 11:26:03</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021042702065800</td>\n",
       "      <td>2021-04-27 11:25:31</td>\n",
       "      <td>2021-04-27 11:26:03</td>\n",
       "      <td>0.537</td>\n",
       "      <td>101.299</td>\n",
       "      <td>10000.000000000</td>\n",
       "      <td>D</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>9126.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-27 11:26:03</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021042702072800</td>\n",
       "      <td>2021-04-27 11:25:31</td>\n",
       "      <td>2021-04-27 11:26:03</td>\n",
       "      <td>0.369</td>\n",
       "      <td>101.399</td>\n",
       "      <td>10000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>9127.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-04-23 11:40:37</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021042302125500</td>\n",
       "      <td>2021-04-23 11:40:30</td>\n",
       "      <td>2021-04-23 11:40:37</td>\n",
       "      <td>0.411</td>\n",
       "      <td>101.387</td>\n",
       "      <td>25000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>9391.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-04-23 11:40:43</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021042302126700</td>\n",
       "      <td>2021-04-23 11:40:30</td>\n",
       "      <td>2021-04-23 11:40:43</td>\n",
       "      <td>0.578</td>\n",
       "      <td>101.287</td>\n",
       "      <td>25000.000000000</td>\n",
       "      <td>D</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>9399.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-04-21 12:39:52</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021042103293900</td>\n",
       "      <td>2021-04-21 12:39:46</td>\n",
       "      <td>2021-04-21 12:39:52</td>\n",
       "      <td>0.23</td>\n",
       "      <td>101.524</td>\n",
       "      <td>15000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>15534.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-04-21 12:39:59</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021042103296500</td>\n",
       "      <td>2021-04-21 12:39:46</td>\n",
       "      <td>2021-04-21 12:39:59</td>\n",
       "      <td>0.393</td>\n",
       "      <td>101.424</td>\n",
       "      <td>15000.000000000</td>\n",
       "      <td>D</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>15544.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-04-16 08:47:02</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2021041600270100</td>\n",
       "      <td>2021-04-16 08:46:48</td>\n",
       "      <td>2021-04-16 08:47:02</td>\n",
       "      <td>0.395</td>\n",
       "      <td>101.442</td>\n",
       "      <td>15000.000000000</td>\n",
       "      <td>D</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1012784</td>\n",
       "      <td>57587AHR2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  msrb_valid_from_date msrb_valid_to_date rtrs_control_number  \\\n",
       "0  2021-05-05 10:54:07         2100-01-01    2021050501478900   \n",
       "1  2021-05-05 10:54:02         2100-01-01    2021050501478500   \n",
       "2  2021-04-27 11:26:03         2100-01-01    2021042702071200   \n",
       "3  2021-04-27 11:26:03         2100-01-01    2021042702065800   \n",
       "4  2021-04-27 11:26:03         2100-01-01    2021042702072800   \n",
       "5  2021-04-23 11:40:37         2100-01-01    2021042302125500   \n",
       "6  2021-04-23 11:40:43         2100-01-01    2021042302126700   \n",
       "7  2021-04-21 12:39:52         2100-01-01    2021042103293900   \n",
       "8  2021-04-21 12:39:59         2100-01-01    2021042103296500   \n",
       "9  2021-04-16 08:47:02         2100-01-01    2021041600270100   \n",
       "\n",
       "       trade_datetime    publish_datetime  yield dollar_price  \\\n",
       "0 2021-05-05 10:53:56 2021-05-05 10:54:07  0.564      101.235   \n",
       "1 2021-05-05 10:53:56 2021-05-05 10:54:02  0.389      101.335   \n",
       "2 2021-04-27 11:25:31 2021-04-27 11:26:03  0.537      101.299   \n",
       "3 2021-04-27 11:25:31 2021-04-27 11:26:03  0.537      101.299   \n",
       "4 2021-04-27 11:25:31 2021-04-27 11:26:03  0.369      101.399   \n",
       "5 2021-04-23 11:40:30 2021-04-23 11:40:37  0.411      101.387   \n",
       "6 2021-04-23 11:40:30 2021-04-23 11:40:43  0.578      101.287   \n",
       "7 2021-04-21 12:39:46 2021-04-21 12:39:52   0.23      101.524   \n",
       "8 2021-04-21 12:39:46 2021-04-21 12:39:59  0.393      101.424   \n",
       "9 2021-04-16 08:46:48 2021-04-16 08:47:02  0.395      101.442   \n",
       "\n",
       "        par_traded trade_type is_non_transaction_based_compensation  ...  \\\n",
       "0  10000.000000000          D                                 False  ...   \n",
       "1  10000.000000000          S                                 False  ...   \n",
       "2  10000.000000000          D                                 False  ...   \n",
       "3  10000.000000000          D                                 False  ...   \n",
       "4  10000.000000000          S                                 False  ...   \n",
       "5  25000.000000000          S                                 False  ...   \n",
       "6  25000.000000000          D                                 False  ...   \n",
       "7  15000.000000000          S                                 False  ...   \n",
       "8  15000.000000000          D                                 False  ...   \n",
       "9  15000.000000000          D                                 False  ...   \n",
       "\n",
       "  calc_day_cat maturity_date next_call_date par_call_date refund_date  \\\n",
       "0            2    2021-12-01           None          None        None   \n",
       "1            2    2021-12-01           None          None        None   \n",
       "2            2    2021-12-01           None          None        None   \n",
       "3            2    2021-12-01           None          None        None   \n",
       "4            2    2021-12-01           None          None        None   \n",
       "5            2    2021-12-01           None          None        None   \n",
       "6            2    2021-12-01           None          None        None   \n",
       "7            2    2021-12-01           None          None        None   \n",
       "8            2    2021-12-01           None          None        None   \n",
       "9            2    2021-12-01           None          None        None   \n",
       "\n",
       "  transaction_type sequence_number coupon issue_key      cusip  \n",
       "0                I          6343.0   2.75   1012784  57587AHR2  \n",
       "1                I          6341.0   2.75   1012784  57587AHR2  \n",
       "2                I          9128.0   2.75   1012784  57587AHR2  \n",
       "3                I          9126.0   2.75   1012784  57587AHR2  \n",
       "4                I          9127.0   2.75   1012784  57587AHR2  \n",
       "5                I          9391.0   2.75   1012784  57587AHR2  \n",
       "6                I          9399.0   2.75   1012784  57587AHR2  \n",
       "7                I         15534.0   2.75   1012784  57587AHR2  \n",
       "8                I         15544.0   2.75   1012784  57587AHR2  \n",
       "9                I          1051.0   2.75   1012784  57587AHR2  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msrb_valid_from_date</th>\n",
       "      <th>msrb_valid_to_date</th>\n",
       "      <th>rtrs_control_number</th>\n",
       "      <th>trade_datetime</th>\n",
       "      <th>publish_datetime</th>\n",
       "      <th>yield</th>\n",
       "      <th>dollar_price</th>\n",
       "      <th>par_traded</th>\n",
       "      <th>trade_type</th>\n",
       "      <th>is_non_transaction_based_compensation</th>\n",
       "      <th>...</th>\n",
       "      <th>calc_day_cat</th>\n",
       "      <th>maturity_date</th>\n",
       "      <th>next_call_date</th>\n",
       "      <th>par_call_date</th>\n",
       "      <th>refund_date</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>sequence_number</th>\n",
       "      <th>coupon</th>\n",
       "      <th>issue_key</th>\n",
       "      <th>cusip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-18 11:45:24</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2022051805574900</td>\n",
       "      <td>2022-05-18 11:45:00</td>\n",
       "      <td>2022-05-18 11:45:24</td>\n",
       "      <td>2.45</td>\n",
       "      <td>103.726</td>\n",
       "      <td>230000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>23765.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1223291</td>\n",
       "      <td>830745LN3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-18 11:45:24</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2022051805574700</td>\n",
       "      <td>2022-05-18 11:45:00</td>\n",
       "      <td>2022-05-18 11:45:24</td>\n",
       "      <td>2.45</td>\n",
       "      <td>103.726</td>\n",
       "      <td>150000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>I</td>\n",
       "      <td>23763.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1223291</td>\n",
       "      <td>830745LN3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-27 06:00:52</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2020032017621900</td>\n",
       "      <td>2020-03-20 17:02:00</td>\n",
       "      <td>2020-03-27 06:00:52</td>\n",
       "      <td>2.398</td>\n",
       "      <td>104.161</td>\n",
       "      <td>9000000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2030-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>901018</td>\n",
       "      <td>59259YHK8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-27 06:00:52</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2020032017477600</td>\n",
       "      <td>2020-03-20 16:51:09</td>\n",
       "      <td>2020-03-27 06:00:52</td>\n",
       "      <td>2.55</td>\n",
       "      <td>103.911</td>\n",
       "      <td>9000000.000000000</td>\n",
       "      <td>D</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2030-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>901018</td>\n",
       "      <td>59259YHK8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-27 06:00:52</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2020032017480100</td>\n",
       "      <td>2020-03-20 16:51:09</td>\n",
       "      <td>2020-03-27 06:00:52</td>\n",
       "      <td>2.6</td>\n",
       "      <td>103.829</td>\n",
       "      <td>9000000.000000000</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2030-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>901018</td>\n",
       "      <td>59259YHK8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-20 16:40:41</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2020032017265100</td>\n",
       "      <td>2020-03-20 16:37:25</td>\n",
       "      <td>2020-03-20 16:40:41</td>\n",
       "      <td>2.55</td>\n",
       "      <td>103.911</td>\n",
       "      <td>1000000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2030-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>901018</td>\n",
       "      <td>59259YHK8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-20 16:40:32</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2020032017260400</td>\n",
       "      <td>2020-03-20 16:36:40</td>\n",
       "      <td>2020-03-20 16:40:32</td>\n",
       "      <td>2.6</td>\n",
       "      <td>103.829</td>\n",
       "      <td>1000000.000000000</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2030-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>901018</td>\n",
       "      <td>59259YHK8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-03-17 10:02:27</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2020031701306600</td>\n",
       "      <td>2020-03-17 10:00:47</td>\n",
       "      <td>2020-03-17 10:02:27</td>\n",
       "      <td>1.63</td>\n",
       "      <td>105.48</td>\n",
       "      <td>1200000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2030-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>901018</td>\n",
       "      <td>59259YHK8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-03-17 10:01:35</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2020031701291200</td>\n",
       "      <td>2020-03-17 09:57:25</td>\n",
       "      <td>2020-03-17 10:01:35</td>\n",
       "      <td>1.65</td>\n",
       "      <td>105.446</td>\n",
       "      <td>1425000.000000000</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2030-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>901018</td>\n",
       "      <td>59259YHK8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-03-17 08:50:26</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>2020031700408700</td>\n",
       "      <td>2020-03-17 08:46:09</td>\n",
       "      <td>2020-03-17 08:50:26</td>\n",
       "      <td>1.75</td>\n",
       "      <td>105.278</td>\n",
       "      <td>2625000.000000000</td>\n",
       "      <td>P</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2030-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>2021-11-15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>901018</td>\n",
       "      <td>59259YHK8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  msrb_valid_from_date msrb_valid_to_date rtrs_control_number  \\\n",
       "0  2022-05-18 11:45:24         2100-01-01    2022051805574900   \n",
       "1  2022-05-18 11:45:24         2100-01-01    2022051805574700   \n",
       "0  2020-03-27 06:00:52         2100-01-01    2020032017621900   \n",
       "1  2020-03-27 06:00:52         2100-01-01    2020032017477600   \n",
       "2  2020-03-27 06:00:52         2100-01-01    2020032017480100   \n",
       "3  2020-03-20 16:40:41         2100-01-01    2020032017265100   \n",
       "4  2020-03-20 16:40:32         2100-01-01    2020032017260400   \n",
       "5  2020-03-17 10:02:27         2100-01-01    2020031701306600   \n",
       "6  2020-03-17 10:01:35         2100-01-01    2020031701291200   \n",
       "7  2020-03-17 08:50:26         2100-01-01    2020031700408700   \n",
       "\n",
       "       trade_datetime    publish_datetime  yield dollar_price  \\\n",
       "0 2022-05-18 11:45:00 2022-05-18 11:45:24   2.45      103.726   \n",
       "1 2022-05-18 11:45:00 2022-05-18 11:45:24   2.45      103.726   \n",
       "0 2020-03-20 17:02:00 2020-03-27 06:00:52  2.398      104.161   \n",
       "1 2020-03-20 16:51:09 2020-03-27 06:00:52   2.55      103.911   \n",
       "2 2020-03-20 16:51:09 2020-03-27 06:00:52    2.6      103.829   \n",
       "3 2020-03-20 16:37:25 2020-03-20 16:40:41   2.55      103.911   \n",
       "4 2020-03-20 16:36:40 2020-03-20 16:40:32    2.6      103.829   \n",
       "5 2020-03-17 10:00:47 2020-03-17 10:02:27   1.63       105.48   \n",
       "6 2020-03-17 09:57:25 2020-03-17 10:01:35   1.65      105.446   \n",
       "7 2020-03-17 08:46:09 2020-03-17 08:50:26   1.75      105.278   \n",
       "\n",
       "          par_traded trade_type is_non_transaction_based_compensation  ...  \\\n",
       "0   230000.000000000          S                                 False  ...   \n",
       "1   150000.000000000          S                                 False  ...   \n",
       "0  9000000.000000000          S                                 False  ...   \n",
       "1  9000000.000000000          D                                 False  ...   \n",
       "2  9000000.000000000          P                                 False  ...   \n",
       "3  1000000.000000000          S                                 False  ...   \n",
       "4  1000000.000000000          P                                 False  ...   \n",
       "5  1200000.000000000          S                                 False  ...   \n",
       "6  1425000.000000000          S                                 False  ...   \n",
       "7  2625000.000000000          P                                 False  ...   \n",
       "\n",
       "  calc_day_cat maturity_date next_call_date par_call_date refund_date  \\\n",
       "0            2    2023-12-01           None          None        None   \n",
       "1            2    2023-12-01           None          None        None   \n",
       "0            3    2030-11-15     2021-11-15    2021-11-15  2021-11-15   \n",
       "1            3    2030-11-15     2021-11-15    2021-11-15  2021-11-15   \n",
       "2            3    2030-11-15     2021-11-15    2021-11-15  2021-11-15   \n",
       "3            3    2030-11-15     2021-11-15    2021-11-15  2021-11-15   \n",
       "4            3    2030-11-15     2021-11-15    2021-11-15  2021-11-15   \n",
       "5            3    2030-11-15     2021-11-15    2021-11-15  2021-11-15   \n",
       "6            3    2030-11-15     2021-11-15    2021-11-15  2021-11-15   \n",
       "7            3    2030-11-15     2021-11-15    2021-11-15  2021-11-15   \n",
       "\n",
       "  transaction_type sequence_number coupon issue_key      cusip  \n",
       "0                I         23765.0    5.0   1223291  830745LN3  \n",
       "1                I         23763.0    5.0   1223291  830745LN3  \n",
       "0             None            None    5.0    901018  59259YHK8  \n",
       "1             None            None    5.0    901018  59259YHK8  \n",
       "2             None            None    5.0    901018  59259YHK8  \n",
       "3             None            None    5.0    901018  59259YHK8  \n",
       "4             None            None    5.0    901018  59259YHK8  \n",
       "5             None            None    5.0    901018  59259YHK8  \n",
       "6             None            None    5.0    901018  59259YHK8  \n",
       "7             None            None    5.0    901018  59259YHK8  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Total number of trades: {len(all_trades)}')\n",
    "display(all_trades.head(10))\n",
    "display(all_trades.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update similar trades redis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN delete_all_keys_in_redis\n",
      "Attempting to delete 10 keys\n",
      "END delete_all_keys_in_redis. Execution time: 0:00:00.583588\n",
      "BEGIN update_similar_trade_history_redis\n",
      "BEGIN upload_to_redis_from_upload_function\n",
      "END upload_to_redis_from_upload_function. Execution time: 4:57:08.793376\n",
      "END update_similar_trade_history_redis. Execution time: 10:30:24.276463\n"
     ]
    }
   ],
   "source": [
    "all_trades = all_trades.sort_values(by=['trade_datetime'], ascending=False)\n",
    "all_trades['trade_date'] = all_trades['trade_datetime'].dt.date\n",
    "\n",
    "delete_all_keys_in_redis(similar_trade_history_redis_client)\n",
    "feature_groups_similar_trade_history_pairs = update_similar_trade_history_redis(all_trades)\n",
    "\n",
    "all_trades = all_trades.drop(columns='trade_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for similar_trades_feature_group in similar_trade_history_redis_client.scan_iter():\n",
    "    print(similar_trades_feature_group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
