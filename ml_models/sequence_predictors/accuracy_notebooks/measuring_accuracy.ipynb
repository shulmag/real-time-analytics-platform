{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358ab8fd",
   "metadata": {},
   "source": [
    "## Yield Spread model\n",
    "\n",
    "This notebooks measures the accuracy on the cusips for clark capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58de4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pandarallel with 16.0 cores\n",
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, NON_CAT_FEATURES, BINARY, CATEGORICAL_FEATURES, IDENTIFIERS, PURPOSE_CLASS_DICT\n",
    "from ficc.utils.gcp_storage_functions import upload_data, download_data\n",
    "from ficc.utils.auxiliary_variables import RELATED_TRADE_BINARY_FEATURES, RELATED_TRADE_NON_CAT_FEATURES, RELATED_TRADE_CATEGORICAL_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dbb1703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 22:59:06.586599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-08 22:59:06.598161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-08 22:59:06.598989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae670dc",
   "metadata": {},
   "source": [
    "Setting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c11246",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"../ahmad_creds.json\"\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e0be5",
   "metadata": {},
   "source": [
    "Initializing BigQuery client and GCP storage client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1d17e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e06a8d",
   "metadata": {},
   "source": [
    "Declaring hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767f6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.85\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 1000\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "DROPOUT = 0.10\n",
    "SEQUENCE_LENGTH = 5\n",
    "NUM_FEATURES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb809f8",
   "metadata": {},
   "source": [
    "Checking if the treasury spreads and target attention features are present in PREDICTORS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338b5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ficc_treasury_spread' not in PREDICTORS:\n",
    "    PREDICTORS.append('ficc_treasury_spread')\n",
    "    NON_CAT_FEATURES.append('ficc_treasury_spread')\n",
    "if 'target_attention_features' not in PREDICTORS:\n",
    "    PREDICTORS.append('target_attention_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e08df",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "We grab the data from a GCP bucket. The data is prepared using the ficc python package. More insight on how the data is prepared can be found [here](https://github.com/Ficc-ai/ficc/blob/ahmad_ml/ml_models/sequence_predictors/data_prep/data_preparation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c7302a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 ms, sys: 5.88 ms, total: 113 ms\n",
      "Wall time: 320 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem(project='eng-reactor-287421')\n",
    "with fs.open('ahmad_data/processed_data_574193KN7_2020.pkl') as f:\n",
    "    data = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7edca2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[-27.12332287833499, 226.2, 4.176091194152832...\n",
       "Name: trade_history, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trade_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6c17c",
   "metadata": {},
   "source": [
    "#### Date range for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5680e3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-03-20 00:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trade_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "548f2ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-03-20 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trade_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859c0b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricting history to 5 trades\n"
     ]
    }
   ],
   "source": [
    "print(f'Restricting history to {SEQUENCE_LENGTH} trades')\n",
    "data.trade_history = data.trade_history.apply(lambda x: x[:SEQUENCE_LENGTH])\n",
    "data.target_attention_features = data.target_attention_features.apply(lambda x:x[:SEQUENCE_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c81c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trade_history.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3131cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_attention_features.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c937dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('trade_datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df935f50",
   "metadata": {},
   "source": [
    "We don't give a predictions if yield is greater than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d59af044",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['yield'] < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "020cf2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f524c3",
   "metadata": {},
   "source": [
    "### Creating features from trade history\n",
    "\n",
    "This implementation is an adaption of Charles's implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a533c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttype_dict = { (0,0):'D', (0,1):'S', (1,0):'P' }\n",
    "\n",
    "ys_variants = [\"max_ys\", \"min_ys\", \"max_qty\", \"min_ago\", \"D_min_ago\", \"P_min_ago\", \"S_min_ago\"]\n",
    "ys_feats = [\"_ys\", \"_ttypes\", \"_ago\", \"_qdiff\"]\n",
    "D_prev = dict()\n",
    "P_prev = dict()\n",
    "S_prev = dict()\n",
    "\n",
    "def get_trade_history_columns():\n",
    "    '''\n",
    "    This function is used to create a list of columns\n",
    "    '''\n",
    "    YS_COLS = []\n",
    "    for prefix in ys_variants:\n",
    "        for suffix in ys_feats:\n",
    "            YS_COLS.append(prefix + suffix)\n",
    "    return YS_COLS\n",
    "\n",
    "def extract_feature_from_trade(row, name, trade):\n",
    "    yield_spread = trade[0]\n",
    "    ttypes = ttype_dict[(trade[3],trade[4])] + row.trade_type\n",
    "    seconds_ago = trade[5]\n",
    "    quantity_diff = np.log10(1 + np.abs(10**trade[2] - 10**row.quantity))\n",
    "    return [yield_spread, ttypes,  seconds_ago, quantity_diff]\n",
    "\n",
    "def trade_history_derived_features(row):\n",
    "    trade_history = row.trade_history\n",
    "    trade = trade_history[0]\n",
    "    \n",
    "    D_min_ago_t = D_prev.get(row.cusip,trade)\n",
    "    D_min_ago = 9        \n",
    "\n",
    "    P_min_ago_t = P_prev.get(row.cusip,trade)\n",
    "    P_min_ago = 9\n",
    "    \n",
    "    S_min_ago_t = S_prev.get(row.cusip,trade)\n",
    "    S_min_ago = 9\n",
    "    \n",
    "    max_ys_t = trade; max_ys = trade[0]\n",
    "    min_ys_t = trade; min_ys = trade[0]\n",
    "    max_qty_t = trade; max_qty = trade[2]\n",
    "    min_ago_t = trade; min_ago = trade[5]\n",
    "    \n",
    "    for trade in trade_history[0:]:\n",
    "        #Checking if the first trade in the history is from the same block\n",
    "        if trade[5] == 0: \n",
    "            continue\n",
    " \n",
    "        if trade[0] > max_ys: \n",
    "            max_ys_t = trade\n",
    "            max_ys = trade[0]\n",
    "        elif trade[0] < min_ys: \n",
    "            min_ys_t = trade; \n",
    "            min_ys = trade[0]\n",
    "\n",
    "        if trade[2] > max_qty: \n",
    "            max_qty_t = trade \n",
    "            max_qty = trade[2]\n",
    "        if trade[5] < min_ago: \n",
    "            min_ago_t = trade; \n",
    "            min_ago = trade[5]\n",
    "            \n",
    "        side = ttype_dict[(trade[3],trade[4])]\n",
    "        if side == \"D\":\n",
    "            if trade[5] < D_min_ago: \n",
    "                D_min_ago_t = trade; D_min_ago = trade[5]\n",
    "                D_prev[row.cusip] = trade\n",
    "        elif side == \"P\":\n",
    "            if trade[5] < P_min_ago: \n",
    "                P_min_ago_t = trade; P_min_ago = trade[5]\n",
    "                P_prev[row.cusip] = trade\n",
    "        elif side == \"S\":\n",
    "            if trade[5] < S_min_ago: \n",
    "                S_min_ago_t = trade; S_min_ago = trade[5]\n",
    "                S_prev[row.cusip] = trade\n",
    "        else: \n",
    "            print(\"invalid side\", trade)\n",
    "    \n",
    "    trade_history_dict = {\"max_ys\":max_ys_t,\n",
    "                          \"min_ys\":min_ys_t,\n",
    "                          \"max_qty\":max_qty_t,\n",
    "                          \"min_ago\":min_ago_t,\n",
    "                          \"D_min_ago\":D_min_ago_t,\n",
    "                          \"P_min_ago\":P_min_ago_t,\n",
    "                          \"S_min_ago\":S_min_ago_t}\n",
    "\n",
    "    return_list = []\n",
    "    for variant in ys_variants:\n",
    "        feature_list = extract_feature_from_trade(row,variant,trade_history_dict[variant])\n",
    "        return_list += feature_list\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8ce568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 ms, sys: 32.9 ms, total: 56 ms\n",
      "Wall time: 73.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "YS_COLS = get_trade_history_columns()\n",
    "temp = data[['cusip','trade_history','quantity','trade_type']].parallel_apply(trade_history_derived_features, axis=1)\n",
    "data[YS_COLS] = pd.DataFrame(temp.tolist(), index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad9fd2",
   "metadata": {},
   "source": [
    "Adding trade history features to PREDICTORS list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70a7f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in YS_COLS:\n",
    "    if 'ttypes' in col and col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "    elif col not in PREDICTORS:\n",
    "        NON_CAT_FEATURES.append(col)\n",
    "        PREDICTORS.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f457d",
   "metadata": {},
   "source": [
    "This feature is used to check if there are any NaN values in the trade history. **It is not used to train the model**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13523b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "CPU times: user 12.3 ms, sys: 27 ms, total: 39.2 ms\n",
      "Wall time: 59 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(len(data))\n",
    "data['trade_history_sum'] = data.trade_history.parallel_apply(lambda x: np.sum(x))\n",
    "data = data.dropna(subset=['trade_history_sum'])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258f7c4",
   "metadata": {},
   "source": [
    "For the purpose of plotting, not used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d69d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.purpose_sub_class.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf9900",
   "metadata": {},
   "source": [
    "Creating new ys label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbdcd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_ys'] = data['yield'] - data['new_ficc_ycl']\n",
    "# data['diff_ys'] = data['new_ys'] - data['last_yield_spread']\n",
    "# data['new_ys'] = data['yield'] - data['new_real_time_ficc_ycl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cd4f26",
   "metadata": {},
   "source": [
    "Adding additional features proposed by Charles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b123b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.last_trade_date = pd.to_datetime(data.last_trade_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3705614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['last_duration'] = (data.last_calc_date - data.last_trade_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e913e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(coupon, ytw, years, dollar_price, peryear=2):\n",
    "    ytw = ytw.clip(0.001,np.inf)\n",
    "    c = (coupon/100) / peryear\n",
    "    y = (ytw/10000) / peryear\n",
    "    n = years * peryear\n",
    "    m = peryear\n",
    "    macaulay_duration = ((1+y) / (m*y)) - ( (1 + y + n*(c-y)) / ((m*c* ((1+y)**n - 1)) + m*y))\n",
    "    modified_duration = macaulay_duration / (1 + y)\n",
    "    dv01 = modified_duration * dollar_price / 10000\n",
    "    return dv01\n",
    "\n",
    "def add_additional_feature(data):\n",
    "    data['diff_ficc_ycl'] = data.new_ficc_ycl - data.last_ficc_ycl\n",
    "    data['diff_ficc_treasury_spread'] = data.last_ficc_ycl - (data.treasury_rate * 100)\n",
    "    data['dv01'] = duration(data.coupon, data.last_yield, data.last_duration, data.last_dollar_price)\n",
    "    data['approx_dpd'] =  data.dv01 * data.diff_ficc_ycl\n",
    "    data['overage'] =  (data.last_dollar_price + data.approx_dpd - data.next_call_price)\n",
    "    #data['de_minimis_gap'] = data.last_dollar_price - data.de_minimis_threshold\n",
    "    return data\n",
    "\n",
    "# data = add_additional_feature(data)\n",
    "# additional_features = ['diff_ficc_ycl','diff_ficc_treasury_spread','dv01','approx_dpd','overage']#,'de_minimis_gap']\n",
    "# for i in additional_features:\n",
    "#     if i not in NON_CAT_FEATURES:\n",
    "#         NON_CAT_FEATURES.append(i)\n",
    "#         PREDICTORS.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96b6f7",
   "metadata": {},
   "source": [
    "Selecting a subset of features for training. PREDICTORS are the features that we are going to use to train the model. More information about the feature set can be found [here](https://github.com/Ficc-ai/ficc_python/blob/d455bd30eca18f26a2535523530facad516dd90f/ficc/utils/auxiliary_variables.py#L120). We also select a set of additonal features, which are not used in training. These features are used to uderstand the results from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37a71950",
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_features = ['dollar_price',\n",
    "                     'calc_date', \n",
    "                     'trade_date',\n",
    "                     'trade_datetime', \n",
    "                     'purpose_sub_class', \n",
    "                     'called_redemption_type', \n",
    "                     'calc_day_cat',\n",
    "                     'yield',\n",
    "                     'ficc_ycl',\n",
    "                     'new_ys',\n",
    "                     'trade_history_sum',\n",
    "                     'new_ficc_ycl',\n",
    "                     'days_to_refund',\n",
    "                     'last_dollar_price',\n",
    "                     'last_rtrs_control_number',\n",
    "                     'is_called',\n",
    "                     'federal_tax_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bfbe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = data[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6fd0a",
   "metadata": {},
   "source": [
    "Checking for missing data and NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "094bf076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_data))\n",
    "processed_data.issue_amount = processed_data.issue_amount.replace([np.inf, -np.inf], np.nan)\n",
    "processed_data.dropna(inplace=True, subset=PREDICTORS)\n",
    "print(len(processed_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "985080c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.sort_values('trade_datetime',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408fd7c1",
   "metadata": {},
   "source": [
    "#### Loading encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78109e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoders.pkl  encoders_test.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls encoders*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd71ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encoders_test.pkl','rb') as f:\n",
    "    encoders_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0967a154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DD', 'DP', 'DS', 'PD', 'PP', 'PS', 'SD', 'SP', 'SS'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders_test['max_ys_ttypes'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af0f1472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders_test['max_ys_ttypes'].transform(['DD', 'DP', 'DS', 'PD', 'PP', 'PS', 'SD', 'SP', 'SS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd764f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/shayaan/ficc_python/encoders.pkl','rb') as f:\n",
    "    encoders = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aba33f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DD', 'DP', 'DS', 'PD', 'PP', 'PS', 'SD', 'SP', 'SS'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['max_ys_ttypes'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9bd6950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders['max_ys_ttypes'].transform(['DD', 'DP', 'DS', 'PD', 'PP', 'PS', 'SD', 'SP', 'SS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e51eae",
   "metadata": {},
   "source": [
    "#### Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89ac40af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82f60c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_data = processed_data[(processed_data.days_to_call == 0) | (processed_data.days_to_call > np.log10(400))]\n",
    "# processed_data = processed_data[(processed_data.days_to_refund == 0) | (processed_data.days_to_refund > np.log10(400))]\n",
    "# processed_data = processed_data[(processed_data.days_to_maturity == 0) | (processed_data.days_to_maturity > np.log10(400))]\n",
    "# processed_data = processed_data[processed_data.days_to_maturity < np.log10(30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "089a4c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86081f1",
   "metadata": {},
   "source": [
    "##### Converting data into format suitable for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1e5fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(df):\n",
    "    global encoders\n",
    "    datalist = []\n",
    "    datalist.append(np.stack(df['trade_history'].to_numpy()))\n",
    "    datalist.append(np.stack(df['target_attention_features'].to_numpy()))\n",
    "\n",
    "    noncat_and_binary = []\n",
    "    for f in NON_CAT_FEATURES + BINARY:\n",
    "        noncat_and_binary.append(np.expand_dims(df[f].to_numpy().astype('float32'), axis=1))\n",
    "    datalist.append(np.concatenate(noncat_and_binary, axis=-1))\n",
    "    \n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        encoded = encoders[f].transform(df[f])\n",
    "        datalist.append(encoded.astype('float32'))\n",
    "    \n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2b65617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.87 ms, sys: 546 Âµs, total: 5.42 ms\n",
      "Wall time: 4.52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_test = create_input(processed_data)\n",
    "y_test = processed_data.new_ys\n",
    "#y_train = train_dataframe.diff_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2acd830e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13728/2740700681.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edce11e",
   "metadata": {},
   "source": [
    "### Load model and measure accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90643b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_spread_model = keras.models.load_model('model-11-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79ba6df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 5, 6) dtype=float32 (created by layer 'trade_history_input')>,\n",
       " <KerasTensor: shape=(None, 1, 3) dtype=float32 (created by layer 'target_attention_input')>,\n",
       " <KerasTensor: shape=(None, 48) dtype=float32 (created by layer 'NON_CAT_AND_BINARY_FEATURES')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'rating')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'incorporated_state_code')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'trade_type')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'purpose_class')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'max_ys_ttypes')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'min_ys_ttypes')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'max_qty_ttypes')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'min_ago_ttypes')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'D_min_ago_ttypes')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'P_min_ago_ttypes')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'S_min_ago_ttypes')>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_spread_model.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "110ca109",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input = [[[[0.7264585614102543, -31.0, 6.698969841003418, 0.0, 0.0, 4.426657628095805], [0.7264585614102543, -31.0, 6.698969841003418, 0.0, 1.0, 4.426657628095805], [10.755671322886258, -21.0, 5.0, 0.0, 1.0, 4.468952557265534], [4.029871021978522, -34.0, 6.698969841003418, 0.0, 0.0, 5.035429738184549], [4.029871021978522, -34.0, 6.698969841003418, 1.0, 0.0, 5.035429738184549]], [[0.7264585614102543, -31.0, 6.698969841003418, 0.0, 0.0, 4.426657628095805], [0.7264585614102543, -31.0, 6.698969841003418, 0.0, 1.0, 4.426657628095805], [10.755671322886258, -21.0, 5.0, 0.0, 1.0, 4.468952557265534], [4.029871021978522, -34.0, 6.698969841003418, 0.0, 0.0, 5.035429738184549], [4.029871021978522, -34.0, 6.698969841003418, 1.0, 0.0, 5.035429738184549]]], [[[5.698969841003418, 0.0, 1.0]], [[5.698969841003418, 1.0, 0.0]]], [[5.698969841003418, 3.8943714538562375, 3.4058583993176366, 4.0, 8.929418563842773, 26708.0, 0.7264585614102543, 5.0, 3.4058583993176366, 8.382107137620704, 111.09, 8.382107137620704, 8.382107137620704, 1253.0, 180.0, 0.06666666666666667, -33.48258594541255, 10.755671322886258, 4.468952557265534, 5.602060872897559, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 4.029871021978522, 5.035429738184549, 6.6532124469526535, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.698969841003418, 3.8943714538562375, 3.4058583993176366, 4.0, 8.929418563842773, 26708.0, 0.7264585614102543, 5.0, 3.4058583993176366, 8.382107137620704, 111.09, 8.382107137620704, 8.382107137620704, 1253.0, 180.0, 0.06666666666666667, -33.48258594541255, 10.755671322886258, 4.468952557265534, 5.602060872897559, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 4.029871021978522, 5.035429738184549, 6.6532124469526535, 0.7264585614102543, 4.426657628095805, 6.6532124469526535, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], [6.0, 6.0], [37.0, 37.0], [2.0, 1.0], [46.0, 46.0], [8.0, 7.0], [2.0, 1.0], [2.0, 1.0], [2.0, 1.0], [2.0, 1.0], [5.0, 4.0], [8.0, 7.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5273885",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp_input)):\n",
    "    temp_input[i] = np.array(temp_input[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "249c440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[  0.72645856, -31.        ,   6.69896984,   0.        ,\n",
       "            0.        ,   4.42665763],\n",
       "         [  0.72645856, -31.        ,   6.69896984,   0.        ,\n",
       "            1.        ,   4.42665763],\n",
       "         [ 10.75567132, -21.        ,   5.        ,   0.        ,\n",
       "            1.        ,   4.46895256],\n",
       "         [  4.02987102, -34.        ,   6.69896984,   0.        ,\n",
       "            0.        ,   5.03542974],\n",
       "         [  4.02987102, -34.        ,   6.69896984,   1.        ,\n",
       "            0.        ,   5.03542974]],\n",
       " \n",
       "        [[  0.72645856, -31.        ,   6.69896984,   0.        ,\n",
       "            0.        ,   4.42665763],\n",
       "         [  0.72645856, -31.        ,   6.69896984,   0.        ,\n",
       "            1.        ,   4.42665763],\n",
       "         [ 10.75567132, -21.        ,   5.        ,   0.        ,\n",
       "            1.        ,   4.46895256],\n",
       "         [  4.02987102, -34.        ,   6.69896984,   0.        ,\n",
       "            0.        ,   5.03542974],\n",
       "         [  4.02987102, -34.        ,   6.69896984,   1.        ,\n",
       "            0.        ,   5.03542974]]]),\n",
       " array([[[5.69896984, 0.        , 1.        ]],\n",
       " \n",
       "        [[5.69896984, 1.        , 0.        ]]]),\n",
       " array([[ 5.69896984e+00,  3.89437145e+00,  3.40585840e+00,\n",
       "          4.00000000e+00,  8.92941856e+00,  2.67080000e+04,\n",
       "          7.26458561e-01,  5.00000000e+00,  3.40585840e+00,\n",
       "          8.38210714e+00,  1.11090000e+02,  8.38210714e+00,\n",
       "          8.38210714e+00,  1.25300000e+03,  1.80000000e+02,\n",
       "          6.66666667e-02, -3.34825859e+01,  1.07556713e+01,\n",
       "          4.46895256e+00,  5.60206087e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  4.02987102e+00,\n",
       "          5.03542974e+00,  6.65321245e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  1.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [ 5.69896984e+00,  3.89437145e+00,  3.40585840e+00,\n",
       "          4.00000000e+00,  8.92941856e+00,  2.67080000e+04,\n",
       "          7.26458561e-01,  5.00000000e+00,  3.40585840e+00,\n",
       "          8.38210714e+00,  1.11090000e+02,  8.38210714e+00,\n",
       "          8.38210714e+00,  1.25300000e+03,  1.80000000e+02,\n",
       "          6.66666667e-02, -3.34825859e+01,  1.07556713e+01,\n",
       "          4.46895256e+00,  5.60206087e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  4.02987102e+00,\n",
       "          5.03542974e+00,  6.65321245e+00,  7.26458561e-01,\n",
       "          4.42665763e+00,  6.65321245e+00,  1.00000000e+00,\n",
       "          1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]),\n",
       " array([6., 6.]),\n",
       " array([37., 37.]),\n",
       " array([2., 1.]),\n",
       " array([46., 46.]),\n",
       " array([8., 7.]),\n",
       " array([2., 1.]),\n",
       " array([2., 1.]),\n",
       " array([2., 1.]),\n",
       " array([2., 1.]),\n",
       " array([5., 4.]),\n",
       " array([8., 7.])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75c97cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 23:10:14.079025: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14488961024 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.7875898],\n",
       "       [ 2.8818445]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_spread_model.predict(temp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ef980f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_spread_model_old = keras.models.load_model('/home/shayaan/ficc_python/model-11-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df19c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 23:04:08.883841: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14488961024 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.7058502],\n",
       "       [ 3.5071597]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_spread_model_old.predict(temp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4006bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 20:16:51.449404: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14488961024 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-10-24 20:16:55.545527: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n"
     ]
    }
   ],
   "source": [
    "processed_data['predicted_ys'] = yield_spread_model.predict(x_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "259903ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['predicted_ytw'] = processed_data['new_ficc_ycl'] + processed_data['predicted_ys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b68e3c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE yield spread model: 12.422\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE yield spread model: {round(np.mean(np.abs(processed_data.predicted_ytw - processed_data['yield'])), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "358326b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAD yield spread model: 12.422\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAD yield spread model: {round(np.median(np.abs(processed_data.predicted_ytw - processed_data['yield'])), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2207600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ficc.pricing.price import compute_price\n",
    "def get_trade_price(trade):\n",
    "    # compute price does not need to return the calc_date, if we are using the calc_date model: \n",
    "    price, _ = compute_price(trade, trade.predicted_ytw/100)\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6d4125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['predicted_price'] = processed_data.apply(lambda x: get_trade_price(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29055304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>last_trade_date</th>\n",
       "      <th>predicted_price</th>\n",
       "      <th>predicted_ytw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>574193KN7</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>103.663</td>\n",
       "      <td>276.264069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cusip last_trade_date  predicted_price  predicted_ytw\n",
       "0  574193KN7      2022-11-07          103.663     276.264069"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[['cusip','last_trade_date','predicted_price','predicted_ytw']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2bb30f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>last_trade_date</th>\n",
       "      <th>predicted_price</th>\n",
       "      <th>predicted_ytw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>574193KN7</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>109.179</td>\n",
       "      <td>275.277859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cusip last_trade_date  predicted_price  predicted_ytw\n",
       "0  574193KN7      2020-03-20          109.179     275.277859"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[['cusip','last_trade_date','predicted_price','predicted_ytw']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0af14e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "377fee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/964018767272/locations/us-east4/models/7659154018622504960\"\n",
      "display_name: \"model-11-08-ys\"\n",
      "predict_schemata {\n",
      "}\n",
      "metadata {\n",
      "}\n",
      "container_spec {\n",
      "  image_uri: \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-7:latest\"\n",
      "}\n",
      "supported_deployment_resources_types: DEDICATED_RESOURCES\n",
      "supported_deployment_resources_types: 3\n",
      "supported_input_storage_formats: \"jsonl\"\n",
      "supported_input_storage_formats: \"bigquery\"\n",
      "supported_input_storage_formats: \"csv\"\n",
      "supported_input_storage_formats: \"tf-record\"\n",
      "supported_input_storage_formats: \"tf-record-gzip\"\n",
      "supported_input_storage_formats: \"file-list\"\n",
      "supported_output_storage_formats: \"jsonl\"\n",
      "supported_output_storage_formats: \"bigquery\"\n",
      "create_time {\n",
      "  seconds: 1699486243\n",
      "  nanos: 108601000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1699486248\n",
      "  nanos: 807307000\n",
      "}\n",
      "deployed_models {\n",
      "  endpoint: \"projects/964018767272/locations/us-east4/endpoints/4283882019768762368\"\n",
      "  deployed_model_id: \"7922772926498078720\"\n",
      "}\n",
      "etag: \"AMEw9yOv-5MqPa_eaO_zLAk8lzgz9Dl6mb94hqp2w6jmHZsEJ7rIDpZQVuCQYEuUvJjm\"\n",
      "supported_export_formats {\n",
      "  id: \"custom-trained\"\n",
      "  exportable_contents: ARTIFACT\n",
      "}\n",
      "artifact_uri: \"gs://automated_training/model-11-08-ys/\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "project_id = \"964018767272\"\n",
    "location = \"us-east4\"  # Change to your model's location\n",
    "model_id = \"7659154018622504960\"  # Change to your model's ID\n",
    "\n",
    "# Initialize the Vertex AI client\n",
    "client = aiplatform.gapic.ModelServiceClient(client_options={\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"})\n",
    "\n",
    "# Get the model's metadata\n",
    "model_name = f\"projects/{project_id}/locations/{location}/models/{model_id}\"\n",
    "response = client.get_model(name=model_name)\n",
    "\n",
    "# Print the model metadata\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809496e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m78"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
