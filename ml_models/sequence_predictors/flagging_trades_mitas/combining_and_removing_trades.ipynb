{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ficc.utils.auxiliary_variables import SPECIAL_CONDITIONS\n",
    "from ficc.utils.adding_flags import get_most_recent_index_and_others, SPECIAL_CONDITIONS_TO_FILTER_ON\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../../../../ficc/ml_models/sequence_predictors/')\n",
    "\n",
    "from yield_spread_model_mitas.data_prep import get_datestring_from_filename, \\\n",
    "                                               replace_rating_with_standalone_rating, \\\n",
    "                                               remove_rows_with_feature_value\n",
    "\n",
    "from rating_model_mitas.data_prep import read_processed_file_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silence the following warning: `SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: Reading from processed file at ../data/processed_data_2022-06-13-19-19.pkl\n",
      "END: Reading from processed file at ../data/processed_data_2022-06-13-19-19.pkl\n",
      "CPU times: user 2.53 s, sys: 1.64 s, total: 4.17 s\n",
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_file_pickle = '../data/processed_data_2022-06-13-19-19.pkl'\n",
    "processed_file_pickle_datestring = get_datestring_from_filename(processed_file_pickle)\n",
    "trade_data = read_processed_file_pickle(processed_file_pickle)\n",
    "# ensure that all column names are unique\n",
    "assert len(trade_data.columns) == len(set(trade_data)), 'Not all column names are unique'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = trade_data[(trade_data.days_to_call == 0) | (trade_data.days_to_call > np.log10(400))]\n",
    "trade_data = trade_data[(trade_data.days_to_refund == 0) | (trade_data.days_to_refund > np.log10(400))]\n",
    "trade_data = trade_data[trade_data.days_to_maturity < np.log10(30000)]\n",
    "trade_data = trade_data[trade_data.sinking == False]\n",
    "trade_data = trade_data[trade_data.incorporated_state_code != 'VI']\n",
    "trade_data = trade_data[trade_data.incorporated_state_code != 'GU']\n",
    "trade_data = trade_data[(trade_data.coupon_type == 8)]\n",
    "trade_data = trade_data[trade_data.is_called == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(df[\"purpose_sub_class\"] != 6) & (df[\"purpose_sub_class\"] != 20) & (df[\"purpose_sub_class\"] != 21) & (df[\"purpose_sub_class\"] != 22) & (df[\"purpose_sub_class\"] != 44) & (df[\"purpose_sub_class\"] != 57) & (df[\"purpose_sub_class\"] != 90) & (df[\"purpose_sub_class\"] != 106)\n",
      "39566 rows had purpose_sub_class in [6, 20, 21, 22, 44, 57, 90, 106] and were removed\n",
      "(df[\"called_redemption_type\"] != 18) & (df[\"called_redemption_type\"] != 19)\n",
      "11590 rows had called_redemption_type in [18, 19] and were removed\n"
     ]
    }
   ],
   "source": [
    "# restructured bonds and high chance of default bonds are removed\n",
    "trade_data = remove_rows_with_feature_value(trade_data, 'purpose_sub_class', [6, 20, 21, 22, 44, 57, 90, 106])\n",
    "# pre-refunded bonds and partially refunded bonds are removed\n",
    "trade_data = remove_rows_with_feature_value(trade_data, 'called_redemption_type', [18, 19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = replace_rating_with_standalone_rating(trade_data)\n",
    "trade_data_original = trade_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trades: 2401047\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of trades: {len(trade_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_OF_INTEREST = ['cusip', 'quantity', 'dollar_price', 'trade_datetime', 'trade_type']\n",
    "IDENTIFIERS = ['cusip', 'rtrs_control_number']\n",
    "ALL_IMPORTANT_FEATURES = list(set().union(FEATURES_OF_INTEREST + IDENTIFIERS + SPECIAL_CONDITIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecessary columns speeds up the upcoming `groupby` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data_select_features = trade_data[ALL_IMPORTANT_FEATURES]\n",
    "trade_data_select_features['brokers_broker'] = trade_data_select_features['brokers_broker'].astype('string').fillna('none')    # replace the NaN value with 'none' so that we can use groupby (groupby doesn't work for NaN even with the dropna flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining and removing trades\n",
    "Currently, we are only combining (with other trades) and removing trades (based on other trades) that occur on the same day as the other trades. We assume that two trades occur *around* the same time, if the two trades occur on the same day.\n",
    "## Combining trades\n",
    "1. If two or more non-interdealer trades (occurring at around the same time) have the same price and direction, and the same flags, they can be combined together. We combine the group of trades by updating the quantity of the most recent trade to sum of the quantities in the group, and remove all but the most recent trade. Note that we can still combine trades even if there are other trades (for the same CUSIP) in between the trades that we are trying to combine.\n",
    "## Removing trades\n",
    "1. If two or more inter-dealer trades (occurring at around the same time) have the same price and the same flags, only the most recent one can be kept since this can be interpreted as a series of trades between related legal entities.\n",
    "2. If two trades (occurring at around the same time) have the same price and same trade amount, and one of the trades is an inter-dealer trade, and the other one is not and has a non-transaction-based compensation flag, then only the inter-dealer trade is the meaningful trade.\n",
    "3. If two trades (occurring at around the same time) have the same price and same trade amount, and one of the trades is an inter-dealer trade, and the other trade is not and does not have a non-transaction-based compensation flag, then only the other trade is the meaningful trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups: 115504\n",
      "CPU times: user 1min 3s, sys: 885 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip', 'trade_type'] + SPECIAL_CONDITIONS_TO_FILTER_ON)\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups: 27375\n"
     ]
    }
   ],
   "source": [
    "groups_same_day_quantity_price_cusip_tradetype_flags_nonDD = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags.items() if set(group_df['trade_type']) == {'S'} or set(group_df['trade_type']) == {'P'}}\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_nonDD)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_trades(df, group_df):\n",
    "    most_recent_trade_index, indices_to_remove = get_most_recent_index_and_others(group_df)\n",
    "    new_total_quantity = np.log10(sum(10 ** group_df['quantity']))    # undo log10 transformation before sum and reapply log10 transformation after sum\n",
    "    df.loc[most_recent_trade_index]['quantity'] = new_total_quantity\n",
    "    return df, indices_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trades: 2361807\n",
      "CPU times: user 4min, sys: 1.13 s, total: 4min 1s\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_indices_to_remove = []\n",
    "for group_df in groups_same_day_quantity_price_cusip_tradetype_flags_nonDD.values():\n",
    "    # does it matter if there are trades in between two trades that are being combined? maybe not from discussion on CUSIP 74265LS66\n",
    "    trade_data, row_indices_to_remove = combine_trades(trade_data, group_df)\n",
    "    all_indices_to_remove.extend(row_indices_to_remove)\n",
    "trade_data = trade_data.drop(all_indices_to_remove)\n",
    "print(f'Number of trades: {len(trade_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups: 88129\n"
     ]
    }
   ],
   "source": [
    "groups_same_day_quantity_price_cusip_tradetype_flags_DD = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags.items() if set(group_df['trade_type']) == {'D'}}\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_DD)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trades: 2261999\n",
      "CPU times: user 13.9 s, sys: 1.21 s, total: 15.1 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_indices_to_remove = []\n",
    "for group_df in groups_same_day_quantity_price_cusip_tradetype_flags_DD.values():\n",
    "    _, indices_to_remove = get_most_recent_index_and_others(group_df, True)\n",
    "    all_indices_to_remove.extend(indices_to_remove)\n",
    "trade_data = trade_data.drop(all_indices_to_remove)\n",
    "print(f'Number of trades: {len(trade_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups: 333637\n",
      "CPU times: user 58.4 s, sys: 1.02 s, total: 59.4 s\n",
      "Wall time: 59.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip'])\n",
    "groups_same_day_quantity_price_cusip = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups: 213430\n"
     ]
    }
   ],
   "source": [
    "two_trades_only_one_is_dd = lambda df: len(df) == 2 and 'D' in set(df['trade_type']) and len(set(df['trade_type'])) == 2    # checks whether `df` has two trades where only one is an inter-dealer trade\n",
    "groups_same_day_quantity_price_cusip_dd_2 = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip.items() if two_trades_only_one_is_dd(group_df)}\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_dd_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trades: 2048569\n",
      "CPU times: user 1min 8s, sys: 2.05 s, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_indices_to_remove = []\n",
    "for group, group_df in groups_same_day_quantity_price_cusip_dd_2.items():\n",
    "    interdealer_trade_index = group_df[group_df['trade_type'] == 'D'].index[0]\n",
    "    other_trade = group_df[group_df['trade_type'] != 'D']\n",
    "    other_trade_index = other_trade.index[0]\n",
    "    if other_trade['is_non_transaction_based_compensation'].values[0]:    # .values[0] isolates the value for this trade\n",
    "        all_indices_to_remove.append(other_trade_index)\n",
    "    else:\n",
    "        all_indices_to_remove.append(interdealer_trade_index)\n",
    "trade_data = trade_data.drop(all_indices_to_remove)\n",
    "print(f'Number of trades: {len(trade_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trades in original dataframe: 2401047\n",
      "Number of trades after combining and removing trades: 2048569\n",
      "Number of trades removed: 352478\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of trades in original dataframe: {len(trade_data_original)}')\n",
    "print(f'Number of trades after combining and removing trades: {len(trade_data)}')\n",
    "print(f'Number of trades removed: {len(trade_data_original) - len(trade_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Grouping with flags\n",
    "*Question*: Does filtering by trade flags (i.e., special condition indicators) greatly reduce the number of groups of trades to combine?\n",
    "\n",
    "*Hypothesis*: No; I believe that the flags are not used very much. Furthermore, I believe that trades that should be combined should have all the same flags.\n",
    "\n",
    "*Results*: When adding in the flags `is_non_transaction_based_compensation` and `is_lop_or_takedown`, there is minimal reduction of groups (goes from 116,663 to 116,194). When adding in the `is_alternative_trading_system` flag, the number of groups drops by about 40% (goes from 116,194 to 73,373). When adding in the `brokers_broker` flag, since most values are `NaN`, this causes the `groupby` command to ignore these groups, and the groups drop dramatically. The `dropna` argument does not work in `groupby` which is a bug in pandas (this was supposedly fixed in more recent versions of pandas, but it still doesn't work for me even with the most up to date version of 1.4.3). \n",
    "\n",
    "*Conclusions*: By including certain flags, the number of groups does drop dramatically, so my hypothesis as a whole was incorrect.\n",
    "\n",
    "*Future work*: This begs the following two questions: (1) can we group trades where one of them was done with the `is_alternative_trading_system` flag and one without?, and (2) what is the best way to handle `NaN` values for `brokers_broker`, i.e., what does `NaN` mean for `brokers_broker`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip', 'trade_type'])\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags_test if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip', 'trade_type'] + ['is_non_transaction_based_compensation'])\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags_test if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip', 'trade_type'] + ['is_non_transaction_based_compensation', 'is_lop_or_takedown'])\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags_test if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip', 'trade_type'] + ['is_non_transaction_based_compensation', 'is_lop_or_takedown', 'brokers_broker'])\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags_test if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip', 'trade_type'] + ['is_non_transaction_based_compensation', 'is_lop_or_takedown', 'is_alternative_trading_system'])\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags_test if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip', 'trade_type'] + ['brokers_broker'])\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags_test if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = trade_data_select_features.groupby([pd.Grouper(key='trade_datetime', freq='1D'), 'quantity', 'dollar_price', 'cusip', 'trade_type'] + ['brokers_broker'], dropna=False)\n",
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = {group_key: group_df for group_key, group_df in groups_same_day_quantity_price_cusip_tradetype_flags_test if len(group_df) > 1}    # removes groups with only 1 item since this is not really a group\n",
    "print(f'Number of groups: {len(groups_same_day_quantity_price_cusip_tradetype_flags_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_same_day_quantity_price_cusip_tradetype_flags_test = trade_data_select_features.groupby(['brokers_broker'], dropna=False)\n",
    "for group, group_df in groups_same_day_quantity_price_cusip_tradetype_flags_test:\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trade_data_select_features['brokers_broker'].value_counts(dropna=False))\n",
    "print(trade_data_select_features['is_alternative_trading_system'].value_counts(dropna=False))\n",
    "print(trade_data_select_features['is_lop_or_takedown'].value_counts(dropna=False))\n",
    "print(trade_data_select_features['is_non_transaction_based_compensation'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code / testing / sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [1, 1, 3], 'b': [1, 5, 6], 'c': [7, 8, 6], 'd': [1, 1, 3]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby(['a', 'd'])\n",
    "all_indices_to_remove = []\n",
    "for group, group_df in groups:\n",
    "    indices_to_remove = group_df.index.to_list()\n",
    "    most_recent_trade_index = indices_to_remove.pop()\n",
    "    print(most_recent_trade_index)\n",
    "    print(df)\n",
    "    df.loc[most_recent_trade_index]['c'] = sum(group_df['c'])\n",
    "    all_indices_to_remove.extend(indices_to_remove)\n",
    "df = df.drop(all_indices_to_remove)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 2], [4, 5], [7, 8]], index=['cobra', 'viper', 'sidewinder'], columns=['max_speed', 'shield'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['viper', 'sidewinder'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there are not trades that are dealer-dealer and have the `is_non_transaction_based_compensation` flag\n",
    "trade_data[trade_data['is_non_transaction_based_compensation'] & (trade_data['trade_type'] == 'D')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e18c70c74e919487903475d4b9ee892d16d9f5351cb9291a624c367bcb362da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
