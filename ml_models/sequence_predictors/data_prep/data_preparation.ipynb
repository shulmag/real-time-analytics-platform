{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd503f33",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "This notebook is used to process data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e2ea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pandarallel with 20.0 cores\n",
      "INFO: Pandarallel will run on 20 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import redis\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, NON_CAT_FEATURES, BINARY, CATEGORICAL_FEATURES, IDENTIFIERS\n",
    "from ficc.utils.gcp_storage_functions import upload_data, download_data\n",
    "from ficc.utils.nelson_siegel_model import yield_curve_level\n",
    "from ficc.utils.diff_in_days import diff_in_days_two_dates\n",
    "from ficc.utils.auxiliary_variables import NUM_OF_DAYS_IN_YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff102a",
   "metadata": {},
   "source": [
    "Stting the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91917aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/ahmad_creds.json\"\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e57d6",
   "metadata": {},
   "source": [
    "Declaring parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ad32eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 5\n",
    "#Change number of features to 7 & when using charles_data_prep\n",
    "NUM_FEATURES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d22ab7",
   "metadata": {},
   "source": [
    "Initializing BigQuery and storage client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9421b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3558d",
   "metadata": {},
   "source": [
    "#### Query to fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afde6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_QUERY = '''SELECT\n",
    "rtrs_control_number, \n",
    "cusip, \n",
    "yield, \n",
    "is_callable, \n",
    "refund_date,\n",
    "refund_price,\n",
    "accrual_date,\n",
    "dated_date, \n",
    "next_sink_date,\n",
    "coupon, \n",
    "delivery_date, \n",
    "trade_date, \n",
    "trade_datetime,\n",
    "par_call_date, \n",
    "interest_payment_frequency,\n",
    "is_called,\n",
    "is_non_transaction_based_compensation,\n",
    "is_general_obligation, \n",
    "callable_at_cav, \n",
    "extraordinary_make_whole_call,\n",
    "make_whole_call, \n",
    "has_unexpired_lines_of_credit,\n",
    "escrow_exists, \n",
    "incorporated_state_code,\n",
    "trade_type, \n",
    "par_traded, \n",
    "maturity_date, \n",
    "settlement_date, \n",
    "next_call_date, \n",
    "issue_amount, \n",
    "maturity_amount, \n",
    "issue_price, \n",
    "orig_principal_amount,\n",
    "publish_datetime,\n",
    "max_amount_outstanding, \n",
    "recent,\n",
    "dollar_price,\n",
    "calc_date,\n",
    "purpose_sub_class,\n",
    "called_redemption_type,\n",
    "calc_day_cat, \n",
    "previous_coupon_payment_date,\n",
    "instrument_primary_name, \n",
    "purpose_class,\n",
    "call_timing,\n",
    "call_timing_in_part,\n",
    "sink_frequency,\n",
    "sink_amount_type,\n",
    "issue_text,\n",
    "state_tax_status, \n",
    "series_name,\n",
    "transaction_type,\n",
    "next_call_price, \n",
    "par_call_price, \n",
    "when_issued,\n",
    "min_amount_outstanding,\n",
    "original_yield, \n",
    "par_price,\n",
    "default_indicator,\n",
    "sp_stand_alone,\n",
    "sp_long, \n",
    "moodys_long, \n",
    "coupon_type,  \n",
    "federal_tax_status,\n",
    "use_of_proceeds, \n",
    "muni_security_type,\n",
    "muni_issue_type,\n",
    "capital_type, \n",
    "other_enhancement_type,  \n",
    "next_coupon_payment_date,\n",
    "first_coupon_date, \n",
    "last_period_accrues_from_date,\n",
    "maturity_description_code,\n",
    "de_minimis_threshold\n",
    "FROM\n",
    "`eng-reactor-287421.auxiliary_views.materialized_trade_history`\n",
    "WHERE\n",
    "  yield IS NOT NULL\n",
    "  AND yield > 0\n",
    "  AND par_traded >= 10000\n",
    "  AND trade_date >= '2023-05-01'\n",
    "  AND trade_date <= '2023-07-31'\n",
    "  AND coupon_type in (8, 4, 10, 17)\n",
    "  AND capital_type <> 10\n",
    "  AND default_exists <> TRUE\n",
    "  AND most_recent_default_event IS NULL\n",
    "  AND default_indicator IS FALSE\n",
    "  AND msrb_valid_to_date > current_date -- condition to remove cancelled trades\n",
    "  AND settlement_date is not null\n",
    "  ORDER BY trade_datetime desc\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac17074",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DATA_QUERY = '''\n",
    "                SELECT\n",
    "                  *\n",
    "                FROM\n",
    "                  `eng-reactor-287421.auxiliary_views.materialized_trade_history`\n",
    "                WHERE\n",
    "                  trade_date >= '2023-08-01'\n",
    "                  AND trade_date <= '2023-08-31'\n",
    "                  AND msrb_valid_to_date > current_date -- condition to remove cancelled trades\n",
    "                  and recent[SAFE_OFFSET(0)].trade_datetime <'2021-08-01'\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baed2315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_QUERY = '''SELECT\n",
    "#     * except(most_recent_event, assumed_settlement_date)\n",
    "#   FROM\n",
    "#      --`eng-reactor-287421.auxiliary_views.materialized_trade_history` \n",
    "#        `eng-reactor-287421.jesse_test_charles_pipeline.materialized_trade_history`\n",
    "#   WHERE\n",
    "#   trade_date >= '2023-05-01'\n",
    "#   AND trade_date < '2023-07-31'\n",
    "#   --AND coupon_type in (8, 4, 10, 17)\n",
    "#   AND capital_type <> 10\n",
    "#   AND default_exists <> TRUE\n",
    "#   AND most_recent_default_event IS NULL\n",
    "#   AND default_indicator IS FALSE\n",
    "#   AND msrb_valid_to_date > current_date -- condition to remove cancelled trades\n",
    "#   AND settlement_date is not null\n",
    "#   ORDER BY trade_datetime desc \n",
    "#   '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d1b39",
   "metadata": {},
   "source": [
    "#### Data Preparation\n",
    "We grab the data from BigQuery and converts it into a format suitable for input to the model. We save the processed data as a pickle file. If the file already exists we read it from the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384a2e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_timestamp = datetime.now().strftime('%Y-%m-%d-%H:%M')\n",
    "# processed_file = f\"processed_data_{file_timestamp}.pkl\"\n",
    "# processed_file = f\"processed_data_dollar_price_{file_timestamp}.pkl\"\n",
    "processed_file = 'test_illiquid_august.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f600460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_illiquid_august.pkl'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " processed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e35a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with\n",
      " remove_short_maturity:False\n",
      " trade_history_delay:0.2\n",
      " min_trades_in_hist:0\n",
      " add_flags:False\n",
      "Grabbing yield curve params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ficc/utils/get_treasury_rate.py:23: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  globals.treasury_rate = globals.treasury_rate.transpose().to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing data from BigQuery\n",
      "Saving query and data to raw_data_2023-08-31-21:06.pkl\n",
      "Raw data contains 4174 samples\n",
      "Creating trade history\n",
      "Removing trades less than 0.2 minutes in the history\n",
      "Trade history created\n",
      "Getting last trade features\n",
      "Restricting the trade history to the 5 most recent trades\n",
      "Padding history\n",
      "Minimum number of trades required in the history 0\n",
      "Padding completed\n",
      "Processed trade history contain 4174 samples\n",
      "Calculating yield spread using ficc yield curve\n",
      "Yield spread calculated\n",
      "Processing features\n",
      "Removing trades which are settled more than a month from trade date\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of samples 4174\n",
      "CPU times: user 5.26 s, sys: 5.63 s, total: 10.9 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# with exclusions\n",
    "data = process_data(DATA_QUERY, \n",
    "                    bq_client,\n",
    "                    SEQUENCE_LENGTH,\n",
    "                    NUM_FEATURES,\n",
    "                    f\"raw_data_{file_timestamp}.pkl\",\n",
    "                    'FICC_NEW',\n",
    "                    remove_short_maturity=True,\n",
    "                    trade_history_delay = 0.2,\n",
    "                    min_trades_in_history = 0,\n",
    "                    treasury_spread = True,\n",
    "                    add_flags=False,\n",
    "                    process_rating=False,\n",
    "                    add_related_trades_bool=False,\n",
    "                    add_rtrs_in_history=False,\n",
    "                    only_dollar_price_history = False)\n",
    "\n",
    "# #Charles data file\n",
    "# #parameters as per his requests\n",
    "# data = process_data(DATA_QUERY, \n",
    "#                     bq_client,\n",
    "#                     SEQUENCE_LENGTH,\n",
    "#                     NUM_FEATURES + 2,\n",
    "#                     f\"raw_data_{file_timestamp}.pkl\",\n",
    "#                     'FICC_NEW',\n",
    "#                     remove_short_maturity=False,\n",
    "#                     trade_history_delay = 0,\n",
    "#                     min_trades_in_history = 0,\n",
    "#                     process_ratings=False,\n",
    "#                     treasury_spread = True,\n",
    "#                     add_previous_treasury_rate=True,\n",
    "#                     add_previous_treasury_difference=True,\n",
    "#                     use_last_duration=False,\n",
    "#                     add_flags=False,\n",
    "#                     add_related_trades_bool=False,\n",
    "#                     production_set=False,\n",
    "#                     add_rtrs_in_history=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec1caa9",
   "metadata": {},
   "source": [
    "Shape of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e33ddb",
   "metadata": {},
   "source": [
    "## Adding target trade features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dc3f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_mapping = {'D':[0,0], 'S':[0,1], 'P':[1,0]}\n",
    "def target_trade_processing_for_attention(row):\n",
    "    target_trade_features = []\n",
    "    target_trade_features.append(row['quantity'])\n",
    "    target_trade_features = target_trade_features + trade_mapping[row['trade_type']]\n",
    "    return np.tile(target_trade_features, (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0155214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 1.01 s, total: 1.11 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['target_attention_features'] = data.parallel_apply(target_trade_processing_for_attention, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3973de",
   "metadata": {},
   "source": [
    "## Replacing the ratings with the stand alone ratings. This is done to exclude enhancements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60364aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.sp_stand_alone.isna(), 'sp_stand_alone'] = 'NR'\n",
    "\n",
    "data.rating = data.rating.astype('str')\n",
    "data.sp_stand_alone = data.sp_stand_alone.astype('str')\n",
    "\n",
    "data.loc[(data.sp_stand_alone != 'NR'),'rating'] = data[(data.sp_stand_alone != 'NR')]['sp_stand_alone'].loc[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f9ffc",
   "metadata": {},
   "source": [
    "### Converting yield scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31c21016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.250\n",
       "1    4.088\n",
       "2    4.533\n",
       "3    4.973\n",
       "4    4.712\n",
       "Name: yield, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['yield'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a467a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['yield'] = data['yield'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fa69a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    525.0\n",
       "1    408.8\n",
       "2    453.3\n",
       "3    497.3\n",
       "4    471.2\n",
       "Name: yield, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['yield'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a98eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_illiquid_august.pkl uploaded to ahmad_data.\n"
     ]
    }
   ],
   "source": [
    "# # We don't need the yield curve coefficients when training dollar price model\n",
    "# data.to_pickle(processed_file)\n",
    "# upload_data(storage_client, 'ahmad_data',processed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6fd00c",
   "metadata": {},
   "source": [
    "# Adding yield for every possible candidate calc date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqltodf(sql, bq_client):\n",
    "    bqr = bq_client.query(sql).result()\n",
    "    return bqr.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nelson_params = sqltodf(\"select * from `eng-reactor-287421.yield_curves_v2.nelson_siegel_coef_daily` order by date desc\", bq_client)\n",
    "nelson_params.set_index(\"date\", drop=True, inplace=True)\n",
    "nelson_params = nelson_params[~nelson_params.index.duplicated(keep='first')]\n",
    "nelson_params = nelson_params.transpose().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b186cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_params = sqltodf(\"select * from`eng-reactor-287421.yield_curves_v2.standardscaler_parameters_daily` order by date desc\", bq_client)\n",
    "scalar_params.set_index(\"date\", drop=True, inplace=True)\n",
    "scalar_params = scalar_params[~scalar_params.index.duplicated(keep='first')]\n",
    "scalar_params = scalar_params.transpose().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b85bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_parameter  = sqltodf(\"SELECT *  FROM `eng-reactor-287421.yield_curves_v2.shape_parameters` order by Date desc\", bq_client)\n",
    "shape_parameter.set_index(\"Date\", drop=True, inplace=True)\n",
    "shape_parameter = shape_parameter[~shape_parameter.index.duplicated(keep='first')]\n",
    "shape_parameter = shape_parameter.transpose().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yield_for_date(row):\n",
    "    ficc_ycl_dates = []\n",
    "    for i in ['maturity_date', 'next_call_date', 'par_call_date', 'refund_date']:\n",
    "        if pd.isnull(row[i]):\n",
    "            ficc_ycl_dates.append(np.nan)\n",
    "            continue\n",
    "        target_date = row[i]\n",
    "        duration =  diff_in_days_two_dates(target_date,row['trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "        ficc_ycl_dates.append(yield_curve_level(duration, row['trade_date'].date(), nelson_params, scalar_params, shape_parameter))\n",
    "\n",
    "    return ficc_ycl_dates[0], ficc_ycl_dates[1], ficc_ycl_dates[2], ficc_ycl_dates[3] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0482eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_df = data.parallel_apply(get_yield_for_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['ficc_ycl_to_maturity','ficc_ycl_to_next_call','ficc_ycl_to_par_call', 'ficc_ycl_to_refund']] = pd.DataFrame(temp_df.to_list(), index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03642f8e",
   "metadata": {},
   "source": [
    "# Adding yield curve level for previous calc date candiates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['last_trade_date'] = data['last_trade_datetime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4da2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yield_for_last_date(row):\n",
    "    ficc_ycl_dates = []\n",
    "    for i in ['last_maturity_date', 'last_next_call_date', 'last_par_call_date', 'last_refund_date']:\n",
    "        if pd.isnull(row[i]):\n",
    "            ficc_ycl_dates.append(np.nan)\n",
    "            continue\n",
    "        target_date = row[i]\n",
    "        duration =  diff_in_days_two_dates(target_date.date(),row['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "        if row['last_trade_date'] < datetime(2021, 8, 2).date():\n",
    "            ficc_ycl_dates.append(yield_curve_level(duration, datetime(2021, 8, 3).date(), nelson_params, scalar_params, shape_parameter))\n",
    "        else:\n",
    "            ficc_ycl_dates.append(yield_curve_level(duration, row['last_trade_date'], nelson_params, scalar_params, shape_parameter))\n",
    "\n",
    "    return ficc_ycl_dates[0], ficc_ycl_dates[1], ficc_ycl_dates[2], ficc_ycl_dates[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c24c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = data.parallel_apply(get_yield_for_last_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['last_ficc_ycl_to_maturity','last_ficc_ycl_to_next_call','last_ficc_ycl_to_par_call', 'last_ficc_ycl_to_refund']] = pd.DataFrame(temp_df.to_list(), index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4443473",
   "metadata": {},
   "source": [
    "### Grabbing new ficc ycl\n",
    "New ficc ycl is the yield curve level for the current trade using the duration of the last trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yield_for_last_duration(row):\n",
    "    if row['last_calc_date'] is None or row['last_trade_date'] is None:\n",
    "        return None\n",
    "    duration =  diff_in_days_two_dates(row['last_calc_date'],row['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    ycl = yield_curve_level(duration, row['trade_date'].date(), nelson_params, scalar_params, shape_parameter)/100\n",
    "    return ycl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6afcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['new_ficc_ycl'] = data[['last_calc_date','last_settlement_date','trade_date','last_trade_date']].parallel_apply(get_yield_for_last_duration, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.new_ficc_ycl = data.new_ficc_ycl * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.new_ficc_ycl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b24b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_ys'] =  data['yield'] - data.new_ficc_ycl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9b6768",
   "metadata": {},
   "source": [
    "#### Adding the last duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_duration(row):\n",
    "    duration = diff_in_days_two_dates(row['last_calc_date'],row['last_trade_date'])/NUM_OF_DAYS_IN_YEAR\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['last_duration'] = data.parallel_apply(get_last_duration, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba1bfd1",
   "metadata": {},
   "source": [
    "#### Fixing data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851ee3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.par_traded = data.par_traded.astype(int)\n",
    "data.last_trade_date = pd.to_datetime(data.last_trade_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d03ee80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2309312"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc979c",
   "metadata": {},
   "source": [
    "## Saving and uploading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "058f7e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'processed_data_2023-08-28-22:37.pkl'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edfa060",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(processed_file)\n",
    "upload_data(storage_client, 'ahmad_data',processed_file)\n",
    "# upload_data(storage_client, 'ficc_training_data_latest',processed_file)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m78"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
