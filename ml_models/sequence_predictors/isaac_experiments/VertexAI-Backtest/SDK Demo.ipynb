{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d5e9cf-2bf5-4cbd-b1b7-144720b16cb4",
   "metadata": {},
   "source": [
    "**Last Updated 29/9/23:**\n",
    "\n",
    "The focus of this notebook is to demonstrate how to programatically configure a Vertex AI custom container job and hyperparameter tuning job. The main benefit of this is for larger jobs like backtesting model performance across several months where doing so on GCP console is troublesome. In general, the SDK is easy to use - simply instantiate a CustomJob class, pass it a dictionary of relevant parameters and if doing a HyperparameterTuningJob, pass the CustomJob as an argument to the HyperparameterTuningJob class. Some variables, such as location, can be initiated just once when initiating aiplatform, and passing it as argument to individual jobs only serves to override the original value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e35a110-fe24-4f05-9203-ff4792ca0ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utilities:\n",
    "\n",
    "Mainly, a function to clear the bigquery table for backtesting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2154b1-8631-45c9-9684-c0b5493c6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import gcsfs\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/ficc/isaac_creds.json\"\n",
    "fs = gcsfs.GCSFileSystem(project='eng-reactor-287421')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99921ce4-6271-45fe-91e5-df40ca4bea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data_from_pickle(path, bucket = 'isaac_data'):\n",
    "#     if os.path.isfile(path):\n",
    "#         print('File available, loading pickle')\n",
    "#         with open(path, 'rb') as f:\n",
    "#             data = pickle.load(f)\n",
    "#     else:\n",
    "#         print(f'File not available, downloading from cloud storage and saving to {path}')\n",
    "#         gc_path = os.path.join(bucket, path)\n",
    "#         print(gc_path)\n",
    "#         with fs.open(gc_path) as gf:\n",
    "#             data = pd.read_pickle(gf)\n",
    "#         with open(path, 'wb') as f:\n",
    "#             pickle.dump(data, f)\n",
    "#     return data\n",
    "\n",
    "# path = '/home/jupyter/ficc/ml_models/sequence_predictors/isaac_experiments/New Features/data_latest_01-08_no_exclusions.pkl'\n",
    "# data = load_data_from_pickle(path)\n",
    "\n",
    "# data.to_pickle('gs://custom-train-job-test/large_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848efb28-bce3-4d63-bb2c-4135b3435f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSchema():\n",
    "    schema = [bigquery.SchemaField(\"rtrs_control_number\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"cusip\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"trade_date\", \"DATE\"),\n",
    "                bigquery.SchemaField(\"yield\", \"FLOAT\"),\n",
    "                bigquery.SchemaField(\"new_ys\", \"FLOAT\"),\n",
    "                bigquery.SchemaField(\"new_ficc_ycl\", \"FLOAT\"),\n",
    "                bigquery.SchemaField(\"dollar_price\", \"FLOAT\"),\n",
    "                bigquery.SchemaField(\"new_ys_prediction\", \"FLOAT\"),\n",
    "             bigquery.SchemaField(\"prediction_datetime\", \"DATETIME\")]\n",
    "    return schema\n",
    "\n",
    "def uploadData(df, TABLE_ID, schema, write_disposition=\"WRITE_APPEND\"):\n",
    "    client = bigquery.Client(project='eng-reactor-287421', location=\"US\")\n",
    "    job_config = bigquery.LoadJobConfig(schema = schema, write_disposition=write_disposition)\n",
    "\n",
    "    job = client.load_table_from_dataframe(df, TABLE_ID,job_config=job_config)\n",
    "\n",
    "    try:\n",
    "        job.result()\n",
    "        print(\"BQ upload Successful\")\n",
    "    except Exception as e:\n",
    "        print(\"BQ failed to Upload\")\n",
    "        \n",
    "def clear_bq():\n",
    "    save_cols = ['rtrs_control_number', 'cusip', 'trade_date', 'dollar_price', 'yield', 'new_ficc_ycl', 'new_ys', 'new_ys_prediction', 'prediction_datetime']\n",
    "    df = pd.DataFrame(columns=save_cols)\n",
    "    uploadData(df, \n",
    "               \"eng-reactor-287421.historical_predictions_test.historical_predictions_test\",\n",
    "               getSchema(),\n",
    "               'WRITE_TRUNCATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85101701-3376-4235-940f-680df0d01a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ upload Successful\n"
     ]
    }
   ],
   "source": [
    "# CLEARS BIG QUERY TABLE BE CAREFUL WHEN RUNNING \n",
    "clear_bq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7543f-88ea-45d6-855e-4efe2e7553bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VERTEX AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf2af1e-8f9c-46e3-803c-2fd3975ff9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580eb178-0e39-4d53-8b57-193c660717c7",
   "metadata": {},
   "source": [
    "Arguments for HPT job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f1338c-554e-4c80-a98a-fd1993af8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = \"us-central1\"\n",
    "STAGING_BUCKET = \"gs://ficc-historical-results\"\n",
    "PROJECT_ID ='eng-reactor-287421'\n",
    "SERVICE_ACCOUNT = \"964018767272-compute@developer.gserviceaccount.com\"\n",
    "JOB_NAME = \"model_backtest_202301_202309\" \n",
    "CONTAINER_URI = \"us-east4-docker.pkg.dev/eng-reactor-287421/custom-train-job/ficc-historical-models:latest\"\n",
    "\n",
    "aip.init(project=PROJECT_ID,\n",
    "         staging_bucket=STAGING_BUCKET,\n",
    "         location=LOCATION)\n",
    "\n",
    "disk_spec = {\n",
    "    \"boot_disk_type\": \"pd-ssd\"  ,\n",
    "    \"boot_disk_size_gb\": 100\n",
    "}\n",
    "\n",
    "machine_spec = {\n",
    "    \"machine_type\": \"n1-highmem-16\",\n",
    "    \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "    \"accelerator_count\": 1\n",
    "}\n",
    "\n",
    "\n",
    "containerSpec = {\n",
    "    \"image_uri\": CONTAINER_URI,\n",
    "    \"args\": [\n",
    "        \"--train_months=6\",\n",
    "        \"--NUM_EPOCHS=150\",\n",
    "        \"--VALIDATION_SPLIT=0.1\",\n",
    "        \"--bucket=ficc-historical-results\",\n",
    "        \"--file=processed_data_2022-09_2023-09.pkl\",\n",
    "        \"--BATCH_SIZE=10000\",\n",
    "        \"--LEARNING_RATE=0.0007\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "worker_pool_spec = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": machine_spec,\n",
    "        \"disk_spec\": disk_spec,\n",
    "        \"container_spec\": containerSpec\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97374861-f980-4b37-bc2f-fd4d63f0ab19",
   "metadata": {},
   "source": [
    "Creating custom job with arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d49ad51-fc41-4fb7-902d-4029f418bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aip.CustomJob(display_name=JOB_NAME, \n",
    "                worker_pool_specs=worker_pool_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f028c34-00d8-43a7-a1f0-bd76e5acb584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "target_dates = pd.bdate_range('2023-03-01', '2023-06-30').strftime('%Y-%m-%d').to_list()\n",
    "print(len(target_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e34ac-ddf0-4c38-9ae5-788125228093",
   "metadata": {},
   "source": [
    "Select dates for backtesting as a hyperparameter. Vertex AI will take a different value every run. With N runs = N dates, every date will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d793a-ef84-45c3-90b4-582f8f833cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dates = [\n",
    "#     '2023-03-01',\n",
    "#                 # '2023-04-03',\n",
    "#                 '2023-05-01',\n",
    "#                 '2023-06-01',\n",
    "#                 # '2023-07-03',\n",
    "#                 # '2023-08-01',\n",
    "#                 # '2023-09-01',\n",
    "#                 '2023-09-29',\n",
    "#                 # '2023-05-29'\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af31b0b6-16dc-4ed4-867f-bf749be78628",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(target_dates)\n",
    "hpt_dates = hpt.CategoricalParameterSpec(target_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273b7a4-580e-406c-aa07-ca9d95b88f29",
   "metadata": {},
   "source": [
    "Instantiate HyperparameterTuningJob class and pass arguments, then run on correct service account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b94c48f-c7b5-40e8-b0d3-5521a2481cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpt_job = aip.HyperparameterTuningJob(\n",
    "    display_name=JOB_NAME,\n",
    "    custom_job=job,\n",
    "    metric_spec={\n",
    "        \"mae\": \"minimize\",\n",
    "    },\n",
    "    parameter_spec={\n",
    "        \"target_date\": hpt_dates,\n",
    "    },\n",
    "    max_trial_count=N,\n",
    "    parallel_trial_count=min(12,N),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ccce4c-a2d0-441f-86e2-1aac1147dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating HyperparameterTuningJob\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob created. Resource name: projects/964018767272/locations/us-central1/hyperparameterTuningJobs/6947764841490677760\n",
      "INFO:google.cloud.aiplatform.jobs:To use this HyperparameterTuningJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:hpt_job = aiplatform.HyperparameterTuningJob.get('projects/964018767272/locations/us-central1/hyperparameterTuningJobs/6947764841490677760')\n",
      "INFO:google.cloud.aiplatform.jobs:View HyperparameterTuningJob:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6947764841490677760?project=964018767272\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11799/395021863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhpt_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSERVICE_ACCOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, timeout, restart_job_on_worker_restart, tensorboard, sync)\u001b[0m\n\u001b[1;32m   1603\u001b[0m             )\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mlog_wait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_wait\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_wait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mprevious_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         _LOGGER.info(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hpt_job.run(service_account = SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3dca9-ef1e-4fc9-b3c3-676f2a60153d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
