{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5803de-86c4-457a-9fc1-d3079e144ce3",
   "metadata": {},
   "source": [
    "TRADE HISTORY LENGTH 2, WRONGLY ORDERED (DESCENDING)\n",
    "\n",
    "NO YIELD CURVE HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58de4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 20:37:29.084700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-12 20:37:29.210965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-12 20:37:29.214698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pandarallel with 16.0 cores\n",
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "TF Version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "from ficc.utils.nelson_siegel_model import *\n",
    "from ficc.utils.diff_in_days import *\n",
    "from ficc.utils.auxiliary_functions import sqltodf\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, NON_CAT_FEATURES, BINARY, CATEGORICAL_FEATURES, IDENTIFIERS, PURPOSE_CLASS_DICT, NUM_OF_DAYS_IN_YEAR\n",
    "from ficc.utils.gcp_storage_functions import upload_data, download_data\n",
    "from ficc.utils.auxiliary_variables import RELATED_TRADE_BINARY_FEATURES, RELATED_TRADE_NON_CAT_FEATURES, RELATED_TRADE_CATEGORICAL_FEATURES\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from ficc_keras_utils import *\n",
    "import ficc_keras_utils\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(f'TF Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c11246",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/ficc/isaac_creds.json\"\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()\n",
    "\n",
    "##COMMON VARIABLES\n",
    "#DATA WINDOW\n",
    "train_start = ficc_keras_utils.train_start\n",
    "train_end = ficc_keras_utils.train_end\n",
    "test_start = ficc_keras_utils.test_start\n",
    "test_end = ficc_keras_utils.test_end\n",
    "#MODEL PARAMETERS \n",
    "VALIDATION_SPLIT = ficc_keras_utils.VALIDATION_SPLIT\n",
    "LEARNING_RATE = ficc_keras_utils.LEARNING_RATE\n",
    "BATCH_SIZE = ficc_keras_utils.BATCH_SIZE\n",
    "NUM_EPOCHS = ficc_keras_utils.NUM_EPOCHS\n",
    "DROPOUT = ficc_keras_utils.DROPOUT\n",
    "\n",
    "##NOTEBOOK SPECIFIC VARIABLES \n",
    "TRADE_SEQUENCE_LENGTH = 2\n",
    "YIELD_SEQUENCE_LENGTH = 12\n",
    "NUM_FEATURES = 6\n",
    "target_variable = 'new_ys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca18089-58e8-4a2e-9c50-11898bfde236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01 2023-03-01 2023-03-01 2023-04-01\n"
     ]
    }
   ],
   "source": [
    "print(train_start ,\n",
    "train_end ,\n",
    "test_start ,\n",
    "test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c142a-8595-4c50-973b-607ef77b2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.read_pickle('../../processed_data-2023-05-12.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2caefc9-1bcf-4f82-b534-2a1dcab35dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "incorporated_state_code\n",
      "trade_type\n",
      "purpose_class\n",
      "max_ys_ttypes\n",
      "min_ys_ttypes\n",
      "max_qty_ttypes\n",
      "min_ago_ttypes\n",
      "D_min_ago_ttypes\n",
      "P_min_ago_ttypes\n",
      "S_min_ago_ttypes\n"
     ]
    }
   ],
   "source": [
    "additional_features = ['ttypes', 'diff_size', 'abs_last_yield_spread', 'abs_diff_size', 'days_duration']\n",
    "YS_COLS = ['max_ys_ys', 'max_ys_ttypes', 'max_ys_ago', 'max_ys_qdiff', 'min_ys_ys', 'min_ys_ttypes', 'min_ys_ago', 'min_ys_qdiff', 'max_qty_ys', 'max_qty_ttypes', \\\n",
    "           'max_qty_ago', 'max_qty_qdiff', 'min_ago_ys', 'min_ago_ttypes', 'min_ago_ago', 'min_ago_qdiff', 'D_min_ago_ys', 'D_min_ago_ttypes', 'D_min_ago_ago', 'D_min_ago_qdiff',\\\n",
    "           'P_min_ago_ys', 'P_min_ago_ttypes', 'P_min_ago_ago', 'P_min_ago_qdiff', 'S_min_ago_ys', 'S_min_ago_ttypes', 'S_min_ago_ago', 'S_min_ago_qdiff']\n",
    "encoders = {}\n",
    "fmax = {}\n",
    "for f in CATEGORICAL_FEATURES:\n",
    "    print(f)\n",
    "    if f in ['rating', 'incorporated_state_code', 'trade_type', 'purpose_class']:\n",
    "        fprep = preprocessing.LabelEncoder().fit(categorical_feature_values[f])\n",
    "    else:\n",
    "        fprep = preprocessing.LabelEncoder().fit(processed_data[f].drop_duplicates())\n",
    "    fmax[f] = np.max(fprep.transform(fprep.classes_))\n",
    "    encoders[f] = fprep\n",
    "    \n",
    "with open('encoders.pkl','wb') as file:\n",
    "    pickle.dump(encoders,file)\n",
    "    \n",
    "for col in YS_COLS:\n",
    "    if 'ttypes' in col and col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "    elif col not in PREDICTORS:\n",
    "        NON_CAT_FEATURES.append(col)\n",
    "        PREDICTORS.append(col)\n",
    "        \n",
    "if 'target_attention_features' not in PREDICTORS:\n",
    "    PREDICTORS.append('target_attention_features')\n",
    "    \n",
    "if 'ficc_treasury_spread' not in PREDICTORS:\n",
    "    PREDICTORS.append('ficc_treasury_spread')\n",
    "    NON_CAT_FEATURES.append('ficc_treasury_spread')\n",
    "    \n",
    "for col in ['new_ficc_ycl', 'new_real_time_ficc_ycl']:     \n",
    "    if col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        NON_CAT_FEATURES.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b92bf3e9-bd78-4aa1-a031-892a653b3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.02 s, sys: 23.3 ms, total: 3.05 s\n",
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_shortened'] = processed_data['trade_history'].apply(lambda x: x[:TRADE_SEQUENCE_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18cf5a1a-d7ee-4b7c-930a-b6d8ad31182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.38 s, sys: 22.3 ms, total: 3.41 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_fixed'] = processed_data['trade_history_shortened'].apply(lambda x: x[::-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82a6907d-d596-42b9-8c10-e390dfeca205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-01'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9daf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data start: 2023-01-03 00:00:00, end: 2023-02-28 00:00:00\n",
      "Test data start: 2023-03-01 00:00:00, end: 2023-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_filter = (processed_data.trade_date < train_end) & (processed_data.trade_date >= train_start)\n",
    "test_filter = (processed_data.trade_date >= test_start) & (processed_data.trade_date <test_end)\n",
    "                                                            \n",
    "train_dataframe = processed_data[train_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "test_dataframe = processed_data[test_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "print('Training data start: {}, end: {}'.format(train_dataframe.trade_date.min(),train_dataframe.trade_date.max()))\n",
    "print('Test data start: {}, end: {}'.format(test_dataframe.trade_date.min(),test_dataframe.trade_date.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1e5fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(df):\n",
    "    global encoders\n",
    "    datalist = []\n",
    "    # datalist.append(np.stack(df['yield_curve_history_sq'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['yield_curve_history'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['yield_curve_history_fixed'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['yield_curve_history_5min_12_averaged_fixed'].to_numpy()))\n",
    "    datalist.append(np.stack(df['trade_history_shortened'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['trade_history_fixed'].to_numpy()))\n",
    "    datalist.append(np.stack(df['target_attention_features'].to_numpy()))\n",
    "\n",
    "    noncat_and_binary = []\n",
    "    for f in NON_CAT_FEATURES + BINARY:\n",
    "        noncat_and_binary.append(np.expand_dims(df[f].to_numpy().astype('float32'), axis=1))\n",
    "    datalist.append(np.concatenate(noncat_and_binary, axis=-1))\n",
    "    \n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        encoded = encoders[f].transform(df[f])\n",
    "        datalist.append(encoded.astype('float32'))\n",
    "    \n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b65617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA: N = 1070549, MIN DATE = 2023-01-03 00:00:00, MAX DATE = 2023-02-28 00:00:00\n",
      "VALIDATION DATA: N = 267637, MIN DATE = 2023-01-03 00:00:00, MAX DATE = 2023-02-28 00:00:00\n",
      "TEST DATA: N = 708432, MIN DATE = 2023-03-01 00:00:00, MAX DATE = 2023-03-31 00:00:00\n",
      "CPU times: user 19.4 s, sys: 592 ms, total: 19.9 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "val_idx = np.random.choice(range(len(train_dataframe)), \n",
    "                 size = int(VALIDATION_SPLIT*len(train_dataframe)),\n",
    "                 replace=False)\n",
    "\n",
    "print(f'TRAINING DATA: N = {len(train_dataframe)-len(val_idx)}, MIN DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.min()}, MAX DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.max()}')\n",
    "print(f'VALIDATION DATA: N = {len(val_idx)}, MIN DATE = {train_dataframe.iloc[val_idx].trade_date.min()}, MAX DATE = {train_dataframe.iloc[val_idx].trade_date.max()}')\n",
    "print(f'TEST DATA: N = {len(test_dataframe)}, MIN DATE = {test_dataframe.trade_date.min()}, MAX DATE = {test_dataframe.trade_date.max()}')\n",
    "\n",
    "x_train = create_input(train_dataframe.drop(val_idx, axis=0))\n",
    "y_train = train_dataframe.drop(val_idx, axis=0)[target_variable]\n",
    "\n",
    "x_val = create_input(train_dataframe.iloc[val_idx])\n",
    "y_val = train_dataframe.iloc[val_idx][target_variable]\n",
    "\n",
    "x_test = create_input(test_dataframe)\n",
    "y_test = test_dataframe[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6aa16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cdb94f2-09a4-4c7f-8a07-b3fbac7a14d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 20:48:49.884077: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 20:48:49.888871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-12 20:48:49.890201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-12 20:48:49.891241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-12 20:48:50.481506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-12 20:48:50.482760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-12 20:48:50.483815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-12 20:48:50.484856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12457 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Normalization layer for the trade history\n",
    "trade_history_normalizer = Normalization(name='Trade_history_normalizer')\n",
    "trade_history_normalizer.adapt(x_train[0],batch_size=BATCH_SIZE)\n",
    "\n",
    "# Normalization layer for the non-categorical and binary features\n",
    "noncat_binary_normalizer = Normalization(name='Numerical_binary_normalizer')\n",
    "noncat_binary_normalizer.adapt(x_train[2], batch_size = BATCH_SIZE)\n",
    "\n",
    "tf.keras.utils.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d9d0d8-e8ee-4f99-9788-98bd4c43ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(TRADE_SEQUENCE_LENGTH = 5, YIELD_SEQUENCE_LENGTH = 12, NUM_FEATURES = NUM_FEATURES, trade_history_normalizer = trade_history_normalizer):\n",
    "    inputs = []\n",
    "    layer = []\n",
    "\n",
    "    ############## INPUT BLOCK ###################\n",
    "    \n",
    "    trade_history_input = layers.Input(name=\"trade_history_input\", \n",
    "                                       shape=(TRADE_SEQUENCE_LENGTH, NUM_FEATURES), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    target_attention_input = layers.Input(name=\"target_attention_input\", \n",
    "                                       shape=(1, 3), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    inputs.append(trade_history_input)\n",
    "    inputs.append(target_attention_input)\n",
    "\n",
    "    inputs.append(layers.Input(\n",
    "        name=\"NON_CAT_AND_BINARY_FEATURES\",\n",
    "        shape=(len(NON_CAT_FEATURES + BINARY),)\n",
    "    ))\n",
    "\n",
    "\n",
    "    layer.append(noncat_binary_normalizer(inputs[2]))\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    ############## TRADE HISTORY MODEL #################\n",
    "\n",
    "    lstm_layer = layers.Bidirectional(layers.LSTM(50, \n",
    "                             activation='tanh',\n",
    "                             input_shape=(TRADE_SEQUENCE_LENGTH,NUM_FEATURES),\n",
    "                             return_sequences = True,\n",
    "                             name='LSTM'))\n",
    "\n",
    "    lstm_layer_2 = layers.Bidirectional(layers.LSTM(100, \n",
    "                                                    activation='tanh',\n",
    "                                                    input_shape=(TRADE_SEQUENCE_LENGTH, 50),\n",
    "                                                    return_sequences = True,\n",
    "                                                    name='LSTM_2'))\n",
    "\n",
    "\n",
    "\n",
    "    features = lstm_layer(trade_history_normalizer(inputs[0]))\n",
    "    features = lstm_layer_2(features)\n",
    "\n",
    "\n",
    "    attention_sequence = layers.Dense(200, activation='relu', name='attention_dense')(target_attention_input)\n",
    "    attention = layers.Dot(axes=[2, 2])([features, attention_sequence])\n",
    "    attention = layers.Activation('softmax')(attention)\n",
    "\n",
    "    context_vector = layers.Dot(axes=[1, 1])([features, attention])\n",
    "    context_vector = layers.Flatten(name='context_vector_flatten')(context_vector)\n",
    "\n",
    "\n",
    "    trade_history_output = layers.Dense(100, \n",
    "                                        activation='relu')(context_vector)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    ############## REFERENCE DATA MODEL ################\n",
    "    global encoders\n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        fin = layers.Input(shape=(1,), name = f)\n",
    "        inputs.append(fin)\n",
    "        embedded = layers.Flatten(name = f + \"_flat\")( layers.Embedding(input_dim = fmax[f]+1,\n",
    "                                                                        output_dim = max(30,int(np.sqrt(fmax[f]))),\n",
    "                                                                        input_length= 1,\n",
    "                                                                        name = f + \"_embed\")(fin))\n",
    "        layer.append(embedded)\n",
    "\n",
    "\n",
    "    reference_hidden = layers.Dense(400,\n",
    "                                    activation='relu',\n",
    "                                    name='reference_hidden_1')(layers.concatenate(layer, axis=-1))\n",
    "\n",
    "    reference_hidden = layers.BatchNormalization()(reference_hidden)\n",
    "    reference_hidden = layers.Dropout(DROPOUT)(reference_hidden)\n",
    "\n",
    "    reference_hidden2 = layers.Dense(200,activation='relu',name='reference_hidden_2')(reference_hidden)\n",
    "    reference_hidden2 = layers.BatchNormalization()(reference_hidden2)\n",
    "    reference_hidden2 = layers.Dropout(DROPOUT)(reference_hidden2)\n",
    "\n",
    "    reference_output = layers.Dense(100,activation='tanh',name='reference_hidden_3')(reference_hidden2)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    feed_forward_input = layers.concatenate([reference_output, trade_history_output])\n",
    "\n",
    "    hidden = layers.Dense(300,activation='relu')(feed_forward_input)\n",
    "    hidden = layers.BatchNormalization()(hidden)\n",
    "    hidden = layers.Dropout(DROPOUT)(hidden)\n",
    "\n",
    "    hidden2 = layers.Dense(100,activation='relu')(hidden)\n",
    "    hidden2 = layers.BatchNormalization()(hidden2)\n",
    "    hidden2 = layers.Dropout(DROPOUT)(hidden2)\n",
    "    final = layers.Dense(1)(hidden2)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=final)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_tf_data(x_train, y_train, shuffle=False, shuffle_buffer=1):\n",
    "                     \n",
    "    X=()\n",
    "    for x in x_train:\n",
    "        X += (tf.data.Dataset.from_tensor_slices(x),)\n",
    "        \n",
    "\n",
    "    temp = tf.data.Dataset.zip((X))\n",
    "    del X\n",
    "    dataset = tf.data.Dataset.zip((temp,\n",
    "                        tf.data.Dataset.from_tensor_slices(y_train)))\n",
    "    del temp\n",
    "    if shuffle:\n",
    "        shuffle_buffer = int(len(x_train[0])*shuffle_buffer)\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c7eea81-0c51-4ac7-bb58-4aef23343c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_val, y_val, shuffle, shuffle_buffer=1):\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H-%M')\n",
    "    \n",
    "    fit_callbacks = fit_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True),\n",
    "        # time_callback,\n",
    "        CSVLoggerTimeHistory(timestamp+'_training_logs_yield_history.csv', separator=\",\", append=False)]\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        train_ds = create_tf_data(x_train, y_train, shuffle, shuffle_buffer)\n",
    "        train_ds = train_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "        val_ds = create_tf_data(x_val, y_val, shuffle = False)\n",
    "        val_ds = val_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "\n",
    "    model_new_ys = generate_model(TRADE_SEQUENCE_LENGTH=TRADE_SEQUENCE_LENGTH,\n",
    "                                  YIELD_SEQUENCE_LENGTH=YIELD_SEQUENCE_LENGTH,\n",
    "                                  NUM_FEATURES=6, \n",
    "                                  trade_history_normalizer = trade_history_normalizer)\n",
    "    \n",
    "    model_new_ys.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "          loss=keras.losses.MeanAbsoluteError(),\n",
    "          metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history_new_ys = model_new_ys.fit(train_ds,\n",
    "                                      validation_data=val_ds,\n",
    "                                        epochs=NUM_EPOCHS,     \n",
    "                                        verbose=1, \n",
    "                                        callbacks=fit_callbacks,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        workers=8)\n",
    "    \n",
    "    return history_new_ys, model_new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e1cb2-1368-496c-a0c2-2f2a4bc26b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 20:49:02.816128: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 13062569984 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-12 20:49:14.715425: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 452485 of 802911\n",
      "2023-05-12 20:49:20.702831: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n",
      "2023-05-12 20:49:22.100728: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 24.4431 - mean_absolute_error: 24.4431"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 20:49:48.470795: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 13062569984 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 58s 29ms/step - loss: 24.4431 - mean_absolute_error: 24.4431 - val_loss: 11.1062 - val_mean_absolute_error: 11.1062\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 10.9050 - mean_absolute_error: 10.9050 - val_loss: 10.0012 - val_mean_absolute_error: 10.0012\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 10.4838 - mean_absolute_error: 10.4838 - val_loss: 9.6790 - val_mean_absolute_error: 9.6790\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 10.2394 - mean_absolute_error: 10.2394 - val_loss: 9.5067 - val_mean_absolute_error: 9.5067\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 10.0691 - mean_absolute_error: 10.0691 - val_loss: 9.1416 - val_mean_absolute_error: 9.1416\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.9434 - mean_absolute_error: 9.9434 - val_loss: 9.1212 - val_mean_absolute_error: 9.1212\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.8467 - mean_absolute_error: 9.8467 - val_loss: 9.2052 - val_mean_absolute_error: 9.2052\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.7717 - mean_absolute_error: 9.7717 - val_loss: 9.1526 - val_mean_absolute_error: 9.1526\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.7034 - mean_absolute_error: 9.7034 - val_loss: 8.8907 - val_mean_absolute_error: 8.8907\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 25s 23ms/step - loss: 9.6410 - mean_absolute_error: 9.6410 - val_loss: 8.9771 - val_mean_absolute_error: 8.9771\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.5844 - mean_absolute_error: 9.5844 - val_loss: 8.9504 - val_mean_absolute_error: 8.9504\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.5354 - mean_absolute_error: 9.5354 - val_loss: 8.7724 - val_mean_absolute_error: 8.7724\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.4895 - mean_absolute_error: 9.4895 - val_loss: 8.8906 - val_mean_absolute_error: 8.8906\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.4534 - mean_absolute_error: 9.4534 - val_loss: 8.6791 - val_mean_absolute_error: 8.6791\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.4014 - mean_absolute_error: 9.4014 - val_loss: 8.7212 - val_mean_absolute_error: 8.7212\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.3670 - mean_absolute_error: 9.3670 - val_loss: 8.6655 - val_mean_absolute_error: 8.6655\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.3347 - mean_absolute_error: 9.3347 - val_loss: 8.6609 - val_mean_absolute_error: 8.6609\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 19s 19ms/step - loss: 9.2972 - mean_absolute_error: 9.2972 - val_loss: 8.6098 - val_mean_absolute_error: 8.6098\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.2691 - mean_absolute_error: 9.2691 - val_loss: 8.6324 - val_mean_absolute_error: 8.6324\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.2368 - mean_absolute_error: 9.2368 - val_loss: 8.5988 - val_mean_absolute_error: 8.5988\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.2003 - mean_absolute_error: 9.2003 - val_loss: 8.5831 - val_mean_absolute_error: 8.5831\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.1772 - mean_absolute_error: 9.1772 - val_loss: 8.5175 - val_mean_absolute_error: 8.5175\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.1517 - mean_absolute_error: 9.1517 - val_loss: 8.6060 - val_mean_absolute_error: 8.6060\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 25s 23ms/step - loss: 9.1275 - mean_absolute_error: 9.1275 - val_loss: 8.5154 - val_mean_absolute_error: 8.5154\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 19s 19ms/step - loss: 9.1021 - mean_absolute_error: 9.1021 - val_loss: 8.5052 - val_mean_absolute_error: 8.5052\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.0861 - mean_absolute_error: 9.0861 - val_loss: 8.4688 - val_mean_absolute_error: 8.4688\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.0491 - mean_absolute_error: 9.0491 - val_loss: 8.5043 - val_mean_absolute_error: 8.5043\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.0294 - mean_absolute_error: 9.0294 - val_loss: 8.4305 - val_mean_absolute_error: 8.4305\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.0112 - mean_absolute_error: 9.0112 - val_loss: 8.4186 - val_mean_absolute_error: 8.4186\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 25s 23ms/step - loss: 8.9885 - mean_absolute_error: 8.9885 - val_loss: 8.4254 - val_mean_absolute_error: 8.4254\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.9660 - mean_absolute_error: 8.9660 - val_loss: 8.4995 - val_mean_absolute_error: 8.4995\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.9503 - mean_absolute_error: 8.9503 - val_loss: 8.4299 - val_mean_absolute_error: 8.4299\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.9351 - mean_absolute_error: 8.9351 - val_loss: 8.4544 - val_mean_absolute_error: 8.4544\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.9090 - mean_absolute_error: 8.9090 - val_loss: 8.4115 - val_mean_absolute_error: 8.4115\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8887 - mean_absolute_error: 8.8887 - val_loss: 8.3749 - val_mean_absolute_error: 8.3749\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.8761 - mean_absolute_error: 8.8761 - val_loss: 8.4175 - val_mean_absolute_error: 8.4175\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8480 - mean_absolute_error: 8.8480 - val_loss: 8.5127 - val_mean_absolute_error: 8.5127\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 25s 23ms/step - loss: 8.8415 - mean_absolute_error: 8.8415 - val_loss: 8.3680 - val_mean_absolute_error: 8.3680\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8238 - mean_absolute_error: 8.8238 - val_loss: 8.3548 - val_mean_absolute_error: 8.3548\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8119 - mean_absolute_error: 8.8119 - val_loss: 8.5322 - val_mean_absolute_error: 8.5322\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.7922 - mean_absolute_error: 8.7922 - val_loss: 8.3802 - val_mean_absolute_error: 8.3802\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7760 - mean_absolute_error: 8.7760 - val_loss: 8.4192 - val_mean_absolute_error: 8.4192\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7683 - mean_absolute_error: 8.7683 - val_loss: 8.4266 - val_mean_absolute_error: 8.4266\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.7477 - mean_absolute_error: 8.7477 - val_loss: 8.4371 - val_mean_absolute_error: 8.4371\n",
      "Epoch 45/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7403 - mean_absolute_error: 8.7403 - val_loss: 8.3076 - val_mean_absolute_error: 8.3076\n",
      "Epoch 46/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.7275 - mean_absolute_error: 8.7275 - val_loss: 8.3066 - val_mean_absolute_error: 8.3066\n",
      "Epoch 47/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.7081 - mean_absolute_error: 8.7081 - val_loss: 8.3279 - val_mean_absolute_error: 8.3279\n",
      "Epoch 48/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7026 - mean_absolute_error: 8.7026 - val_loss: 8.3125 - val_mean_absolute_error: 8.3125\n",
      "Epoch 49/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6839 - mean_absolute_error: 8.6839 - val_loss: 8.3056 - val_mean_absolute_error: 8.3056\n",
      "Epoch 50/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.6685 - mean_absolute_error: 8.6685 - val_loss: 8.2807 - val_mean_absolute_error: 8.2807\n",
      "Epoch 51/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6613 - mean_absolute_error: 8.6613 - val_loss: 8.3304 - val_mean_absolute_error: 8.3304\n",
      "Epoch 52/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.6564 - mean_absolute_error: 8.6564 - val_loss: 8.2661 - val_mean_absolute_error: 8.2661\n",
      "Epoch 53/100\n",
      "1046/1046 [==============================] - 24s 22ms/step - loss: 8.6421 - mean_absolute_error: 8.6421 - val_loss: 8.3134 - val_mean_absolute_error: 8.3134\n",
      "Epoch 54/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6272 - mean_absolute_error: 8.6272 - val_loss: 8.4003 - val_mean_absolute_error: 8.4003\n",
      "Epoch 55/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.6250 - mean_absolute_error: 8.6250 - val_loss: 8.2896 - val_mean_absolute_error: 8.2896\n",
      "Epoch 56/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6068 - mean_absolute_error: 8.6068 - val_loss: 8.2896 - val_mean_absolute_error: 8.2896\n",
      "Epoch 57/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5976 - mean_absolute_error: 8.5976 - val_loss: 8.3141 - val_mean_absolute_error: 8.3141\n",
      "Epoch 58/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.5932 - mean_absolute_error: 8.5932 - val_loss: 8.3664 - val_mean_absolute_error: 8.3664\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5776 - mean_absolute_error: 8.5776 - val_loss: 8.2944 - val_mean_absolute_error: 8.2944\n",
      "Epoch 60/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5724 - mean_absolute_error: 8.5724 - val_loss: 8.2927 - val_mean_absolute_error: 8.2927\n",
      "Epoch 61/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.5626 - mean_absolute_error: 8.5626 - val_loss: 8.3851 - val_mean_absolute_error: 8.3851\n",
      "Epoch 62/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5524 - mean_absolute_error: 8.5524 - val_loss: 8.3765 - val_mean_absolute_error: 8.3765\n",
      "Model training time was 22.44 minutes (1346.52 seconds).\n",
      "Average time for each epoch was 0.22 minutes (13.47 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 21:11:36.873969: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 13062569984 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 0, MAE: 9.262046069506859 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 21:13:27.547993: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 13062569984 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-12 21:13:38.249773: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 605217 of 802911\n",
      "2023-05-12 21:13:41.525429: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 24.2809 - mean_absolute_error: 24.2809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 21:14:12.170409: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 13062569984 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 55s 34ms/step - loss: 24.2809 - mean_absolute_error: 24.2809 - val_loss: 11.4323 - val_mean_absolute_error: 11.4323\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 10.9113 - mean_absolute_error: 10.9113 - val_loss: 10.0461 - val_mean_absolute_error: 10.0461\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 10.4811 - mean_absolute_error: 10.4811 - val_loss: 9.6831 - val_mean_absolute_error: 9.6831\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 10.2205 - mean_absolute_error: 10.2205 - val_loss: 9.5635 - val_mean_absolute_error: 9.5635\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 10.0608 - mean_absolute_error: 10.0608 - val_loss: 9.2136 - val_mean_absolute_error: 9.2136\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.9386 - mean_absolute_error: 9.9386 - val_loss: 9.0509 - val_mean_absolute_error: 9.0509\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.8475 - mean_absolute_error: 9.8475 - val_loss: 9.1852 - val_mean_absolute_error: 9.1852\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.7578 - mean_absolute_error: 9.7578 - val_loss: 9.1799 - val_mean_absolute_error: 9.1799\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.6914 - mean_absolute_error: 9.6914 - val_loss: 9.1175 - val_mean_absolute_error: 9.1175\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.6287 - mean_absolute_error: 9.6287 - val_loss: 8.9873 - val_mean_absolute_error: 8.9873\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.5795 - mean_absolute_error: 9.5795 - val_loss: 9.1096 - val_mean_absolute_error: 9.1096\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.5189 - mean_absolute_error: 9.5189 - val_loss: 8.7924 - val_mean_absolute_error: 8.7924\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.4670 - mean_absolute_error: 9.4670 - val_loss: 8.8937 - val_mean_absolute_error: 8.8937\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.4346 - mean_absolute_error: 9.4346 - val_loss: 8.8132 - val_mean_absolute_error: 8.8132\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.3892 - mean_absolute_error: 9.3892 - val_loss: 8.7467 - val_mean_absolute_error: 8.7467\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.3596 - mean_absolute_error: 9.3596 - val_loss: 8.7820 - val_mean_absolute_error: 8.7820\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.3211 - mean_absolute_error: 9.3211 - val_loss: 8.6699 - val_mean_absolute_error: 8.6699\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.2860 - mean_absolute_error: 9.2860 - val_loss: 8.8059 - val_mean_absolute_error: 8.8059\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.2539 - mean_absolute_error: 9.2539 - val_loss: 8.7972 - val_mean_absolute_error: 8.7972\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 9.2236 - mean_absolute_error: 9.2236 - val_loss: 8.5944 - val_mean_absolute_error: 8.5944\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 9.1960 - mean_absolute_error: 9.1960 - val_loss: 8.5649 - val_mean_absolute_error: 8.5649\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 9.1566 - mean_absolute_error: 9.1566 - val_loss: 8.6357 - val_mean_absolute_error: 8.6357\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 9.1397 - mean_absolute_error: 9.1397 - val_loss: 8.6916 - val_mean_absolute_error: 8.6916\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 9.1096 - mean_absolute_error: 9.1096 - val_loss: 8.5745 - val_mean_absolute_error: 8.5745\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 9.0916 - mean_absolute_error: 9.0916 - val_loss: 8.6019 - val_mean_absolute_error: 8.6019\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 9.0633 - mean_absolute_error: 9.0633 - val_loss: 8.5597 - val_mean_absolute_error: 8.5597\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 9.0355 - mean_absolute_error: 9.0355 - val_loss: 8.4902 - val_mean_absolute_error: 8.4902\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.0076 - mean_absolute_error: 9.0076 - val_loss: 8.5211 - val_mean_absolute_error: 8.5211\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 18s 17ms/step - loss: 8.9885 - mean_absolute_error: 8.9885 - val_loss: 8.4939 - val_mean_absolute_error: 8.4939\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.9707 - mean_absolute_error: 8.9707 - val_loss: 8.4700 - val_mean_absolute_error: 8.4700\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.9473 - mean_absolute_error: 8.9473 - val_loss: 8.6235 - val_mean_absolute_error: 8.6235\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.9336 - mean_absolute_error: 8.9336 - val_loss: 8.5251 - val_mean_absolute_error: 8.5251\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.9065 - mean_absolute_error: 8.9065 - val_loss: 8.4808 - val_mean_absolute_error: 8.4808\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 23s 22ms/step - loss: 8.8920 - mean_absolute_error: 8.8920 - val_loss: 8.5715 - val_mean_absolute_error: 8.5715\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8742 - mean_absolute_error: 8.8742 - val_loss: 8.5376 - val_mean_absolute_error: 8.5376\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.8532 - mean_absolute_error: 8.8532 - val_loss: 8.5071 - val_mean_absolute_error: 8.5071\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8398 - mean_absolute_error: 8.8398 - val_loss: 8.5150 - val_mean_absolute_error: 8.5150\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8196 - mean_absolute_error: 8.8196 - val_loss: 8.4204 - val_mean_absolute_error: 8.4204\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 8.8090 - mean_absolute_error: 8.8090 - val_loss: 8.5069 - val_mean_absolute_error: 8.5069\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 8.7935 - mean_absolute_error: 8.7935 - val_loss: 8.4703 - val_mean_absolute_error: 8.4703\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7873 - mean_absolute_error: 8.7873 - val_loss: 8.3943 - val_mean_absolute_error: 8.3943\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.7683 - mean_absolute_error: 8.7683 - val_loss: 8.4561 - val_mean_absolute_error: 8.4561\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7509 - mean_absolute_error: 8.7509 - val_loss: 8.5345 - val_mean_absolute_error: 8.5345\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7409 - mean_absolute_error: 8.7409 - val_loss: 8.4655 - val_mean_absolute_error: 8.4655\n",
      "Epoch 45/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.7333 - mean_absolute_error: 8.7333 - val_loss: 8.4104 - val_mean_absolute_error: 8.4104\n",
      "Epoch 46/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7066 - mean_absolute_error: 8.7066 - val_loss: 8.4749 - val_mean_absolute_error: 8.4749\n",
      "Epoch 47/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6979 - mean_absolute_error: 8.6979 - val_loss: 8.4886 - val_mean_absolute_error: 8.4886\n",
      "Epoch 48/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.6908 - mean_absolute_error: 8.6908 - val_loss: 8.4218 - val_mean_absolute_error: 8.4218\n",
      "Epoch 49/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6704 - mean_absolute_error: 8.6704 - val_loss: 8.6029 - val_mean_absolute_error: 8.6029\n",
      "Epoch 50/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6646 - mean_absolute_error: 8.6646 - val_loss: 8.5941 - val_mean_absolute_error: 8.5941\n",
      "Epoch 51/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.6511 - mean_absolute_error: 8.6511 - val_loss: 8.6584 - val_mean_absolute_error: 8.6584\n",
      "Model training time was 17.76 minutes (1065.78 seconds).\n",
      "Average time for each epoch was 0.18 minutes (10.66 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 21:31:20.135923: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 13062569984 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 1, MAE: 9.347772110161896 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 21:33:08.350891: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 13062569984 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-12 21:33:19.227228: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 609620 of 802911\n",
      "2023-05-12 21:33:22.378164: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 24.2892 - mean_absolute_error: 24.2892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 21:33:47.757054: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 13062569984 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 53s 28ms/step - loss: 24.2892 - mean_absolute_error: 24.2892 - val_loss: 10.8921 - val_mean_absolute_error: 10.8921\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 10.9200 - mean_absolute_error: 10.9200 - val_loss: 10.1864 - val_mean_absolute_error: 10.1864\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 10.5100 - mean_absolute_error: 10.5100 - val_loss: 9.6643 - val_mean_absolute_error: 9.6643\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 10.2611 - mean_absolute_error: 10.2611 - val_loss: 9.5256 - val_mean_absolute_error: 9.5256\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 10.0784 - mean_absolute_error: 10.0784 - val_loss: 9.3005 - val_mean_absolute_error: 9.3005\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.9507 - mean_absolute_error: 9.9507 - val_loss: 9.2965 - val_mean_absolute_error: 9.2965\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.8555 - mean_absolute_error: 9.8555 - val_loss: 9.0659 - val_mean_absolute_error: 9.0659\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.7691 - mean_absolute_error: 9.7691 - val_loss: 9.0795 - val_mean_absolute_error: 9.0795\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.6963 - mean_absolute_error: 9.6963 - val_loss: 9.0076 - val_mean_absolute_error: 9.0076\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.6423 - mean_absolute_error: 9.6423 - val_loss: 8.9291 - val_mean_absolute_error: 8.9291\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.5834 - mean_absolute_error: 9.5834 - val_loss: 8.9293 - val_mean_absolute_error: 8.9293\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.5329 - mean_absolute_error: 9.5329 - val_loss: 8.8810 - val_mean_absolute_error: 8.8810\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.4909 - mean_absolute_error: 9.4909 - val_loss: 8.8485 - val_mean_absolute_error: 8.8485\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.4458 - mean_absolute_error: 9.4458 - val_loss: 8.9293 - val_mean_absolute_error: 8.9293\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.4108 - mean_absolute_error: 9.4108 - val_loss: 8.7674 - val_mean_absolute_error: 8.7674\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.3611 - mean_absolute_error: 9.3611 - val_loss: 8.8285 - val_mean_absolute_error: 8.8285\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.3325 - mean_absolute_error: 9.3325 - val_loss: 8.7897 - val_mean_absolute_error: 8.7897\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.2921 - mean_absolute_error: 9.2921 - val_loss: 8.7322 - val_mean_absolute_error: 8.7322\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.2679 - mean_absolute_error: 9.2679 - val_loss: 8.7497 - val_mean_absolute_error: 8.7497\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.2378 - mean_absolute_error: 9.2378 - val_loss: 8.5932 - val_mean_absolute_error: 8.5932\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.2093 - mean_absolute_error: 9.2093 - val_loss: 8.6217 - val_mean_absolute_error: 8.6217\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.1827 - mean_absolute_error: 9.1827 - val_loss: 8.6935 - val_mean_absolute_error: 8.6935\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.1523 - mean_absolute_error: 9.1523 - val_loss: 8.6955 - val_mean_absolute_error: 8.6955\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.1269 - mean_absolute_error: 9.1269 - val_loss: 8.5452 - val_mean_absolute_error: 8.5452\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.1013 - mean_absolute_error: 9.1013 - val_loss: 8.5387 - val_mean_absolute_error: 8.5387\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.0762 - mean_absolute_error: 9.0762 - val_loss: 8.5945 - val_mean_absolute_error: 8.5945\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.0555 - mean_absolute_error: 9.0555 - val_loss: 8.5881 - val_mean_absolute_error: 8.5881\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 25s 23ms/step - loss: 9.0358 - mean_absolute_error: 9.0358 - val_loss: 8.5239 - val_mean_absolute_error: 8.5239\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.0138 - mean_absolute_error: 9.0138 - val_loss: 8.4738 - val_mean_absolute_error: 8.4738\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 8.9883 - mean_absolute_error: 8.9883 - val_loss: 8.6166 - val_mean_absolute_error: 8.6166\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9719 - mean_absolute_error: 8.9719 - val_loss: 8.4961 - val_mean_absolute_error: 8.4961\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.9526 - mean_absolute_error: 8.9526 - val_loss: 8.4426 - val_mean_absolute_error: 8.4426\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.9303 - mean_absolute_error: 8.9303 - val_loss: 8.5032 - val_mean_absolute_error: 8.5032\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.9161 - mean_absolute_error: 8.9161 - val_loss: 8.4961 - val_mean_absolute_error: 8.4961\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.9022 - mean_absolute_error: 8.9022 - val_loss: 8.5186 - val_mean_absolute_error: 8.5186\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.8749 - mean_absolute_error: 8.8749 - val_loss: 8.4032 - val_mean_absolute_error: 8.4032\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8557 - mean_absolute_error: 8.8557 - val_loss: 8.4571 - val_mean_absolute_error: 8.4571\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8421 - mean_absolute_error: 8.8421 - val_loss: 8.4043 - val_mean_absolute_error: 8.4043\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.8250 - mean_absolute_error: 8.8250 - val_loss: 8.3758 - val_mean_absolute_error: 8.3758\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.8073 - mean_absolute_error: 8.8073 - val_loss: 8.3846 - val_mean_absolute_error: 8.3846\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7971 - mean_absolute_error: 8.7971 - val_loss: 8.3726 - val_mean_absolute_error: 8.3726\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 25s 23ms/step - loss: 8.7770 - mean_absolute_error: 8.7770 - val_loss: 8.3453 - val_mean_absolute_error: 8.3453\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7637 - mean_absolute_error: 8.7637 - val_loss: 8.3280 - val_mean_absolute_error: 8.3280\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7461 - mean_absolute_error: 8.7461 - val_loss: 8.3131 - val_mean_absolute_error: 8.3131\n",
      "Epoch 45/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.7340 - mean_absolute_error: 8.7340 - val_loss: 8.3859 - val_mean_absolute_error: 8.3859\n",
      "Epoch 46/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.7273 - mean_absolute_error: 8.7273 - val_loss: 8.3984 - val_mean_absolute_error: 8.3984\n",
      "Epoch 47/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.7060 - mean_absolute_error: 8.7060 - val_loss: 8.3658 - val_mean_absolute_error: 8.3658\n",
      "Epoch 48/100\n",
      "1046/1046 [==============================] - 23s 22ms/step - loss: 8.6953 - mean_absolute_error: 8.6953 - val_loss: 8.2877 - val_mean_absolute_error: 8.2877\n",
      "Epoch 49/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6809 - mean_absolute_error: 8.6809 - val_loss: 8.3105 - val_mean_absolute_error: 8.3105\n",
      "Epoch 50/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.6707 - mean_absolute_error: 8.6707 - val_loss: 8.3061 - val_mean_absolute_error: 8.3061\n",
      "Epoch 51/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6557 - mean_absolute_error: 8.6557 - val_loss: 8.3436 - val_mean_absolute_error: 8.3436\n",
      "Epoch 52/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6489 - mean_absolute_error: 8.6489 - val_loss: 8.2723 - val_mean_absolute_error: 8.2723\n",
      "Epoch 53/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.6366 - mean_absolute_error: 8.6366 - val_loss: 8.2373 - val_mean_absolute_error: 8.2373\n",
      "Epoch 54/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6242 - mean_absolute_error: 8.6242 - val_loss: 8.2533 - val_mean_absolute_error: 8.2533\n",
      "Epoch 55/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.6073 - mean_absolute_error: 8.6073 - val_loss: 8.2241 - val_mean_absolute_error: 8.2241\n",
      "Epoch 56/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.5975 - mean_absolute_error: 8.5975 - val_loss: 8.3095 - val_mean_absolute_error: 8.3095\n",
      "Epoch 57/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5900 - mean_absolute_error: 8.5900 - val_loss: 8.2499 - val_mean_absolute_error: 8.2499\n",
      "Epoch 58/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5769 - mean_absolute_error: 8.5769 - val_loss: 8.2422 - val_mean_absolute_error: 8.2422\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.5626 - mean_absolute_error: 8.5626 - val_loss: 8.2308 - val_mean_absolute_error: 8.2308\n",
      "Epoch 60/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5716 - mean_absolute_error: 8.5716 - val_loss: 8.2608 - val_mean_absolute_error: 8.2608\n",
      "Epoch 61/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5467 - mean_absolute_error: 8.5467 - val_loss: 8.2510 - val_mean_absolute_error: 8.2510\n",
      "Epoch 62/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.5463 - mean_absolute_error: 8.5463 - val_loss: 8.2548 - val_mean_absolute_error: 8.2548\n",
      "Epoch 63/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5305 - mean_absolute_error: 8.5305 - val_loss: 8.2125 - val_mean_absolute_error: 8.2125\n",
      "Epoch 64/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 8.5201 - mean_absolute_error: 8.5201 - val_loss: 8.2387 - val_mean_absolute_error: 8.2387\n",
      "Epoch 65/100\n",
      " 644/1046 [=================>............] - ETA: 10s - loss: 8.5143 - mean_absolute_error: 8.5143"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(4):\n",
    "    history, model = train_model(x_train, y_train, x_val, y_val, shuffle=True, shuffle_buffer=0.75)\n",
    "    pred = model.predict(x_test)\n",
    "    predictions.append(pred)\n",
    "    print('='*25+f' TRIAL {i}, MAE: {mean_absolute_error(pred,y_test)} '+'='*25)\n",
    "    results.append([history, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff15239-8f1e-4f6d-b431-f369b3e26348",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'{mean_absolute_error(prediction, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914f1ac-6f49-4002-b083-cffa639fea90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5733a7a-9728-4e91-8cbc-029c5070ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.stack(predictions).reshape(8, -1).T, columns = [f'model_{i}' for i in range(1,9)])\n",
    "test_dataframe[[f'prediction_{i}' for i in range(1,9)]] = pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "194638de-adb8-4a01-9e09-afd3f6e04427",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe.to_pickle('diff_ys-yield_history_2-2023_05_09.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d91511-c477-4420-9dbe-9d2dbb416e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
