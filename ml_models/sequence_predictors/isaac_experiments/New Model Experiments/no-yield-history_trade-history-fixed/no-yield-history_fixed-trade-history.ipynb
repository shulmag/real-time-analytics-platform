{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5803de-86c4-457a-9fc1-d3079e144ce3",
   "metadata": {},
   "source": [
    "TRADE HISTORY LENGTH 2, CORRECTLY ORDERED \n",
    "\n",
    "NO YIELD CURVE HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58de4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:11:36.384297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:11:36.396211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:11:36.397837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pandarallel with 16.0 cores\n",
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "TF Version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "from ficc.utils.nelson_siegel_model import *\n",
    "from ficc.utils.diff_in_days import *\n",
    "from ficc.utils.auxiliary_functions import sqltodf\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, NON_CAT_FEATURES, BINARY, CATEGORICAL_FEATURES, IDENTIFIERS, PURPOSE_CLASS_DICT, NUM_OF_DAYS_IN_YEAR\n",
    "from ficc.utils.gcp_storage_functions import upload_data, download_data\n",
    "from ficc.utils.auxiliary_variables import RELATED_TRADE_BINARY_FEATURES, RELATED_TRADE_NON_CAT_FEATURES, RELATED_TRADE_CATEGORICAL_FEATURES\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from ficc_keras_utils import *\n",
    "import ficc_keras_utils\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(f'TF Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c11246",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/ficc/isaac_creds.json\"\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()\n",
    "\n",
    "##COMMON VARIABLES\n",
    "#DATA WINDOW\n",
    "train_start = ficc_keras_utils.train_start\n",
    "train_end = ficc_keras_utils.train_end\n",
    "test_start = ficc_keras_utils.test_start\n",
    "test_end = ficc_keras_utils.test_end\n",
    "#MODEL PARAMETERS \n",
    "VALIDATION_SPLIT = ficc_keras_utils.VALIDATION_SPLIT\n",
    "LEARNING_RATE = ficc_keras_utils.LEARNING_RATE\n",
    "BATCH_SIZE = ficc_keras_utils.BATCH_SIZE\n",
    "NUM_EPOCHS = ficc_keras_utils.NUM_EPOCHS\n",
    "DROPOUT = ficc_keras_utils.DROPOUT\n",
    "\n",
    "##NOTEBOOK SPECIFIC VARIABLES \n",
    "TRADE_SEQUENCE_LENGTH = 2\n",
    "YIELD_SEQUENCE_LENGTH = 12\n",
    "NUM_FEATURES = 6\n",
    "target_variable = 'new_ys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca18089-58e8-4a2e-9c50-11898bfde236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01 2023-03-01 2023-03-01 2023-04-01\n"
     ]
    }
   ],
   "source": [
    "print(train_start ,\n",
    "train_end ,\n",
    "test_start ,\n",
    "test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689c142a-8595-4c50-973b-607ef77b2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.read_pickle('../../processed_data-2023-05-12.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92bf3e9-bd78-4aa1-a031-892a653b3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 529 ms, total: 11.6 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_shortened'] = processed_data['trade_history'].apply(lambda x: x[:TRADE_SEQUENCE_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18cf5a1a-d7ee-4b7c-930a-b6d8ad31182e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 338 ms, total: 11.3 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_fixed'] = processed_data['trade_history_shortened'].apply(lambda x: x[::-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a6907d-d596-42b9-8c10-e390dfeca205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "incorporated_state_code\n",
      "trade_type\n",
      "purpose_class\n",
      "max_ys_ttypes\n",
      "min_ys_ttypes\n",
      "max_qty_ttypes\n",
      "min_ago_ttypes\n",
      "D_min_ago_ttypes\n",
      "P_min_ago_ttypes\n",
      "S_min_ago_ttypes\n"
     ]
    }
   ],
   "source": [
    "additional_features = ['ttypes', 'diff_size', 'abs_last_yield_spread', 'abs_diff_size', 'days_duration']\n",
    "YS_COLS = ['max_ys_ys', 'max_ys_ttypes', 'max_ys_ago', 'max_ys_qdiff', 'min_ys_ys', 'min_ys_ttypes', 'min_ys_ago', 'min_ys_qdiff', 'max_qty_ys', 'max_qty_ttypes', \\\n",
    "           'max_qty_ago', 'max_qty_qdiff', 'min_ago_ys', 'min_ago_ttypes', 'min_ago_ago', 'min_ago_qdiff', 'D_min_ago_ys', 'D_min_ago_ttypes', 'D_min_ago_ago', 'D_min_ago_qdiff',\\\n",
    "           'P_min_ago_ys', 'P_min_ago_ttypes', 'P_min_ago_ago', 'P_min_ago_qdiff', 'S_min_ago_ys', 'S_min_ago_ttypes', 'S_min_ago_ago', 'S_min_ago_qdiff']\n",
    "encoders = {}\n",
    "fmax = {}\n",
    "for f in CATEGORICAL_FEATURES:\n",
    "    print(f)\n",
    "    if f in ['rating', 'incorporated_state_code', 'trade_type', 'purpose_class']:\n",
    "        fprep = preprocessing.LabelEncoder().fit(categorical_feature_values[f])\n",
    "    else:\n",
    "        fprep = preprocessing.LabelEncoder().fit(processed_data[f].drop_duplicates())\n",
    "    fmax[f] = np.max(fprep.transform(fprep.classes_))\n",
    "    encoders[f] = fprep\n",
    "    \n",
    "with open('encoders.pkl','wb') as file:\n",
    "    pickle.dump(encoders,file)\n",
    "    \n",
    "for col in YS_COLS:\n",
    "    if 'ttypes' in col and col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "    elif col not in PREDICTORS:\n",
    "        NON_CAT_FEATURES.append(col)\n",
    "        PREDICTORS.append(col)\n",
    "        \n",
    "if 'target_attention_features' not in PREDICTORS:\n",
    "    PREDICTORS.append('target_attention_features')\n",
    "    \n",
    "if 'ficc_treasury_spread' not in PREDICTORS:\n",
    "    PREDICTORS.append('ficc_treasury_spread')\n",
    "    NON_CAT_FEATURES.append('ficc_treasury_spread')\n",
    "    \n",
    "for col in ['new_ficc_ycl', 'new_real_time_ficc_ycl']:     \n",
    "    if col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        NON_CAT_FEATURES.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9daf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data start: 2023-01-03 00:00:00, end: 2023-02-28 00:00:00\n",
      "Test data start: 2023-03-01 00:00:00, end: 2023-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_filter = (processed_data.trade_date < train_end) & (processed_data.trade_date >= train_start)\n",
    "test_filter = (processed_data.trade_date >= test_start) & (processed_data.trade_date <test_end)\n",
    "                                                            \n",
    "train_dataframe = processed_data[train_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "test_dataframe = processed_data[test_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "print('Training data start: {}, end: {}'.format(train_dataframe.trade_date.min(),train_dataframe.trade_date.max()))\n",
    "print('Test data start: {}, end: {}'.format(test_dataframe.trade_date.min(),test_dataframe.trade_date.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e5fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(df):\n",
    "    global encoders\n",
    "    datalist = []\n",
    "    # datalist.append(np.stack(df['yield_curve_history_sq'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['yield_curve_history'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['yield_curve_history_fixed'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['yield_curve_history_5min_12_averaged_fixed'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['trade_history_shortened'].to_numpy()))\n",
    "    datalist.append(np.stack(df['trade_history_fixed'].to_numpy()))\n",
    "    datalist.append(np.stack(df['target_attention_features'].to_numpy()))\n",
    "\n",
    "    noncat_and_binary = []\n",
    "    for f in NON_CAT_FEATURES + BINARY:\n",
    "        noncat_and_binary.append(np.expand_dims(df[f].to_numpy().astype('float32'), axis=1))\n",
    "    datalist.append(np.concatenate(noncat_and_binary, axis=-1))\n",
    "    \n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        encoded = encoders[f].transform(df[f])\n",
    "        datalist.append(encoded.astype('float32'))\n",
    "    \n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2b65617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA: N = 1070549, MIN DATE = 2023-01-03 00:00:00, MAX DATE = 2023-02-28 00:00:00\n",
      "VALIDATION DATA: N = 267637, MIN DATE = 2023-01-03 00:00:00, MAX DATE = 2023-02-28 00:00:00\n",
      "TEST DATA: N = 708432, MIN DATE = 2023-03-01 00:00:00, MAX DATE = 2023-03-31 00:00:00\n",
      "CPU times: user 18.4 s, sys: 1.35 s, total: 19.8 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "val_idx = np.random.choice(range(len(train_dataframe)), \n",
    "                 size = int(VALIDATION_SPLIT*len(train_dataframe)),\n",
    "                 replace=False)\n",
    "\n",
    "print(f'TRAINING DATA: N = {len(train_dataframe)-len(val_idx)}, MIN DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.min()}, MAX DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.max()}')\n",
    "print(f'VALIDATION DATA: N = {len(val_idx)}, MIN DATE = {train_dataframe.iloc[val_idx].trade_date.min()}, MAX DATE = {train_dataframe.iloc[val_idx].trade_date.max()}')\n",
    "print(f'TEST DATA: N = {len(test_dataframe)}, MIN DATE = {test_dataframe.trade_date.min()}, MAX DATE = {test_dataframe.trade_date.max()}')\n",
    "\n",
    "x_train = create_input(train_dataframe.drop(val_idx, axis=0))\n",
    "y_train = train_dataframe.drop(val_idx, axis=0)[target_variable]\n",
    "\n",
    "x_val = create_input(train_dataframe.iloc[val_idx])\n",
    "y_val = train_dataframe.iloc[val_idx][target_variable]\n",
    "\n",
    "x_test = create_input(test_dataframe)\n",
    "y_test = test_dataframe[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6aa16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cdb94f2-09a4-4c7f-8a07-b3fbac7a14d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:16:50.627184: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 22:16:50.631691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:16:50.635463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:16:50.638111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:16:51.248324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:16:51.250196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:16:51.251786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-15 22:16:51.253346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13594 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Normalization layer for the trade history\n",
    "trade_history_normalizer = Normalization(name='Trade_history_normalizer')\n",
    "trade_history_normalizer.adapt(x_train[0],batch_size=BATCH_SIZE)\n",
    "\n",
    "# Normalization layer for the non-categorical and binary features\n",
    "noncat_binary_normalizer = Normalization(name='Numerical_binary_normalizer')\n",
    "noncat_binary_normalizer.adapt(x_train[2], batch_size = BATCH_SIZE)\n",
    "\n",
    "tf.keras.utils.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63d9d0d8-e8ee-4f99-9788-98bd4c43ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(TRADE_SEQUENCE_LENGTH = 5, YIELD_SEQUENCE_LENGTH = 12, NUM_FEATURES = NUM_FEATURES, trade_history_normalizer = trade_history_normalizer):\n",
    "    inputs = []\n",
    "    layer = []\n",
    "\n",
    "    ############## INPUT BLOCK ###################\n",
    "    \n",
    "    trade_history_input = layers.Input(name=\"trade_history_input\", \n",
    "                                       shape=(TRADE_SEQUENCE_LENGTH, NUM_FEATURES), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    target_attention_input = layers.Input(name=\"target_attention_input\", \n",
    "                                       shape=(1, 3), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    inputs.append(trade_history_input)\n",
    "    inputs.append(target_attention_input)\n",
    "\n",
    "    inputs.append(layers.Input(\n",
    "        name=\"NON_CAT_AND_BINARY_FEATURES\",\n",
    "        shape=(len(NON_CAT_FEATURES + BINARY),)\n",
    "    ))\n",
    "\n",
    "\n",
    "    layer.append(noncat_binary_normalizer(inputs[2]))\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    ############## TRADE HISTORY MODEL #################\n",
    "\n",
    "    lstm_layer = layers.Bidirectional(layers.LSTM(50, \n",
    "                             activation='tanh',\n",
    "                             input_shape=(TRADE_SEQUENCE_LENGTH,NUM_FEATURES),\n",
    "                             return_sequences = True,\n",
    "                             name='LSTM'))\n",
    "\n",
    "    lstm_layer_2 = layers.Bidirectional(layers.LSTM(100, \n",
    "                                                    activation='tanh',\n",
    "                                                    input_shape=(TRADE_SEQUENCE_LENGTH, 50),\n",
    "                                                    return_sequences = True,\n",
    "                                                    name='LSTM_2'))\n",
    "\n",
    "\n",
    "\n",
    "    features = lstm_layer(trade_history_normalizer(inputs[0]))\n",
    "    features = lstm_layer_2(features)\n",
    "\n",
    "\n",
    "    attention_sequence = layers.Dense(200, activation='relu', name='attention_dense')(target_attention_input)\n",
    "    attention = layers.Dot(axes=[2, 2])([features, attention_sequence])\n",
    "    attention = layers.Activation('softmax')(attention)\n",
    "\n",
    "    context_vector = layers.Dot(axes=[1, 1])([features, attention])\n",
    "    context_vector = layers.Flatten(name='context_vector_flatten')(context_vector)\n",
    "\n",
    "\n",
    "    trade_history_output = layers.Dense(100, \n",
    "                                        activation='relu')(context_vector)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    ############## REFERENCE DATA MODEL ################\n",
    "    global encoders\n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        fin = layers.Input(shape=(1,), name = f)\n",
    "        inputs.append(fin)\n",
    "        embedded = layers.Flatten(name = f + \"_flat\")( layers.Embedding(input_dim = fmax[f]+1,\n",
    "                                                                        output_dim = max(30,int(np.sqrt(fmax[f]))),\n",
    "                                                                        input_length= 1,\n",
    "                                                                        name = f + \"_embed\")(fin))\n",
    "        layer.append(embedded)\n",
    "\n",
    "\n",
    "    reference_hidden = layers.Dense(400,\n",
    "                                    activation='relu',\n",
    "                                    name='reference_hidden_1')(layers.concatenate(layer, axis=-1))\n",
    "\n",
    "    reference_hidden = layers.BatchNormalization()(reference_hidden)\n",
    "    reference_hidden = layers.Dropout(DROPOUT)(reference_hidden)\n",
    "\n",
    "    reference_hidden2 = layers.Dense(200,activation='relu',name='reference_hidden_2')(reference_hidden)\n",
    "    reference_hidden2 = layers.BatchNormalization()(reference_hidden2)\n",
    "    reference_hidden2 = layers.Dropout(DROPOUT)(reference_hidden2)\n",
    "\n",
    "    reference_output = layers.Dense(100,activation='tanh',name='reference_hidden_3')(reference_hidden2)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    feed_forward_input = layers.concatenate([reference_output, trade_history_output])\n",
    "\n",
    "    hidden = layers.Dense(300,activation='relu')(feed_forward_input)\n",
    "    hidden = layers.BatchNormalization()(hidden)\n",
    "    hidden = layers.Dropout(DROPOUT)(hidden)\n",
    "\n",
    "    hidden2 = layers.Dense(100,activation='relu')(hidden)\n",
    "    hidden2 = layers.BatchNormalization()(hidden2)\n",
    "    hidden2 = layers.Dropout(DROPOUT)(hidden2)\n",
    "    final = layers.Dense(1)(hidden2)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=final)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_tf_data(x_train, y_train, shuffle=False, shuffle_buffer=1):\n",
    "                     \n",
    "    X=()\n",
    "    for x in x_train:\n",
    "        X += (tf.data.Dataset.from_tensor_slices(x),)\n",
    "        \n",
    "\n",
    "    temp = tf.data.Dataset.zip((X))\n",
    "    del X\n",
    "    dataset = tf.data.Dataset.zip((temp,\n",
    "                        tf.data.Dataset.from_tensor_slices(y_train)))\n",
    "    del temp\n",
    "    if shuffle:\n",
    "        shuffle_buffer = int(len(x_train[0])*shuffle_buffer)\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c7eea81-0c51-4ac7-bb58-4aef23343c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_val, y_val, shuffle, shuffle_buffer=1):\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H-%M')\n",
    "    \n",
    "    fit_callbacks = fit_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True),\n",
    "        # time_callback,\n",
    "        CSVLoggerTimeHistory(timestamp+'_training_logs_yield_history.csv', separator=\",\", append=False)]\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        train_ds = create_tf_data(x_train, y_train, shuffle, shuffle_buffer)\n",
    "        train_ds = train_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "        val_ds = create_tf_data(x_val, y_val, shuffle = False)\n",
    "        val_ds = val_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "\n",
    "    model_new_ys = generate_model(TRADE_SEQUENCE_LENGTH=TRADE_SEQUENCE_LENGTH,\n",
    "                                  YIELD_SEQUENCE_LENGTH=YIELD_SEQUENCE_LENGTH,\n",
    "                                  NUM_FEATURES=6, \n",
    "                                  trade_history_normalizer = trade_history_normalizer)\n",
    "    \n",
    "    model_new_ys.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "          loss=keras.losses.MeanAbsoluteError(),\n",
    "          metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history_new_ys = model_new_ys.fit(train_ds,\n",
    "                                      validation_data=val_ds,\n",
    "                                        epochs=NUM_EPOCHS,     \n",
    "                                        verbose=1, \n",
    "                                        callbacks=fit_callbacks,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        workers=8)\n",
    "    \n",
    "    return history_new_ys, model_new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896e1cb2-1368-496c-a0c2-2f2a4bc26b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:17:01.902031: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-15 22:17:13.704254: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 437959 of 802911\n",
      "2023-05-15 22:17:19.808617: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n",
      "2023-05-15 22:17:21.048778: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 24.4414 - mean_absolute_error: 24.4414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:17:45.891737: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 55s 28ms/step - loss: 24.4414 - mean_absolute_error: 24.4414 - val_loss: 12.0080 - val_mean_absolute_error: 12.0080\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 10.8879 - mean_absolute_error: 10.8879 - val_loss: 10.0153 - val_mean_absolute_error: 10.0153\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 10.4825 - mean_absolute_error: 10.4825 - val_loss: 9.8672 - val_mean_absolute_error: 9.8672\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 10.2319 - mean_absolute_error: 10.2319 - val_loss: 9.7382 - val_mean_absolute_error: 9.7382\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 10.0699 - mean_absolute_error: 10.0699 - val_loss: 9.2545 - val_mean_absolute_error: 9.2545\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.9421 - mean_absolute_error: 9.9421 - val_loss: 9.1635 - val_mean_absolute_error: 9.1635\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 9.8471 - mean_absolute_error: 9.8471 - val_loss: 8.9915 - val_mean_absolute_error: 8.9915\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 9.7719 - mean_absolute_error: 9.7719 - val_loss: 8.9698 - val_mean_absolute_error: 8.9698\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.6956 - mean_absolute_error: 9.6956 - val_loss: 8.8486 - val_mean_absolute_error: 8.8486\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 9.6379 - mean_absolute_error: 9.6379 - val_loss: 8.8319 - val_mean_absolute_error: 8.8319\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 9.5765 - mean_absolute_error: 9.5765 - val_loss: 8.7613 - val_mean_absolute_error: 8.7613\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.5290 - mean_absolute_error: 9.5290 - val_loss: 8.7244 - val_mean_absolute_error: 8.7244\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 9.4817 - mean_absolute_error: 9.4817 - val_loss: 8.7288 - val_mean_absolute_error: 8.7288\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 9.4440 - mean_absolute_error: 9.4440 - val_loss: 8.7541 - val_mean_absolute_error: 8.7541\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 9.3973 - mean_absolute_error: 9.3973 - val_loss: 8.6929 - val_mean_absolute_error: 8.6929\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 9.3616 - mean_absolute_error: 9.3616 - val_loss: 8.6971 - val_mean_absolute_error: 8.6971\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 9.3225 - mean_absolute_error: 9.3225 - val_loss: 8.6627 - val_mean_absolute_error: 8.6627\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 9.2855 - mean_absolute_error: 9.2855 - val_loss: 8.6485 - val_mean_absolute_error: 8.6485\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.2504 - mean_absolute_error: 9.2504 - val_loss: 8.5914 - val_mean_absolute_error: 8.5914\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 9.2177 - mean_absolute_error: 9.2177 - val_loss: 8.6170 - val_mean_absolute_error: 8.6170\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 9.1922 - mean_absolute_error: 9.1922 - val_loss: 8.6281 - val_mean_absolute_error: 8.6281\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.1660 - mean_absolute_error: 9.1660 - val_loss: 8.5943 - val_mean_absolute_error: 8.5943\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 9.1341 - mean_absolute_error: 9.1341 - val_loss: 8.5927 - val_mean_absolute_error: 8.5927\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 9.1158 - mean_absolute_error: 9.1158 - val_loss: 8.4820 - val_mean_absolute_error: 8.4820\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 9.0861 - mean_absolute_error: 9.0861 - val_loss: 8.5677 - val_mean_absolute_error: 8.5677\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.0698 - mean_absolute_error: 9.0698 - val_loss: 8.4617 - val_mean_absolute_error: 8.4617\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.0388 - mean_absolute_error: 9.0388 - val_loss: 8.5081 - val_mean_absolute_error: 8.5081\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.0169 - mean_absolute_error: 9.0169 - val_loss: 8.4719 - val_mean_absolute_error: 8.4719\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.9958 - mean_absolute_error: 8.9958 - val_loss: 8.4391 - val_mean_absolute_error: 8.4391\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.9736 - mean_absolute_error: 8.9736 - val_loss: 8.4006 - val_mean_absolute_error: 8.4006\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.9475 - mean_absolute_error: 8.9475 - val_loss: 8.4180 - val_mean_absolute_error: 8.4180\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9444 - mean_absolute_error: 8.9444 - val_loss: 8.4218 - val_mean_absolute_error: 8.4218\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9191 - mean_absolute_error: 8.9191 - val_loss: 8.4230 - val_mean_absolute_error: 8.4230\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8951 - mean_absolute_error: 8.8951 - val_loss: 8.3707 - val_mean_absolute_error: 8.3707\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8877 - mean_absolute_error: 8.8877 - val_loss: 8.3840 - val_mean_absolute_error: 8.3840\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8674 - mean_absolute_error: 8.8674 - val_loss: 8.3857 - val_mean_absolute_error: 8.3857\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8439 - mean_absolute_error: 8.8439 - val_loss: 8.4014 - val_mean_absolute_error: 8.4014\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8374 - mean_absolute_error: 8.8374 - val_loss: 8.3404 - val_mean_absolute_error: 8.3404\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8063 - mean_absolute_error: 8.8063 - val_loss: 8.3663 - val_mean_absolute_error: 8.3663\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.7987 - mean_absolute_error: 8.7987 - val_loss: 8.4231 - val_mean_absolute_error: 8.4231\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.7837 - mean_absolute_error: 8.7837 - val_loss: 8.3518 - val_mean_absolute_error: 8.3518\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.7685 - mean_absolute_error: 8.7685 - val_loss: 8.3836 - val_mean_absolute_error: 8.3836\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.7492 - mean_absolute_error: 8.7492 - val_loss: 8.3737 - val_mean_absolute_error: 8.3737\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.7420 - mean_absolute_error: 8.7420 - val_loss: 8.3448 - val_mean_absolute_error: 8.3448\n",
      "Epoch 45/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.7243 - mean_absolute_error: 8.7243 - val_loss: 8.3226 - val_mean_absolute_error: 8.3226\n",
      "Epoch 46/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.7208 - mean_absolute_error: 8.7208 - val_loss: 8.3750 - val_mean_absolute_error: 8.3750\n",
      "Epoch 47/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.7066 - mean_absolute_error: 8.7066 - val_loss: 8.4199 - val_mean_absolute_error: 8.4199\n",
      "Epoch 48/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.6899 - mean_absolute_error: 8.6899 - val_loss: 8.4173 - val_mean_absolute_error: 8.4173\n",
      "Epoch 49/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.6728 - mean_absolute_error: 8.6728 - val_loss: 8.2983 - val_mean_absolute_error: 8.2983\n",
      "Epoch 50/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.6596 - mean_absolute_error: 8.6596 - val_loss: 8.3234 - val_mean_absolute_error: 8.3234\n",
      "Epoch 51/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.6477 - mean_absolute_error: 8.6477 - val_loss: 8.2898 - val_mean_absolute_error: 8.2898\n",
      "Epoch 52/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.6369 - mean_absolute_error: 8.6369 - val_loss: 8.3277 - val_mean_absolute_error: 8.3277\n",
      "Epoch 53/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.6323 - mean_absolute_error: 8.6323 - val_loss: 8.3925 - val_mean_absolute_error: 8.3925\n",
      "Epoch 54/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.6198 - mean_absolute_error: 8.6198 - val_loss: 8.2589 - val_mean_absolute_error: 8.2589\n",
      "Epoch 55/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.6050 - mean_absolute_error: 8.6050 - val_loss: 8.3324 - val_mean_absolute_error: 8.3324\n",
      "Epoch 56/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.6027 - mean_absolute_error: 8.6027 - val_loss: 8.2907 - val_mean_absolute_error: 8.2907\n",
      "Epoch 57/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5879 - mean_absolute_error: 8.5879 - val_loss: 8.2684 - val_mean_absolute_error: 8.2684\n",
      "Epoch 58/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.5857 - mean_absolute_error: 8.5857 - val_loss: 8.3445 - val_mean_absolute_error: 8.3445\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5685 - mean_absolute_error: 8.5685 - val_loss: 8.2450 - val_mean_absolute_error: 8.2450\n",
      "Epoch 60/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.5619 - mean_absolute_error: 8.5619 - val_loss: 8.2697 - val_mean_absolute_error: 8.2697\n",
      "Epoch 61/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5444 - mean_absolute_error: 8.5444 - val_loss: 8.3594 - val_mean_absolute_error: 8.3594\n",
      "Epoch 62/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5372 - mean_absolute_error: 8.5372 - val_loss: 8.2447 - val_mean_absolute_error: 8.2447\n",
      "Epoch 63/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.5309 - mean_absolute_error: 8.5309 - val_loss: 8.2471 - val_mean_absolute_error: 8.2471\n",
      "Epoch 64/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5147 - mean_absolute_error: 8.5147 - val_loss: 8.2393 - val_mean_absolute_error: 8.2393\n",
      "Epoch 65/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5145 - mean_absolute_error: 8.5145 - val_loss: 8.2333 - val_mean_absolute_error: 8.2333\n",
      "Epoch 66/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5054 - mean_absolute_error: 8.5054 - val_loss: 8.2230 - val_mean_absolute_error: 8.2230\n",
      "Epoch 67/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.5036 - mean_absolute_error: 8.5036 - val_loss: 8.2971 - val_mean_absolute_error: 8.2971\n",
      "Epoch 68/100\n",
      "1046/1046 [==============================] - 18s 17ms/step - loss: 8.4871 - mean_absolute_error: 8.4871 - val_loss: 8.3056 - val_mean_absolute_error: 8.3056\n",
      "Epoch 69/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.4696 - mean_absolute_error: 8.4696 - val_loss: 8.1903 - val_mean_absolute_error: 8.1903\n",
      "Epoch 70/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.4663 - mean_absolute_error: 8.4663 - val_loss: 8.2685 - val_mean_absolute_error: 8.2685\n",
      "Epoch 71/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.4566 - mean_absolute_error: 8.4566 - val_loss: 8.2627 - val_mean_absolute_error: 8.2627\n",
      "Epoch 72/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.4509 - mean_absolute_error: 8.4509 - val_loss: 8.2676 - val_mean_absolute_error: 8.2676\n",
      "Epoch 73/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.4447 - mean_absolute_error: 8.4447 - val_loss: 8.2160 - val_mean_absolute_error: 8.2160\n",
      "Epoch 74/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.4397 - mean_absolute_error: 8.4397 - val_loss: 8.3322 - val_mean_absolute_error: 8.3322\n",
      "Epoch 75/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.4288 - mean_absolute_error: 8.4288 - val_loss: 8.2416 - val_mean_absolute_error: 8.2416\n",
      "Epoch 76/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.4226 - mean_absolute_error: 8.4226 - val_loss: 8.2833 - val_mean_absolute_error: 8.2833\n",
      "Epoch 77/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.4111 - mean_absolute_error: 8.4111 - val_loss: 8.2540 - val_mean_absolute_error: 8.2540\n",
      "Epoch 78/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.4055 - mean_absolute_error: 8.4055 - val_loss: 8.2233 - val_mean_absolute_error: 8.2233\n",
      "Epoch 79/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3911 - mean_absolute_error: 8.3911 - val_loss: 8.4194 - val_mean_absolute_error: 8.4194\n",
      "Model training time was 28.09 minutes (1685.23 seconds).\n",
      "Average time for each epoch was 0.28 minutes (16.85 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:45:39.179523: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 0, MAE: 9.305492318518825 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:47:34.913852: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-15 22:47:45.577215: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 592326 of 802911\n",
      "2023-05-15 22:47:49.108047: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 24.2765 - mean_absolute_error: 24.2765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 22:48:20.814934: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 56s 35ms/step - loss: 24.2765 - mean_absolute_error: 24.2765 - val_loss: 11.4492 - val_mean_absolute_error: 11.4492\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 10.8973 - mean_absolute_error: 10.8973 - val_loss: 10.0325 - val_mean_absolute_error: 10.0325\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 10.4828 - mean_absolute_error: 10.4828 - val_loss: 9.9506 - val_mean_absolute_error: 9.9506\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 10.2287 - mean_absolute_error: 10.2287 - val_loss: 9.3586 - val_mean_absolute_error: 9.3586\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 10.0682 - mean_absolute_error: 10.0682 - val_loss: 9.1861 - val_mean_absolute_error: 9.1861\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.9403 - mean_absolute_error: 9.9403 - val_loss: 9.1690 - val_mean_absolute_error: 9.1690\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.8504 - mean_absolute_error: 9.8504 - val_loss: 9.3487 - val_mean_absolute_error: 9.3487\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.7650 - mean_absolute_error: 9.7650 - val_loss: 9.0417 - val_mean_absolute_error: 9.0417\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.6925 - mean_absolute_error: 9.6925 - val_loss: 8.9306 - val_mean_absolute_error: 8.9306\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.6350 - mean_absolute_error: 9.6350 - val_loss: 8.8205 - val_mean_absolute_error: 8.8205\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.5722 - mean_absolute_error: 9.5722 - val_loss: 8.8277 - val_mean_absolute_error: 8.8277\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.5181 - mean_absolute_error: 9.5181 - val_loss: 8.7487 - val_mean_absolute_error: 8.7487\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.4654 - mean_absolute_error: 9.4654 - val_loss: 8.7892 - val_mean_absolute_error: 8.7892\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.4306 - mean_absolute_error: 9.4306 - val_loss: 8.7098 - val_mean_absolute_error: 8.7098\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.3871 - mean_absolute_error: 9.3871 - val_loss: 8.6624 - val_mean_absolute_error: 8.6624\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.3438 - mean_absolute_error: 9.3438 - val_loss: 8.6840 - val_mean_absolute_error: 8.6840\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.3112 - mean_absolute_error: 9.3112 - val_loss: 8.6337 - val_mean_absolute_error: 8.6337\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.2782 - mean_absolute_error: 9.2782 - val_loss: 8.6194 - val_mean_absolute_error: 8.6194\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.2529 - mean_absolute_error: 9.2529 - val_loss: 8.5508 - val_mean_absolute_error: 8.5508\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.2167 - mean_absolute_error: 9.2167 - val_loss: 8.5645 - val_mean_absolute_error: 8.5645\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.1915 - mean_absolute_error: 9.1915 - val_loss: 8.5433 - val_mean_absolute_error: 8.5433\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.1532 - mean_absolute_error: 9.1532 - val_loss: 8.5391 - val_mean_absolute_error: 8.5391\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.1391 - mean_absolute_error: 9.1391 - val_loss: 8.6106 - val_mean_absolute_error: 8.6106\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 26s 24ms/step - loss: 9.1055 - mean_absolute_error: 9.1055 - val_loss: 8.4532 - val_mean_absolute_error: 8.4532\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.0841 - mean_absolute_error: 9.0841 - val_loss: 8.4719 - val_mean_absolute_error: 8.4719\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.0667 - mean_absolute_error: 9.0667 - val_loss: 8.4564 - val_mean_absolute_error: 8.4564\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.0431 - mean_absolute_error: 9.0431 - val_loss: 8.5452 - val_mean_absolute_error: 8.5452\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.0059 - mean_absolute_error: 9.0059 - val_loss: 8.6001 - val_mean_absolute_error: 8.6001\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.9834 - mean_absolute_error: 8.9834 - val_loss: 8.5212 - val_mean_absolute_error: 8.5212\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.9730 - mean_absolute_error: 8.9730 - val_loss: 8.4927 - val_mean_absolute_error: 8.4927\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9508 - mean_absolute_error: 8.9508 - val_loss: 8.4372 - val_mean_absolute_error: 8.4372\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.9330 - mean_absolute_error: 8.9330 - val_loss: 8.6046 - val_mean_absolute_error: 8.6046\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9154 - mean_absolute_error: 8.9154 - val_loss: 8.4852 - val_mean_absolute_error: 8.4852\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8915 - mean_absolute_error: 8.8915 - val_loss: 8.4838 - val_mean_absolute_error: 8.4838\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8812 - mean_absolute_error: 8.8812 - val_loss: 8.4687 - val_mean_absolute_error: 8.4687\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8586 - mean_absolute_error: 8.8586 - val_loss: 8.5671 - val_mean_absolute_error: 8.5671\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8442 - mean_absolute_error: 8.8442 - val_loss: 8.5040 - val_mean_absolute_error: 8.5040\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8217 - mean_absolute_error: 8.8217 - val_loss: 8.4552 - val_mean_absolute_error: 8.4552\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8047 - mean_absolute_error: 8.8047 - val_loss: 8.4200 - val_mean_absolute_error: 8.4200\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.7996 - mean_absolute_error: 8.7996 - val_loss: 8.4851 - val_mean_absolute_error: 8.4851\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.7906 - mean_absolute_error: 8.7906 - val_loss: 8.3783 - val_mean_absolute_error: 8.3783\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.7702 - mean_absolute_error: 8.7702 - val_loss: 8.7149 - val_mean_absolute_error: 8.7149\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.7504 - mean_absolute_error: 8.7504 - val_loss: 8.3659 - val_mean_absolute_error: 8.3659\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.7451 - mean_absolute_error: 8.7451 - val_loss: 8.3772 - val_mean_absolute_error: 8.3772\n",
      "Epoch 45/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.7366 - mean_absolute_error: 8.7366 - val_loss: 8.4015 - val_mean_absolute_error: 8.4015\n",
      "Epoch 46/100\n",
      "1046/1046 [==============================] - 23s 22ms/step - loss: 8.7164 - mean_absolute_error: 8.7164 - val_loss: 8.2693 - val_mean_absolute_error: 8.2693\n",
      "Epoch 47/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 8.7039 - mean_absolute_error: 8.7039 - val_loss: 8.3857 - val_mean_absolute_error: 8.3857\n",
      "Epoch 48/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 8.6902 - mean_absolute_error: 8.6902 - val_loss: 8.4097 - val_mean_absolute_error: 8.4097\n",
      "Epoch 49/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.6767 - mean_absolute_error: 8.6767 - val_loss: 8.3372 - val_mean_absolute_error: 8.3372\n",
      "Epoch 50/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 8.6615 - mean_absolute_error: 8.6615 - val_loss: 8.2934 - val_mean_absolute_error: 8.2934\n",
      "Epoch 51/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 8.6544 - mean_absolute_error: 8.6544 - val_loss: 8.5270 - val_mean_absolute_error: 8.5270\n",
      "Epoch 52/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 8.6423 - mean_absolute_error: 8.6423 - val_loss: 8.3209 - val_mean_absolute_error: 8.3209\n",
      "Epoch 53/100\n",
      "1046/1046 [==============================] - 16s 16ms/step - loss: 8.6279 - mean_absolute_error: 8.6279 - val_loss: 8.3343 - val_mean_absolute_error: 8.3343\n",
      "Epoch 54/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.6254 - mean_absolute_error: 8.6254 - val_loss: 8.2779 - val_mean_absolute_error: 8.2779\n",
      "Epoch 55/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 8.6174 - mean_absolute_error: 8.6174 - val_loss: 8.3782 - val_mean_absolute_error: 8.3782\n",
      "Epoch 56/100\n",
      "1046/1046 [==============================] - 16s 15ms/step - loss: 8.6026 - mean_absolute_error: 8.6026 - val_loss: 8.2666 - val_mean_absolute_error: 8.2666\n",
      "Epoch 57/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.5941 - mean_absolute_error: 8.5941 - val_loss: 8.2915 - val_mean_absolute_error: 8.2915\n",
      "Epoch 58/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5799 - mean_absolute_error: 8.5799 - val_loss: 8.2486 - val_mean_absolute_error: 8.2486\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.5712 - mean_absolute_error: 8.5712 - val_loss: 8.3193 - val_mean_absolute_error: 8.3193\n",
      "Epoch 60/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.5638 - mean_absolute_error: 8.5638 - val_loss: 8.3207 - val_mean_absolute_error: 8.3207\n",
      "Epoch 61/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5526 - mean_absolute_error: 8.5526 - val_loss: 8.3838 - val_mean_absolute_error: 8.3838\n",
      "Epoch 62/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5410 - mean_absolute_error: 8.5410 - val_loss: 8.2677 - val_mean_absolute_error: 8.2677\n",
      "Epoch 63/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5347 - mean_absolute_error: 8.5347 - val_loss: 8.2232 - val_mean_absolute_error: 8.2232\n",
      "Epoch 64/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5240 - mean_absolute_error: 8.5240 - val_loss: 8.2850 - val_mean_absolute_error: 8.2850\n",
      "Epoch 65/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5211 - mean_absolute_error: 8.5211 - val_loss: 8.2727 - val_mean_absolute_error: 8.2727\n",
      "Epoch 66/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5036 - mean_absolute_error: 8.5036 - val_loss: 8.2554 - val_mean_absolute_error: 8.2554\n",
      "Epoch 67/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5023 - mean_absolute_error: 8.5023 - val_loss: 8.2880 - val_mean_absolute_error: 8.2880\n",
      "Epoch 68/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.4948 - mean_absolute_error: 8.4948 - val_loss: 8.2499 - val_mean_absolute_error: 8.2499\n",
      "Epoch 69/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.4838 - mean_absolute_error: 8.4838 - val_loss: 8.3067 - val_mean_absolute_error: 8.3067\n",
      "Epoch 70/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.4753 - mean_absolute_error: 8.4753 - val_loss: 8.2538 - val_mean_absolute_error: 8.2538\n",
      "Epoch 71/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.4715 - mean_absolute_error: 8.4715 - val_loss: 8.1654 - val_mean_absolute_error: 8.1654\n",
      "Epoch 72/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.4577 - mean_absolute_error: 8.4577 - val_loss: 8.2663 - val_mean_absolute_error: 8.2663\n",
      "Epoch 73/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.4563 - mean_absolute_error: 8.4563 - val_loss: 8.2656 - val_mean_absolute_error: 8.2656\n",
      "Epoch 74/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.4439 - mean_absolute_error: 8.4439 - val_loss: 8.2556 - val_mean_absolute_error: 8.2556\n",
      "Epoch 75/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.4422 - mean_absolute_error: 8.4422 - val_loss: 8.2132 - val_mean_absolute_error: 8.2132\n",
      "Epoch 76/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.4321 - mean_absolute_error: 8.4321 - val_loss: 8.2583 - val_mean_absolute_error: 8.2583\n",
      "Epoch 77/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.4243 - mean_absolute_error: 8.4243 - val_loss: 8.1669 - val_mean_absolute_error: 8.1669\n",
      "Epoch 78/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.4157 - mean_absolute_error: 8.4157 - val_loss: 8.1398 - val_mean_absolute_error: 8.1398\n",
      "Epoch 79/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.4144 - mean_absolute_error: 8.4144 - val_loss: 8.2853 - val_mean_absolute_error: 8.2853\n",
      "Epoch 80/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.3968 - mean_absolute_error: 8.3968 - val_loss: 8.1435 - val_mean_absolute_error: 8.1435\n",
      "Epoch 81/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3978 - mean_absolute_error: 8.3978 - val_loss: 8.2573 - val_mean_absolute_error: 8.2573\n",
      "Epoch 82/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.3888 - mean_absolute_error: 8.3888 - val_loss: 8.2265 - val_mean_absolute_error: 8.2265\n",
      "Epoch 83/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.3913 - mean_absolute_error: 8.3913 - val_loss: 8.1579 - val_mean_absolute_error: 8.1579\n",
      "Epoch 84/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3817 - mean_absolute_error: 8.3817 - val_loss: 8.1795 - val_mean_absolute_error: 8.1795\n",
      "Epoch 85/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.3665 - mean_absolute_error: 8.3665 - val_loss: 8.1426 - val_mean_absolute_error: 8.1426\n",
      "Epoch 86/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3510 - mean_absolute_error: 8.3510 - val_loss: 8.1668 - val_mean_absolute_error: 8.1668\n",
      "Epoch 87/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.3530 - mean_absolute_error: 8.3530 - val_loss: 8.1250 - val_mean_absolute_error: 8.1250\n",
      "Epoch 88/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.3453 - mean_absolute_error: 8.3453 - val_loss: 8.2922 - val_mean_absolute_error: 8.2922\n",
      "Epoch 89/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3390 - mean_absolute_error: 8.3390 - val_loss: 8.2105 - val_mean_absolute_error: 8.2105\n",
      "Epoch 90/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3302 - mean_absolute_error: 8.3302 - val_loss: 8.1757 - val_mean_absolute_error: 8.1757\n",
      "Epoch 91/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3301 - mean_absolute_error: 8.3301 - val_loss: 8.1358 - val_mean_absolute_error: 8.1358\n",
      "Epoch 92/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3152 - mean_absolute_error: 8.3152 - val_loss: 8.2605 - val_mean_absolute_error: 8.2605\n",
      "Epoch 93/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3176 - mean_absolute_error: 8.3176 - val_loss: 8.1242 - val_mean_absolute_error: 8.1242\n",
      "Epoch 94/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3073 - mean_absolute_error: 8.3073 - val_loss: 8.1741 - val_mean_absolute_error: 8.1741\n",
      "Epoch 95/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3091 - mean_absolute_error: 8.3091 - val_loss: 8.1722 - val_mean_absolute_error: 8.1722\n",
      "Epoch 96/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.2958 - mean_absolute_error: 8.2958 - val_loss: 8.2164 - val_mean_absolute_error: 8.2164\n",
      "Epoch 97/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.2788 - mean_absolute_error: 8.2788 - val_loss: 8.2151 - val_mean_absolute_error: 8.2151\n",
      "Epoch 98/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.2735 - mean_absolute_error: 8.2735 - val_loss: 8.1926 - val_mean_absolute_error: 8.1926\n",
      "Epoch 99/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.2796 - mean_absolute_error: 8.2796 - val_loss: 8.1113 - val_mean_absolute_error: 8.1113\n",
      "Epoch 100/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.2741 - mean_absolute_error: 8.2741 - val_loss: 8.2111 - val_mean_absolute_error: 8.2111\n",
      "Model training time was 37.33 minutes (2239.61 seconds).\n",
      "Average time for each epoch was 0.37 minutes (22.40 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 23:25:27.341234: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 1, MAE: 9.394648825867902 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 23:27:19.804571: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-15 23:27:30.479173: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 594089 of 802911\n",
      "2023-05-15 23:27:34.006291: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 24.2796 - mean_absolute_error: 24.2796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 23:28:00.353107: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 55s 33ms/step - loss: 24.2796 - mean_absolute_error: 24.2796 - val_loss: 11.0202 - val_mean_absolute_error: 11.0202\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 10.9053 - mean_absolute_error: 10.9053 - val_loss: 10.6080 - val_mean_absolute_error: 10.6080\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 10.4844 - mean_absolute_error: 10.4844 - val_loss: 9.8609 - val_mean_absolute_error: 9.8609\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 10.2375 - mean_absolute_error: 10.2375 - val_loss: 9.4653 - val_mean_absolute_error: 9.4653\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 10.0769 - mean_absolute_error: 10.0769 - val_loss: 9.2978 - val_mean_absolute_error: 9.2978\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.9613 - mean_absolute_error: 9.9613 - val_loss: 9.3988 - val_mean_absolute_error: 9.3988\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.8592 - mean_absolute_error: 9.8592 - val_loss: 9.1480 - val_mean_absolute_error: 9.1480\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.7792 - mean_absolute_error: 9.7792 - val_loss: 9.1229 - val_mean_absolute_error: 9.1229\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.7061 - mean_absolute_error: 9.7061 - val_loss: 9.1732 - val_mean_absolute_error: 9.1732\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.6476 - mean_absolute_error: 9.6476 - val_loss: 9.0122 - val_mean_absolute_error: 9.0122\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.5844 - mean_absolute_error: 9.5844 - val_loss: 9.0929 - val_mean_absolute_error: 9.0929\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.5350 - mean_absolute_error: 9.5350 - val_loss: 9.0106 - val_mean_absolute_error: 9.0106\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.4916 - mean_absolute_error: 9.4916 - val_loss: 8.9323 - val_mean_absolute_error: 8.9323\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.4490 - mean_absolute_error: 9.4490 - val_loss: 8.8301 - val_mean_absolute_error: 8.8301\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.4114 - mean_absolute_error: 9.4114 - val_loss: 8.6844 - val_mean_absolute_error: 8.6844\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.3611 - mean_absolute_error: 9.3611 - val_loss: 8.7490 - val_mean_absolute_error: 8.7490\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.3293 - mean_absolute_error: 9.3293 - val_loss: 8.6850 - val_mean_absolute_error: 8.6850\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.2871 - mean_absolute_error: 9.2871 - val_loss: 8.8942 - val_mean_absolute_error: 8.8942\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.2674 - mean_absolute_error: 9.2674 - val_loss: 8.7774 - val_mean_absolute_error: 8.7774\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 26s 24ms/step - loss: 9.2361 - mean_absolute_error: 9.2361 - val_loss: 8.5302 - val_mean_absolute_error: 8.5302\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.2108 - mean_absolute_error: 9.2108 - val_loss: 8.5669 - val_mean_absolute_error: 8.5669\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.1746 - mean_absolute_error: 9.1746 - val_loss: 8.6906 - val_mean_absolute_error: 8.6906\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.1481 - mean_absolute_error: 9.1481 - val_loss: 8.5727 - val_mean_absolute_error: 8.5727\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.1325 - mean_absolute_error: 9.1325 - val_loss: 8.6078 - val_mean_absolute_error: 8.6078\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.1035 - mean_absolute_error: 9.1035 - val_loss: 8.5415 - val_mean_absolute_error: 8.5415\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.0736 - mean_absolute_error: 9.0736 - val_loss: 8.5175 - val_mean_absolute_error: 8.5175\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.0539 - mean_absolute_error: 9.0539 - val_loss: 8.5679 - val_mean_absolute_error: 8.5679\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.0410 - mean_absolute_error: 9.0410 - val_loss: 8.4972 - val_mean_absolute_error: 8.4972\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.0139 - mean_absolute_error: 9.0139 - val_loss: 8.5628 - val_mean_absolute_error: 8.5628\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9873 - mean_absolute_error: 8.9873 - val_loss: 8.6112 - val_mean_absolute_error: 8.6112\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8661 - mean_absolute_error: 8.8661 - val_loss: 8.3905 - val_mean_absolute_error: 8.3905\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.8529 - mean_absolute_error: 8.8529 - val_loss: 8.4539 - val_mean_absolute_error: 8.4539\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.8382 - mean_absolute_error: 8.8382 - val_loss: 8.4014 - val_mean_absolute_error: 8.4014\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8230 - mean_absolute_error: 8.8230 - val_loss: 8.3711 - val_mean_absolute_error: 8.3711\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.8100 - mean_absolute_error: 8.8100 - val_loss: 8.3226 - val_mean_absolute_error: 8.3226\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.7917 - mean_absolute_error: 8.7917 - val_loss: 8.3507 - val_mean_absolute_error: 8.3507\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.7739 - mean_absolute_error: 8.7739 - val_loss: 8.3148 - val_mean_absolute_error: 8.3148\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.7572 - mean_absolute_error: 8.7572 - val_loss: 8.3406 - val_mean_absolute_error: 8.3406\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.7514 - mean_absolute_error: 8.7514 - val_loss: 8.3494 - val_mean_absolute_error: 8.3494\n",
      "Epoch 45/100\n",
      " 614/1046 [================>.............] - ETA: 7s - loss: 8.7498 - mean_absolute_error: 8.7498"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.4794 - mean_absolute_error: 8.4794 - val_loss: 8.3492 - val_mean_absolute_error: 8.3492\n",
      "Model training time was 25.48 minutes (1528.67 seconds).\n",
      "Average time for each epoch was 0.25 minutes (15.29 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 23:52:58.127200: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 2, MAE: 9.330022136823363 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 23:54:52.260278: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-15 23:55:02.915833: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 557991 of 802911\n",
      "2023-05-15 23:55:09.873724: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 24.4134 - mean_absolute_error: 24.4134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 23:55:36.157662: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 54s 30ms/step - loss: 24.4134 - mean_absolute_error: 24.4134 - val_loss: 10.9647 - val_mean_absolute_error: 10.9647\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 10.8902 - mean_absolute_error: 10.8902 - val_loss: 9.9097 - val_mean_absolute_error: 9.9097\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 10.4672 - mean_absolute_error: 10.4672 - val_loss: 9.6286 - val_mean_absolute_error: 9.6286\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 10.2189 - mean_absolute_error: 10.2189 - val_loss: 9.5515 - val_mean_absolute_error: 9.5515\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 26s 24ms/step - loss: 10.0591 - mean_absolute_error: 10.0591 - val_loss: 9.3246 - val_mean_absolute_error: 9.3246\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.9359 - mean_absolute_error: 9.9359 - val_loss: 9.3630 - val_mean_absolute_error: 9.3630\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.8311 - mean_absolute_error: 9.8311 - val_loss: 9.3838 - val_mean_absolute_error: 9.3838\n",
      "Epoch 8/100\n",
      " 422/1046 [===========>..................] - ETA: 19s - loss: 9.7898 - mean_absolute_error: 9.7898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.4288 - mean_absolute_error: 9.4288 - val_loss: 8.7118 - val_mean_absolute_error: 8.7118\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 26s 24ms/step - loss: 9.3901 - mean_absolute_error: 9.3901 - val_loss: 8.7406 - val_mean_absolute_error: 8.7406\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.3491 - mean_absolute_error: 9.3491 - val_loss: 8.6485 - val_mean_absolute_error: 8.6485\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.3183 - mean_absolute_error: 9.3183 - val_loss: 8.6311 - val_mean_absolute_error: 8.6311\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 26s 24ms/step - loss: 9.2816 - mean_absolute_error: 9.2816 - val_loss: 8.6327 - val_mean_absolute_error: 8.6327\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.2433 - mean_absolute_error: 9.2433 - val_loss: 8.7005 - val_mean_absolute_error: 8.7005\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.2226 - mean_absolute_error: 9.2226 - val_loss: 8.7574 - val_mean_absolute_error: 8.7574\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.1872 - mean_absolute_error: 9.1872 - val_loss: 8.5535 - val_mean_absolute_error: 8.5535\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.1613 - mean_absolute_error: 9.1613 - val_loss: 8.5365 - val_mean_absolute_error: 8.5365\n",
      "Epoch 23/100\n",
      " 298/1046 [=======>......................] - ETA: 13s - loss: 9.1400 - mean_absolute_error: 9.1400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.9674 - mean_absolute_error: 8.9674 - val_loss: 8.4238 - val_mean_absolute_error: 8.4238\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.9419 - mean_absolute_error: 8.9419 - val_loss: 8.4184 - val_mean_absolute_error: 8.4184\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.9255 - mean_absolute_error: 8.9255 - val_loss: 8.3714 - val_mean_absolute_error: 8.3714\n",
      "Epoch 33/100\n",
      " 924/1046 [=========================>....] - ETA: 2s - loss: 8.8951 - mean_absolute_error: 8.8951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8196 - mean_absolute_error: 8.8196 - val_loss: 8.3523 - val_mean_absolute_error: 8.3523\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.8094 - mean_absolute_error: 8.8094 - val_loss: 8.4803 - val_mean_absolute_error: 8.4803\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.7858 - mean_absolute_error: 8.7858 - val_loss: 8.3899 - val_mean_absolute_error: 8.3899\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.7725 - mean_absolute_error: 8.7725 - val_loss: 8.3740 - val_mean_absolute_error: 8.3740\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.7551 - mean_absolute_error: 8.7551 - val_loss: 8.3175 - val_mean_absolute_error: 8.3175\n",
      "Epoch 43/100\n",
      "  61/1046 [>.............................] - ETA: 17s - loss: 8.9641 - mean_absolute_error: 8.9641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5717 - mean_absolute_error: 8.5717 - val_loss: 8.2765 - val_mean_absolute_error: 8.2765\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.5530 - mean_absolute_error: 8.5530 - val_loss: 8.2256 - val_mean_absolute_error: 8.2256\n",
      "Epoch 60/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.5489 - mean_absolute_error: 8.5489 - val_loss: 8.2515 - val_mean_absolute_error: 8.2515\n",
      "Epoch 61/100\n",
      "1027/1046 [============================>.] - ETA: 0s - loss: 8.5430 - mean_absolute_error: 8.5430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.4743 - mean_absolute_error: 8.4743 - val_loss: 8.2335 - val_mean_absolute_error: 8.2335\n",
      "Epoch 70/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.4567 - mean_absolute_error: 8.4567 - val_loss: 8.2228 - val_mean_absolute_error: 8.2228\n",
      "Epoch 71/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.4549 - mean_absolute_error: 8.4549 - val_loss: 8.2295 - val_mean_absolute_error: 8.2295\n",
      "Epoch 72/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.4421 - mean_absolute_error: 8.4421 - val_loss: 8.2684 - val_mean_absolute_error: 8.2684\n",
      "Epoch 73/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.4374 - mean_absolute_error: 8.4374 - val_loss: 8.4404 - val_mean_absolute_error: 8.4404\n",
      "Epoch 74/100\n",
      " 184/1046 [====>.........................] - ETA: 15s - loss: 8.4784 - mean_absolute_error: 8.4784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 24s 23ms/step - loss: 8.3126 - mean_absolute_error: 8.3126 - val_loss: 8.2064 - val_mean_absolute_error: 8.2064\n",
      "Epoch 90/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 8.3063 - mean_absolute_error: 8.3063 - val_loss: 8.3010 - val_mean_absolute_error: 8.3010\n",
      "Epoch 91/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 8.3044 - mean_absolute_error: 8.3044 - val_loss: 8.2937 - val_mean_absolute_error: 8.2937\n",
      "Epoch 92/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 8.2928 - mean_absolute_error: 8.2928 - val_loss: 8.1916 - val_mean_absolute_error: 8.1916\n",
      "Epoch 93/100\n",
      "1046/1046 [==============================] - 17s 16ms/step - loss: 8.2919 - mean_absolute_error: 8.2919 - val_loss: 8.1873 - val_mean_absolute_error: 8.1873\n",
      "Epoch 94/100\n",
      " 297/1046 [=======>......................] - ETA: 12s - loss: 8.2983 - mean_absolute_error: 8.2983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 20s 19ms/step - loss: 10.0699 - mean_absolute_error: 10.0699 - val_loss: 9.4773 - val_mean_absolute_error: 9.4773\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.9408 - mean_absolute_error: 9.9408 - val_loss: 9.1582 - val_mean_absolute_error: 9.1582\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.8481 - mean_absolute_error: 9.8481 - val_loss: 9.1960 - val_mean_absolute_error: 9.1960\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.7696 - mean_absolute_error: 9.7696 - val_loss: 8.9851 - val_mean_absolute_error: 8.9851\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.6991 - mean_absolute_error: 9.6991 - val_loss: 9.0017 - val_mean_absolute_error: 9.0017\n",
      "Epoch 10/100\n",
      "  64/1046 [>.............................] - ETA: 17s - loss: 9.6326 - mean_absolute_error: 9.6326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.1011 - mean_absolute_error: 9.1011 - val_loss: 8.5357 - val_mean_absolute_error: 8.5357\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 9.0705 - mean_absolute_error: 9.0705 - val_loss: 8.4511 - val_mean_absolute_error: 8.4511\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.0441 - mean_absolute_error: 9.0441 - val_loss: 8.4759 - val_mean_absolute_error: 8.4759\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 9.0214 - mean_absolute_error: 9.0214 - val_loss: 8.4401 - val_mean_absolute_error: 8.4401\n",
      "Epoch 29/100\n",
      "  82/1046 [=>............................] - ETA: 17s - loss: 9.0177 - mean_absolute_error: 9.0177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8767 - mean_absolute_error: 8.8767 - val_loss: 8.3719 - val_mean_absolute_error: 8.3719\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8548 - mean_absolute_error: 8.8548 - val_loss: 8.4121 - val_mean_absolute_error: 8.4121\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8397 - mean_absolute_error: 8.8397 - val_loss: 8.4498 - val_mean_absolute_error: 8.4498\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8328 - mean_absolute_error: 8.8328 - val_loss: 8.3329 - val_mean_absolute_error: 8.3329\n",
      "Epoch 40/100\n",
      "1038/1046 [============================>.] - ETA: 0s - loss: 8.8058 - mean_absolute_error: 8.8058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 26s 24ms/step - loss: 8.6173 - mean_absolute_error: 8.6173 - val_loss: 8.3851 - val_mean_absolute_error: 8.3851\n",
      "Epoch 57/100\n",
      "1046/1046 [==============================] - 20s 19ms/step - loss: 8.6110 - mean_absolute_error: 8.6110 - val_loss: 8.4109 - val_mean_absolute_error: 8.4109\n",
      "Epoch 58/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.5965 - mean_absolute_error: 8.5965 - val_loss: 8.3671 - val_mean_absolute_error: 8.3671\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 18s 17ms/step - loss: 8.5803 - mean_absolute_error: 8.5803 - val_loss: 8.3021 - val_mean_absolute_error: 8.3021\n",
      "Epoch 60/100\n",
      "  28/1046 [..............................] - ETA: 18s - loss: 8.7970 - mean_absolute_error: 8.7970"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.9349 - mean_absolute_error: 9.9349 - val_loss: 9.1668 - val_mean_absolute_error: 9.1668\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 9.8383 - mean_absolute_error: 9.8383 - val_loss: 9.0283 - val_mean_absolute_error: 9.0283\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.7632 - mean_absolute_error: 9.7632 - val_loss: 8.8974 - val_mean_absolute_error: 8.8974\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.6870 - mean_absolute_error: 9.6870 - val_loss: 8.8457 - val_mean_absolute_error: 8.8457\n",
      "Epoch 10/100\n",
      " 619/1046 [================>.............] - ETA: 7s - loss: 9.6606 - mean_absolute_error: 9.6606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.0868 - mean_absolute_error: 9.0868 - val_loss: 8.6046 - val_mean_absolute_error: 8.6046\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3479 - mean_absolute_error: 8.3479 - val_loss: 8.1785 - val_mean_absolute_error: 8.1785\n",
      "Epoch 87/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3273 - mean_absolute_error: 8.3273 - val_loss: 8.1519 - val_mean_absolute_error: 8.1519\n",
      "Epoch 88/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3436 - mean_absolute_error: 8.3436 - val_loss: 8.1445 - val_mean_absolute_error: 8.1445\n",
      "Epoch 89/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3237 - mean_absolute_error: 8.3237 - val_loss: 8.1668 - val_mean_absolute_error: 8.1668\n",
      "Epoch 90/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3265 - mean_absolute_error: 8.3265 - val_loss: 8.1944 - val_mean_absolute_error: 8.1944\n",
      "Epoch 91/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3162 - mean_absolute_error: 8.3162 - val_loss: 8.1605 - val_mean_absolute_error: 8.1605\n",
      "Epoch 92/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.3022 - mean_absolute_error: 8.3022 - val_loss: 8.1226 - val_mean_absolute_error: 8.1226\n",
      "Epoch 93/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.3080 - mean_absolute_error: 8.3080 - val_loss: 8.1202 - val_mean_absolute_error: 8.1202\n",
      "Epoch 94/100\n",
      "1046/1046 [==============================] - 20s 20ms/step - loss: 8.3003 - mean_absolute_error: 8.3003 - val_loss: 8.1165 - val_mean_absolute_error: 8.1165\n",
      "Epoch 95/100\n",
      " 368/1046 [=========>....................] - ETA: 11s - loss: 8.3170 - mean_absolute_error: 8.3170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.2672 - mean_absolute_error: 8.2672 - val_loss: 8.1291 - val_mean_absolute_error: 8.1291\n",
      "Epoch 99/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.2663 - mean_absolute_error: 8.2663 - val_loss: 8.1372 - val_mean_absolute_error: 8.1372\n",
      "Epoch 100/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.2563 - mean_absolute_error: 8.2563 - val_loss: 8.1166 - val_mean_absolute_error: 8.1166\n",
      "Model training time was 38.06 minutes (2283.51 seconds).\n",
      "Average time for each epoch was 0.38 minutes (22.84 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 02:05:58.293761: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 6, MAE: 9.315381832471289 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 02:07:54.018909: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-16 02:08:04.698546: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 509455 of 802911\n",
      "2023-05-16 02:08:11.902662: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 24.3200 - mean_absolute_error: 24.3200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 02:08:39.998019: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 57s 31ms/step - loss: 24.3200 - mean_absolute_error: 24.3200 - val_loss: 11.0921 - val_mean_absolute_error: 11.0921\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 10.8739 - mean_absolute_error: 10.8739 - val_loss: 9.9676 - val_mean_absolute_error: 9.9676\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 10.4475 - mean_absolute_error: 10.4475 - val_loss: 9.5761 - val_mean_absolute_error: 9.5761\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 10.2016 - mean_absolute_error: 10.2016 - val_loss: 9.5130 - val_mean_absolute_error: 9.5130\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 10.0382 - mean_absolute_error: 10.0382 - val_loss: 9.2909 - val_mean_absolute_error: 9.2909\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.9199 - mean_absolute_error: 9.9199 - val_loss: 9.2102 - val_mean_absolute_error: 9.2102\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 9.8270 - mean_absolute_error: 9.8270 - val_loss: 9.0496 - val_mean_absolute_error: 9.0496\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.7431 - mean_absolute_error: 9.7431 - val_loss: 8.9386 - val_mean_absolute_error: 8.9386\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.6775 - mean_absolute_error: 9.6775 - val_loss: 9.1755 - val_mean_absolute_error: 9.1755\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.6196 - mean_absolute_error: 9.6196 - val_loss: 8.9583 - val_mean_absolute_error: 8.9583\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.5551 - mean_absolute_error: 9.5551 - val_loss: 9.0128 - val_mean_absolute_error: 9.0128\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.5082 - mean_absolute_error: 9.5082 - val_loss: 8.7888 - val_mean_absolute_error: 8.7888\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.4663 - mean_absolute_error: 9.4663 - val_loss: 8.7023 - val_mean_absolute_error: 8.7023\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.4249 - mean_absolute_error: 9.4249 - val_loss: 8.7799 - val_mean_absolute_error: 8.7799\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.3780 - mean_absolute_error: 9.3780 - val_loss: 8.6337 - val_mean_absolute_error: 8.6337\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.3421 - mean_absolute_error: 9.3421 - val_loss: 8.6877 - val_mean_absolute_error: 8.6877\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.3081 - mean_absolute_error: 9.3081 - val_loss: 8.7725 - val_mean_absolute_error: 8.7725\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.2703 - mean_absolute_error: 9.2703 - val_loss: 8.5704 - val_mean_absolute_error: 8.5704\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.2431 - mean_absolute_error: 9.2431 - val_loss: 8.6440 - val_mean_absolute_error: 8.6440\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.2084 - mean_absolute_error: 9.2084 - val_loss: 8.6326 - val_mean_absolute_error: 8.6326\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.1710 - mean_absolute_error: 9.1710 - val_loss: 8.5546 - val_mean_absolute_error: 8.5546\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.1586 - mean_absolute_error: 9.1586 - val_loss: 8.4925 - val_mean_absolute_error: 8.4925\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.1300 - mean_absolute_error: 9.1300 - val_loss: 8.5173 - val_mean_absolute_error: 8.5173\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.1075 - mean_absolute_error: 9.1075 - val_loss: 8.5287 - val_mean_absolute_error: 8.5287\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 9.0877 - mean_absolute_error: 9.0877 - val_loss: 8.4687 - val_mean_absolute_error: 8.4687\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.0513 - mean_absolute_error: 9.0513 - val_loss: 8.5054 - val_mean_absolute_error: 8.5054\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.0446 - mean_absolute_error: 9.0446 - val_loss: 8.5026 - val_mean_absolute_error: 8.5026\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.0108 - mean_absolute_error: 9.0108 - val_loss: 8.4371 - val_mean_absolute_error: 8.4371\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9863 - mean_absolute_error: 8.9863 - val_loss: 8.3774 - val_mean_absolute_error: 8.3774\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9707 - mean_absolute_error: 8.9707 - val_loss: 8.4670 - val_mean_absolute_error: 8.4670\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.9473 - mean_absolute_error: 8.9473 - val_loss: 8.4252 - val_mean_absolute_error: 8.4252\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.9386 - mean_absolute_error: 8.9386 - val_loss: 8.3923 - val_mean_absolute_error: 8.3923\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 25s 24ms/step - loss: 8.9102 - mean_absolute_error: 8.9102 - val_loss: 8.3946 - val_mean_absolute_error: 8.3946\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8908 - mean_absolute_error: 8.8908 - val_loss: 8.4067 - val_mean_absolute_error: 8.4067\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8770 - mean_absolute_error: 8.8770 - val_loss: 8.3791 - val_mean_absolute_error: 8.3791\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8552 - mean_absolute_error: 8.8552 - val_loss: 8.3816 - val_mean_absolute_error: 8.3816\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8405 - mean_absolute_error: 8.8405 - val_loss: 8.3777 - val_mean_absolute_error: 8.3777\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 8.8240 - mean_absolute_error: 8.8240 - val_loss: 8.4336 - val_mean_absolute_error: 8.4336\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 8.8145 - mean_absolute_error: 8.8145 - val_loss: 8.4265 - val_mean_absolute_error: 8.4265\n",
      "Model training time was 15.48 minutes (928.91 seconds).\n",
      "Average time for each epoch was 0.15 minutes (9.29 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 02:23:26.858006: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254866432 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 7, MAE: 9.309889960993559 =========================\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(8):\n",
    "    history, model = train_model(x_train, y_train, x_val, y_val, shuffle=True, shuffle_buffer=0.75)\n",
    "    pred = model.predict(x_test)\n",
    "    predictions.append(pred)\n",
    "    print('='*25+f' TRIAL {i}, MAE: {mean_absolute_error(pred,y_test)} '+'='*25)\n",
    "    results.append([history, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ff15239-8f1e-4f6d-b431-f369b3e26348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.305492318518825\n",
      "9.394648825867902\n",
      "9.330022136823363\n",
      "9.267440123243153\n",
      "9.287088063905149\n",
      "9.313944806064923\n",
      "9.315381832471289\n",
      "9.309889960993559\n"
     ]
    }
   ],
   "source": [
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'{mean_absolute_error(prediction, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914f1ac-6f49-4002-b083-cffa639fea90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5733a7a-9728-4e91-8cbc-029c5070ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.stack(predictions).reshape(8, -1).T, columns = [f'model_{i}' for i in range(1,9)])\n",
    "test_dataframe[[f'prediction_{i}' for i in range(1,9)]] = pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "194638de-adb8-4a01-9e09-afd3f6e04427",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe.to_pickle('diff_ys-yield_history_2-2023_05_09.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d91511-c477-4420-9dbe-9d2dbb416e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
