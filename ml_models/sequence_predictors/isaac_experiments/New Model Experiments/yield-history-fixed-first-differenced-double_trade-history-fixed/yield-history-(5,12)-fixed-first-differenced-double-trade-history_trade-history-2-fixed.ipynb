{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c407d3f-44f9-44c7-b20c-aacf5d9dd5e0",
   "metadata": {},
   "source": [
    "TRADE HISTORY LENGTH 2, CORRECTLY ORDERED \n",
    "\n",
    "YIELD CURVE HISTORY 5MIN_12_AVERAGE , CORRECTLY ORDERED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58de4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 17:38:18.179558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:38:18.306275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 17:38:18.307960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pandarallel with 16.0 cores\n",
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "TF Version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "from ficc.utils.nelson_siegel_model import *\n",
    "from ficc.utils.diff_in_days import *\n",
    "from ficc.utils.auxiliary_functions import sqltodf\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, NON_CAT_FEATURES, BINARY, CATEGORICAL_FEATURES, IDENTIFIERS, PURPOSE_CLASS_DICT, NUM_OF_DAYS_IN_YEAR\n",
    "from ficc.utils.gcp_storage_functions import upload_data, download_data\n",
    "from ficc.utils.auxiliary_variables import RELATED_TRADE_BINARY_FEATURES, RELATED_TRADE_NON_CAT_FEATURES, RELATED_TRADE_CATEGORICAL_FEATURES\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from ficc_keras_utils import *\n",
    "import ficc_keras_utils\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(f'TF Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c11246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/ficc/isaac_creds.json\"\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()\n",
    "\n",
    "##COMMON VARIABLES\n",
    "#DATA WINDOW\n",
    "train_start = ficc_keras_utils.train_start\n",
    "train_end = ficc_keras_utils.train_end\n",
    "test_start = ficc_keras_utils.test_start\n",
    "test_end = ficc_keras_utils.test_end\n",
    "#MODEL PARAMETERS \n",
    "VALIDATION_SPLIT = ficc_keras_utils.VALIDATION_SPLIT\n",
    "LEARNING_RATE = ficc_keras_utils.LEARNING_RATE\n",
    "BATCH_SIZE = ficc_keras_utils.BATCH_SIZE\n",
    "NUM_EPOCHS = ficc_keras_utils.NUM_EPOCHS\n",
    "DROPOUT = ficc_keras_utils.DROPOUT\n",
    "\n",
    "##NOTEBOOK SPECIFIC VARIABLES \n",
    "TRADE_SEQUENCE_LENGTH = 2\n",
    "YIELD_SEQUENCE_LENGTH = 11\n",
    "NUM_FEATURES = 6\n",
    "# target_variable = 'new_ys_diff'\n",
    "target_variable = 'new_ys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca18089-58e8-4a2e-9c50-11898bfde236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-01 2023-03-01 2023-03-01 2023-04-01\n"
     ]
    }
   ],
   "source": [
    "print(train_start ,\n",
    "train_end ,\n",
    "test_start ,\n",
    "test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7cee41-fd7e-48ae-bf29-9ae07e10b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.read_pickle('../../'processed_file_FULL_2023-05-03-17:08_5min_12_exp.pkl'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc47f4e4-9a1a-4ffa-932c-5413827d0731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "incorporated_state_code\n",
      "trade_type\n",
      "purpose_class\n"
     ]
    }
   ],
   "source": [
    "additional_features = ['ttypes', 'diff_size', 'abs_last_yield_spread', 'abs_diff_size', 'days_duration']\n",
    "YS_COLS = ['max_ys_ys', 'max_ys_ttypes', 'max_ys_ago', 'max_ys_qdiff', 'min_ys_ys', 'min_ys_ttypes', 'min_ys_ago', 'min_ys_qdiff', 'max_qty_ys', 'max_qty_ttypes', \\\n",
    "           'max_qty_ago', 'max_qty_qdiff', 'min_ago_ys', 'min_ago_ttypes', 'min_ago_ago', 'min_ago_qdiff', 'D_min_ago_ys', 'D_min_ago_ttypes', 'D_min_ago_ago', 'D_min_ago_qdiff',\\\n",
    "           'P_min_ago_ys', 'P_min_ago_ttypes', 'P_min_ago_ago', 'P_min_ago_qdiff', 'S_min_ago_ys', 'S_min_ago_ttypes', 'S_min_ago_ago', 'S_min_ago_qdiff']\n",
    "encoders = {}\n",
    "fmax = {}\n",
    "for f in CATEGORICAL_FEATURES:\n",
    "    print(f)\n",
    "    if f in ['rating', 'incorporated_state_code', 'trade_type', 'purpose_class']:\n",
    "        fprep = preprocessing.LabelEncoder().fit(categorical_feature_values[f])\n",
    "    else:\n",
    "        fprep = preprocessing.LabelEncoder().fit(processed_data[f].drop_duplicates())\n",
    "    fmax[f] = np.max(fprep.transform(fprep.classes_))\n",
    "    encoders[f] = fprep\n",
    "    \n",
    "with open('encoders.pkl','wb') as file:\n",
    "    pickle.dump(encoders,file)\n",
    "    \n",
    "for col in YS_COLS:\n",
    "    if 'ttypes' in col and col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "    elif col not in PREDICTORS:\n",
    "        NON_CAT_FEATURES.append(col)\n",
    "        PREDICTORS.append(col)\n",
    "        \n",
    "if 'target_attention_features' not in PREDICTORS:\n",
    "    PREDICTORS.append('target_attention_features')\n",
    "    \n",
    "if 'ficc_treasury_spread' not in PREDICTORS:\n",
    "    PREDICTORS.append('ficc_treasury_spread')\n",
    "    NON_CAT_FEATURES.append('ficc_treasury_spread')\n",
    "    \n",
    "for col in ['new_ficc_ycl', 'new_real_time_ficc_ycl']:     \n",
    "    if col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        NON_CAT_FEATURES.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e9cb49-8e29-46da-baef-b009a27580d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.8 s, sys: 500 ms, total: 32.3 s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['yield_curve_history_5min_12_averaged_first_differenced'] = processed_data['yield_curve_history_5min_12_averaged']\\\n",
    ".apply(lambda x: -np.diff(x))\\\n",
    ".apply(lambda x: x[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31793fd1-37b0-4a2d-b187-e268b389fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.7 s, sys: 264 ms, total: 37 s\n",
      "Wall time: 37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['yield_curve_history_1min_20_averaged_first_differenced'] = processed_data['yield_curve_history_1min_20_averaged']\\\n",
    ".apply(lambda x: -np.diff(x))\\\n",
    ".apply(lambda x: x[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b92bf3e9-bd78-4aa1-a031-892a653b3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 530 ms, total: 11.6 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_shortened'] = processed_data['trade_history'].apply(lambda x: x[:TRADE_SEQUENCE_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0d6e5b-5e69-454e-9d53-348fc11ad2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 431 ms, total: 12.8 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_fixed'] = processed_data['trade_history_shortened'].apply(lambda x: x[::-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9daf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data start: 2023-01-03 00:00:00, end: 2023-02-28 00:00:00\n",
      "Test data start: 2023-03-01 00:00:00, end: 2023-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_filter = (processed_data.trade_date < train_end) & (processed_data.trade_date >= train_start)\n",
    "test_filter = (processed_data.trade_date >= test_start) & (processed_data.trade_date <test_end)\n",
    "                                                            \n",
    "train_dataframe = processed_data[train_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "test_dataframe = processed_data[test_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "print('Training data start: {}, end: {}'.format(train_dataframe.trade_date.min(),train_dataframe.trade_date.max()))\n",
    "print('Test data start: {}, end: {}'.format(test_dataframe.trade_date.min(),test_dataframe.trade_date.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f44b3bb4-26e1-43ad-a85b-937a3f912834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_new(df, trade_history_col, yield_history_cols):\n",
    "    global encoders\n",
    "    datalist = []\n",
    "    \n",
    "    for col in yield_history_cols:\n",
    "        datalist.append(np.stack(df[col].to_numpy()))\n",
    "        \n",
    "    datalist.append(np.stack(df[trade_history_col].to_numpy()))\n",
    "    datalist.append(np.stack(df['target_attention_features'].to_numpy()))\n",
    "\n",
    "    noncat_and_binary = []\n",
    "    for f in NON_CAT_FEATURES + BINARY:\n",
    "        noncat_and_binary.append(np.expand_dims(df[f].to_numpy().astype('float32'), axis=1))\n",
    "    datalist.append(np.concatenate(noncat_and_binary, axis=-1))\n",
    "    \n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        encoded = encoders[f].transform(df[f])\n",
    "        datalist.append(encoded.astype('float32'))\n",
    "    \n",
    "    return datalist\n",
    "\n",
    "def generate_model_new(TRADE_SEQUENCE_LENGTH, yield_history_cols, yield_history_lengths, num_yield_history,\n",
    "                      yield_history_normalizers, trade_history_normalizer, noncat_binary_normalizer):\n",
    "    inputs = []\n",
    "    layer = []\n",
    "\n",
    "    ############## INPUT BLOCK ###################\n",
    "    for i in range(num_yield_history):\n",
    "        inputs.append(layers.Input(name=f\"yield_history_input_{yield_history_cols[i]}\", \n",
    "                                           shape=(yield_history_lengths[i], 1), \n",
    "                                           dtype = tf.float32))\n",
    "    \n",
    "    trade_history_input = layers.Input(name=\"trade_history_input\", \n",
    "                                       shape=(TRADE_SEQUENCE_LENGTH, NUM_FEATURES), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    target_attention_input = layers.Input(name=\"target_attention_input\", \n",
    "                                       shape=(1, 3), \n",
    "                                       dtype = tf.float32) \n",
    "    inputs.append(trade_history_input)\n",
    "    inputs.append(target_attention_input)\n",
    "\n",
    "    inputs.append(layers.Input(\n",
    "        name=\"NON_CAT_AND_BINARY_FEATURES\",\n",
    "        shape=(len(NON_CAT_FEATURES + BINARY),)\n",
    "    ))\n",
    "\n",
    "\n",
    "    layer.append(noncat_binary_normalizer(inputs[num_yield_history+2]))\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    ############## TRADE HISTORY MODEL #################\n",
    "\n",
    "    lstm_layer = layers.Bidirectional(layers.LSTM(50, \n",
    "                             activation='tanh',\n",
    "                             input_shape=(TRADE_SEQUENCE_LENGTH,NUM_FEATURES),\n",
    "                             return_sequences = True,\n",
    "                             name='LSTM'))\n",
    "\n",
    "    lstm_layer_2 = layers.Bidirectional(layers.LSTM(100, \n",
    "                                                    activation='tanh',\n",
    "                                                    input_shape=(TRADE_SEQUENCE_LENGTH, 50),\n",
    "                                                    return_sequences = True,\n",
    "                                                    name='LSTM_2'))\n",
    "\n",
    "\n",
    "\n",
    "    features = lstm_layer(trade_history_normalizer(inputs[num_yield_history]))\n",
    "    features = lstm_layer_2(features)\n",
    "\n",
    "\n",
    "    attention_sequence = layers.Dense(200, activation='relu', name='attention_dense')(target_attention_input)\n",
    "    attention = layers.Dot(axes=[2, 2])([features, attention_sequence])\n",
    "    attention = layers.Activation('softmax')(attention)\n",
    "\n",
    "    context_vector = layers.Dot(axes=[1, 1])([features, attention])\n",
    "    context_vector = layers.Flatten(name='context_vector_flatten')(context_vector)\n",
    "\n",
    "\n",
    "    trade_history_output = layers.Dense(100, \n",
    "                                        activation='relu')(context_vector)\n",
    "\n",
    "    ####################################################\n",
    "    \n",
    "    ############## YIELD HISTORY MODEL #################\n",
    "    yield_history_outputs = []\n",
    "    for i in range(num_yield_history):\n",
    "        yield_lstm_layer = layers.Bidirectional(layers.LSTM(50, \n",
    "                                 activation='tanh',\n",
    "                                 input_shape=(YIELD_SEQUENCE_LENGTH, 1),\n",
    "                                 return_sequences = False,\n",
    "                                 name=f'Yield_History_LSTM_{yield_history_cols[i]}'))\n",
    "\n",
    "        yield_features = yield_lstm_layer(yield_history_normalizers[i](inputs[i]))\n",
    "        yield_history_outputs.append(layers.Dense(25, activation='relu')(yield_features))\n",
    " \n",
    "    ####################################################\n",
    "\n",
    "    ############## REFERENCE DATA MODEL ################\n",
    "    global encoders\n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        fin = layers.Input(shape=(1,), name = f)\n",
    "        inputs.append(fin)\n",
    "        embedded = layers.Flatten(name = f + \"_flat\")( layers.Embedding(input_dim = fmax[f]+1,\n",
    "                                                                        output_dim = max(30,int(np.sqrt(fmax[f]))),\n",
    "                                                                        input_length= 1,\n",
    "                                                                        name = f + \"_embed\")(fin))\n",
    "        layer.append(embedded)\n",
    "\n",
    "\n",
    "    reference_hidden = layers.Dense(400,\n",
    "                                    activation='relu',\n",
    "                                    name='reference_hidden_1')(layers.concatenate(layer, axis=-1))\n",
    "\n",
    "    reference_hidden = layers.BatchNormalization()(reference_hidden)\n",
    "    reference_hidden = layers.Dropout(DROPOUT)(reference_hidden)\n",
    "\n",
    "    reference_hidden2 = layers.Dense(200,activation='relu',name='reference_hidden_2')(reference_hidden)\n",
    "    reference_hidden2 = layers.BatchNormalization()(reference_hidden2)\n",
    "    reference_hidden2 = layers.Dropout(DROPOUT)(reference_hidden2)\n",
    "\n",
    "    reference_output = layers.Dense(100,activation='tanh',name='reference_hidden_3')(reference_hidden2)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    feed_forward_input = layers.concatenate(yield_history_outputs+[reference_output, trade_history_output])\n",
    "\n",
    "    hidden = layers.Dense(300,activation='relu')(feed_forward_input)\n",
    "    hidden = layers.BatchNormalization()(hidden)\n",
    "    hidden = layers.Dropout(DROPOUT)(hidden)\n",
    "\n",
    "    hidden2 = layers.Dense(100,activation='relu')(hidden)\n",
    "    hidden2 = layers.BatchNormalization()(hidden2)\n",
    "    hidden2 = layers.Dropout(DROPOUT)(hidden2)\n",
    "    final = layers.Dense(1)(hidden2)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=final)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_data_set_and_model(train_dataframe, test_dataframe, trade_history_col, yield_history_cols):\n",
    "    \n",
    "    if not isinstance(trade_history_col, str):\n",
    "        raise ValueError('trade_history_col must be a string')\n",
    "    \n",
    "    if isinstance(yield_history_cols, str):\n",
    "        num_yield_history = 1\n",
    "        yield_history_cols = [yield_history_cols]\n",
    "    else:\n",
    "        num_yield_history = len(yield_history_cols)\n",
    "    \n",
    "    yield_history_lengths = [train_dataframe[x][0].shape[0] for x in yield_history_cols]\n",
    "    \n",
    "    TRADE_SEQUENCE_LENGTH = train_dataframe[trade_history_col][0].shape[0] \n",
    "    \n",
    "    params = {'TRADE_SEQUENCE_LENGTH':TRADE_SEQUENCE_LENGTH, \n",
    "           'yield_history_cols':yield_history_cols, \n",
    "           'yield_history_lengths':yield_history_lengths, \n",
    "           'num_yield_history':num_yield_history }\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    val_idx = np.random.choice(range(len(train_dataframe)), \n",
    "                     size = int(VALIDATION_SPLIT*len(train_dataframe)),\n",
    "                     replace=False)\n",
    "\n",
    "    print(f'TRAINING DATA: N = {len(train_dataframe)-len(val_idx)}, MIN DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.min()}, MAX DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.max()}')\n",
    "    print(f'VALIDATION DATA: N = {len(val_idx)}, MIN DATE = {train_dataframe.iloc[val_idx].trade_date.min()}, MAX DATE = {train_dataframe.iloc[val_idx].trade_date.max()}')\n",
    "    print(f'TEST DATA: N = {len(test_dataframe)}, MIN DATE = {test_dataframe.trade_date.min()}, MAX DATE = {test_dataframe.trade_date.max()}')\n",
    "\n",
    "    x_train = create_input_new(train_dataframe.drop(val_idx, axis=0), trade_history_col, yield_history_cols)\n",
    "    y_train = train_dataframe.drop(val_idx, axis=0)[target_variable]\n",
    "\n",
    "    x_val = create_input_new(train_dataframe.iloc[val_idx], trade_history_col, yield_history_cols)\n",
    "    y_val = train_dataframe.iloc[val_idx][target_variable]\n",
    "\n",
    "    x_test = create_input_new(test_dataframe, trade_history_col, yield_history_cols)\n",
    "    y_test = test_dataframe[target_variable]    \n",
    "    \n",
    "    # Normalization layer for the yield history\n",
    "    yield_history_normalizers = []\n",
    "    for i in range(num_yield_history):\n",
    "        yield_history_normalizers.append(Normalization(name=f'Yield_history_normalizer_{yield_history_cols[i]}'))\n",
    "        yield_history_normalizers[i].adapt(x_train[i],batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Normalization layer for the trade history\n",
    "    trade_history_normalizer = Normalization(name='Trade_history_normalizer')\n",
    "    trade_history_normalizer.adapt(x_train[num_yield_history],batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Normalization layer for the non-categorical and binary features\n",
    "    noncat_binary_normalizer = Normalization(name='Numerical_binary_normalizer')\n",
    "    noncat_binary_normalizer.adapt(x_train[num_yield_history+2], batch_size = BATCH_SIZE)\n",
    "\n",
    "    normalizers = {'yield_history_normalizers': yield_history_normalizers,\n",
    "                  'trade_history_normalizer': trade_history_normalizer,\n",
    "                  'noncat_binary_normalizer': noncat_binary_normalizer}\n",
    "\n",
    "    return  params, normalizers, x_train, y_train, x_val, y_val, x_test, y_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16e33f76-449a-4655-882f-8b3fe873099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_data(x_train, y_train, shuffle=False, shuffle_buffer=1):\n",
    "                     \n",
    "    X=()\n",
    "    for x in x_train:\n",
    "        X += (tf.data.Dataset.from_tensor_slices(x),)\n",
    "        \n",
    "\n",
    "    temp = tf.data.Dataset.zip((X))\n",
    "    del X\n",
    "    dataset = tf.data.Dataset.zip((temp,\n",
    "                        tf.data.Dataset.from_tensor_slices(y_train)))\n",
    "    del temp\n",
    "    if shuffle:\n",
    "        shuffle_buffer = int(len(x_train[0])*shuffle_buffer)\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cb5cfc2-a1c5-40ff-b11d-f041113bf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1:1, 2:3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c7eea81-0c51-4ac7-bb58-4aef23343c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_new(params, normalizers, x_train, y_train, x_val, y_val, shuffle, shuffle_buffer=1):\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "    TRADE_SEQUENCE_LENGTH = params.get('TRADE_SEQUENCE_LENGTH')\n",
    "    yield_history_cols = params.get('yield_history_cols')\n",
    "    yield_history_lengths = params.get('yield_history_lengths')\n",
    "    num_yield_history = params.get('num_yield_history')\n",
    "      \n",
    "    yield_history_normalizers = normalizers.get('yield_history_normalizers')\n",
    "    trade_history_normalizer = normalizers.get('trade_history_normalizer')\n",
    "    noncat_binary_normalizer = normalizers.get('noncat_binary_normalizer')\n",
    "       \n",
    "    tf.keras.utils.set_random_seed(10)\n",
    "    model = generate_model_new(TRADE_SEQUENCE_LENGTH, yield_history_cols, yield_history_lengths, num_yield_history, \n",
    "                               yield_history_normalizers, trade_history_normalizer, noncat_binary_normalizer)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H-%M')\n",
    "    \n",
    "    fit_callbacks = fit_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True),\n",
    "        # time_callback,\n",
    "        CSVLoggerTimeHistory(timestamp+'_training_logs_yield_history.csv', separator=\",\", append=False)]\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        train_ds = create_tf_data(x_train, y_train, shuffle, shuffle_buffer)\n",
    "        train_ds = train_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "        val_ds = create_tf_data(x_val, y_val, shuffle = False)\n",
    "        val_ds = val_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "          loss=keras.losses.MeanAbsoluteError(),\n",
    "          metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history= model.fit(train_ds,\n",
    "                                      validation_data=val_ds,\n",
    "                                        epochs=NUM_EPOCHS,     \n",
    "                                        verbose=1, \n",
    "                                        callbacks=fit_callbacks,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        workers=8)\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e40d5dc8-31a6-4c39-a36c-8377f2afa2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_history_col = 'trade_history_fixed'\n",
    "yield_history_cols = ['yield_curve_history_5min_12_averaged_first_differenced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "404fc0cb-bb04-4d79-875b-ba91eb490e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA: N = 1070549, MIN DATE = 2023-01-03 00:00:00, MAX DATE = 2023-02-28 00:00:00\n",
      "VALIDATION DATA: N = 267637, MIN DATE = 2023-01-03 00:00:00, MAX DATE = 2023-02-28 00:00:00\n",
      "TEST DATA: N = 708432, MIN DATE = 2023-03-01 00:00:00, MAX DATE = 2023-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "params, normalizers, x_train, y_train, x_val, y_val, x_test, y_test, model = create_data_set_and_model(train_dataframe, test_dataframe, trade_history_col, yield_history_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ded485-96ec-43a2-a374-6b77bd936e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 21:11:54.398747: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254800896 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-17 21:12:05.530231: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 427770 of 535274\n",
      "2023-05-17 21:12:09.015440: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 53.7064 - mean_absolute_error: 53.7064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 21:12:47.599979: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254800896 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 67s 42ms/step - loss: 53.7064 - mean_absolute_error: 53.7064 - val_loss: 48.9358 - val_mean_absolute_error: 48.9358\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 48.2928 - mean_absolute_error: 48.2928 - val_loss: 44.5007 - val_mean_absolute_error: 44.5007\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 40.0662 - mean_absolute_error: 40.0662 - val_loss: 35.1123 - val_mean_absolute_error: 35.1123\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 29.0830 - mean_absolute_error: 29.0830 - val_loss: 21.6408 - val_mean_absolute_error: 21.6408\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 18.3768 - mean_absolute_error: 18.3768 - val_loss: 12.8622 - val_mean_absolute_error: 12.8622\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 12.6928 - mean_absolute_error: 12.6928 - val_loss: 10.4179 - val_mean_absolute_error: 10.4179\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 11.4142 - mean_absolute_error: 11.4142 - val_loss: 10.1162 - val_mean_absolute_error: 10.1162\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 11.1277 - mean_absolute_error: 11.1277 - val_loss: 9.9580 - val_mean_absolute_error: 9.9580\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 35s 33ms/step - loss: 10.9623 - mean_absolute_error: 10.9623 - val_loss: 9.8132 - val_mean_absolute_error: 9.8132\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 10.8496 - mean_absolute_error: 10.8496 - val_loss: 9.7841 - val_mean_absolute_error: 9.7841\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 35s 33ms/step - loss: 10.7387 - mean_absolute_error: 10.7387 - val_loss: 9.7862 - val_mean_absolute_error: 9.7862\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 10.6395 - mean_absolute_error: 10.6395 - val_loss: 9.5697 - val_mean_absolute_error: 9.5697\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 10.5594 - mean_absolute_error: 10.5594 - val_loss: 9.5163 - val_mean_absolute_error: 9.5163\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.4800 - mean_absolute_error: 10.4800 - val_loss: 9.5320 - val_mean_absolute_error: 9.5320\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 10.4190 - mean_absolute_error: 10.4190 - val_loss: 9.4364 - val_mean_absolute_error: 9.4364\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 10.3576 - mean_absolute_error: 10.3576 - val_loss: 9.3228 - val_mean_absolute_error: 9.3228\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 30s 29ms/step - loss: 10.3023 - mean_absolute_error: 10.3023 - val_loss: 9.4706 - val_mean_absolute_error: 9.4706\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 10.2540 - mean_absolute_error: 10.2540 - val_loss: 9.4051 - val_mean_absolute_error: 9.4051\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.2052 - mean_absolute_error: 10.2052 - val_loss: 9.3837 - val_mean_absolute_error: 9.3837\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 10.1530 - mean_absolute_error: 10.1530 - val_loss: 9.2284 - val_mean_absolute_error: 9.2284\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 22s 21ms/step - loss: 10.1145 - mean_absolute_error: 10.1145 - val_loss: 9.1793 - val_mean_absolute_error: 9.1793\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 27s 26ms/step - loss: 10.0815 - mean_absolute_error: 10.0815 - val_loss: 9.2134 - val_mean_absolute_error: 9.2134\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 10.0339 - mean_absolute_error: 10.0339 - val_loss: 9.0403 - val_mean_absolute_error: 9.0403\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 10.0043 - mean_absolute_error: 10.0043 - val_loss: 9.1717 - val_mean_absolute_error: 9.1717\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 27s 25ms/step - loss: 9.9702 - mean_absolute_error: 9.9702 - val_loss: 9.0450 - val_mean_absolute_error: 9.0450\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 9.9444 - mean_absolute_error: 9.9444 - val_loss: 9.0182 - val_mean_absolute_error: 9.0182\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.9152 - mean_absolute_error: 9.9152 - val_loss: 8.9575 - val_mean_absolute_error: 8.9575\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.8829 - mean_absolute_error: 9.8829 - val_loss: 9.0165 - val_mean_absolute_error: 9.0165\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.8555 - mean_absolute_error: 9.8555 - val_loss: 8.9699 - val_mean_absolute_error: 8.9699\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.8355 - mean_absolute_error: 9.8355 - val_loss: 9.0186 - val_mean_absolute_error: 9.0186\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.8109 - mean_absolute_error: 9.8109 - val_loss: 8.8950 - val_mean_absolute_error: 8.8950\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.7760 - mean_absolute_error: 9.7760 - val_loss: 8.8877 - val_mean_absolute_error: 8.8877\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.7721 - mean_absolute_error: 9.7721 - val_loss: 8.8843 - val_mean_absolute_error: 8.8843\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 35s 33ms/step - loss: 9.7304 - mean_absolute_error: 9.7304 - val_loss: 8.8687 - val_mean_absolute_error: 8.8687\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.7190 - mean_absolute_error: 9.7190 - val_loss: 8.9734 - val_mean_absolute_error: 8.9734\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 35s 33ms/step - loss: 9.6874 - mean_absolute_error: 9.6874 - val_loss: 8.8673 - val_mean_absolute_error: 8.8673\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.6752 - mean_absolute_error: 9.6752 - val_loss: 8.7785 - val_mean_absolute_error: 8.7785\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.6552 - mean_absolute_error: 9.6552 - val_loss: 8.8001 - val_mean_absolute_error: 8.8001\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.6299 - mean_absolute_error: 9.6299 - val_loss: 8.6868 - val_mean_absolute_error: 8.6868\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.6147 - mean_absolute_error: 9.6147 - val_loss: 8.7655 - val_mean_absolute_error: 8.7655\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.6017 - mean_absolute_error: 9.6017 - val_loss: 8.7857 - val_mean_absolute_error: 8.7857\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.5838 - mean_absolute_error: 9.5838 - val_loss: 8.7769 - val_mean_absolute_error: 8.7769\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.5613 - mean_absolute_error: 9.5613 - val_loss: 8.8668 - val_mean_absolute_error: 8.8668\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.5522 - mean_absolute_error: 9.5522 - val_loss: 8.7034 - val_mean_absolute_error: 8.7034\n",
      "Epoch 45/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.5359 - mean_absolute_error: 9.5359 - val_loss: 8.7518 - val_mean_absolute_error: 8.7518\n",
      "Epoch 46/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.5182 - mean_absolute_error: 9.5182 - val_loss: 8.6583 - val_mean_absolute_error: 8.6583\n",
      "Epoch 47/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.4987 - mean_absolute_error: 9.4987 - val_loss: 8.7324 - val_mean_absolute_error: 8.7324\n",
      "Epoch 48/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.4844 - mean_absolute_error: 9.4844 - val_loss: 8.6588 - val_mean_absolute_error: 8.6588\n",
      "Epoch 49/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.4740 - mean_absolute_error: 9.4740 - val_loss: 8.6683 - val_mean_absolute_error: 8.6683\n",
      "Epoch 50/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.4580 - mean_absolute_error: 9.4580 - val_loss: 8.6375 - val_mean_absolute_error: 8.6375\n",
      "Epoch 51/100\n",
      "1046/1046 [==============================] - 35s 33ms/step - loss: 9.4497 - mean_absolute_error: 9.4497 - val_loss: 8.6146 - val_mean_absolute_error: 8.6146\n",
      "Epoch 52/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.4245 - mean_absolute_error: 9.4245 - val_loss: 8.6663 - val_mean_absolute_error: 8.6663\n",
      "Epoch 53/100\n",
      "1046/1046 [==============================] - 35s 33ms/step - loss: 9.4159 - mean_absolute_error: 9.4159 - val_loss: 8.6241 - val_mean_absolute_error: 8.6241\n",
      "Epoch 54/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.4007 - mean_absolute_error: 9.4007 - val_loss: 8.6463 - val_mean_absolute_error: 8.6463\n",
      "Epoch 55/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.3854 - mean_absolute_error: 9.3854 - val_loss: 8.5755 - val_mean_absolute_error: 8.5755\n",
      "Epoch 56/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.3803 - mean_absolute_error: 9.3803 - val_loss: 8.7277 - val_mean_absolute_error: 8.7277\n",
      "Epoch 57/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.3667 - mean_absolute_error: 9.3667 - val_loss: 8.7355 - val_mean_absolute_error: 8.7355\n",
      "Epoch 58/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.3519 - mean_absolute_error: 9.3519 - val_loss: 8.6178 - val_mean_absolute_error: 8.6178\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.3479 - mean_absolute_error: 9.3479 - val_loss: 8.6521 - val_mean_absolute_error: 8.6521\n",
      "Epoch 60/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.3306 - mean_absolute_error: 9.3306 - val_loss: 8.5947 - val_mean_absolute_error: 8.5947\n",
      "Epoch 61/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.3184 - mean_absolute_error: 9.3184 - val_loss: 8.6798 - val_mean_absolute_error: 8.6798\n",
      "Epoch 62/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.2981 - mean_absolute_error: 9.2981 - val_loss: 8.5588 - val_mean_absolute_error: 8.5588\n",
      "Epoch 63/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.3045 - mean_absolute_error: 9.3045 - val_loss: 8.5371 - val_mean_absolute_error: 8.5371\n",
      "Epoch 64/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.2830 - mean_absolute_error: 9.2830 - val_loss: 8.5359 - val_mean_absolute_error: 8.5359\n",
      "Epoch 65/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.2751 - mean_absolute_error: 9.2751 - val_loss: 8.5480 - val_mean_absolute_error: 8.5480\n",
      "Epoch 66/100\n",
      "1046/1046 [==============================] - 30s 29ms/step - loss: 9.2683 - mean_absolute_error: 9.2683 - val_loss: 8.5329 - val_mean_absolute_error: 8.5329\n",
      "Epoch 67/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.2559 - mean_absolute_error: 9.2559 - val_loss: 8.5307 - val_mean_absolute_error: 8.5307\n",
      "Epoch 68/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.2447 - mean_absolute_error: 9.2447 - val_loss: 8.6056 - val_mean_absolute_error: 8.6056\n",
      "Epoch 69/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2387 - mean_absolute_error: 9.2387 - val_loss: 8.5816 - val_mean_absolute_error: 8.5816\n",
      "Epoch 70/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.2215 - mean_absolute_error: 9.2215 - val_loss: 8.5230 - val_mean_absolute_error: 8.5230\n",
      "Epoch 71/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2127 - mean_absolute_error: 9.2127 - val_loss: 8.4801 - val_mean_absolute_error: 8.4801\n",
      "Epoch 72/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.2083 - mean_absolute_error: 9.2083 - val_loss: 8.5616 - val_mean_absolute_error: 8.5616\n",
      "Epoch 73/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1943 - mean_absolute_error: 9.1943 - val_loss: 8.6141 - val_mean_absolute_error: 8.6141\n",
      "Epoch 74/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.1914 - mean_absolute_error: 9.1914 - val_loss: 8.4727 - val_mean_absolute_error: 8.4727\n",
      "Epoch 75/100\n",
      "1046/1046 [==============================] - 30s 29ms/step - loss: 9.1822 - mean_absolute_error: 9.1822 - val_loss: 8.4914 - val_mean_absolute_error: 8.4914\n",
      "Epoch 76/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.1767 - mean_absolute_error: 9.1767 - val_loss: 8.5202 - val_mean_absolute_error: 8.5202\n",
      "Epoch 77/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.1611 - mean_absolute_error: 9.1611 - val_loss: 8.4985 - val_mean_absolute_error: 8.4985\n",
      "Epoch 78/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1556 - mean_absolute_error: 9.1556 - val_loss: 8.5256 - val_mean_absolute_error: 8.5256\n",
      "Epoch 79/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.1479 - mean_absolute_error: 9.1479 - val_loss: 8.6292 - val_mean_absolute_error: 8.6292\n",
      "Epoch 80/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.1327 - mean_absolute_error: 9.1327 - val_loss: 8.4869 - val_mean_absolute_error: 8.4869\n",
      "Epoch 81/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.1327 - mean_absolute_error: 9.1327 - val_loss: 8.4119 - val_mean_absolute_error: 8.4119\n",
      "Epoch 82/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1162 - mean_absolute_error: 9.1162 - val_loss: 8.5280 - val_mean_absolute_error: 8.5280\n",
      "Epoch 83/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.1163 - mean_absolute_error: 9.1163 - val_loss: 8.5380 - val_mean_absolute_error: 8.5380\n",
      "Epoch 84/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.0981 - mean_absolute_error: 9.0981 - val_loss: 8.5191 - val_mean_absolute_error: 8.5191\n",
      "Epoch 85/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.0915 - mean_absolute_error: 9.0915 - val_loss: 8.5225 - val_mean_absolute_error: 8.5225\n",
      "Epoch 86/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0872 - mean_absolute_error: 9.0872 - val_loss: 8.4783 - val_mean_absolute_error: 8.4783\n",
      "Epoch 87/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.0782 - mean_absolute_error: 9.0782 - val_loss: 8.4219 - val_mean_absolute_error: 8.4219\n",
      "Epoch 88/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0764 - mean_absolute_error: 9.0764 - val_loss: 8.4315 - val_mean_absolute_error: 8.4315\n",
      "Epoch 89/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.0680 - mean_absolute_error: 9.0680 - val_loss: 8.4616 - val_mean_absolute_error: 8.4616\n",
      "Epoch 90/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.0604 - mean_absolute_error: 9.0604 - val_loss: 8.4719 - val_mean_absolute_error: 8.4719\n",
      "Epoch 91/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0520 - mean_absolute_error: 9.0520 - val_loss: 8.4010 - val_mean_absolute_error: 8.4010\n",
      "Epoch 92/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.0379 - mean_absolute_error: 9.0379 - val_loss: 8.4158 - val_mean_absolute_error: 8.4158\n",
      "Epoch 93/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0480 - mean_absolute_error: 9.0480 - val_loss: 8.4190 - val_mean_absolute_error: 8.4190\n",
      "Epoch 94/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.0284 - mean_absolute_error: 9.0284 - val_loss: 8.5241 - val_mean_absolute_error: 8.5241\n",
      "Epoch 95/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0249 - mean_absolute_error: 9.0249 - val_loss: 8.4882 - val_mean_absolute_error: 8.4882\n",
      "Epoch 96/100\n",
      "1046/1046 [==============================] - 30s 29ms/step - loss: 9.0111 - mean_absolute_error: 9.0111 - val_loss: 8.5245 - val_mean_absolute_error: 8.5245\n",
      "Epoch 97/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0125 - mean_absolute_error: 9.0125 - val_loss: 8.4527 - val_mean_absolute_error: 8.4527\n",
      "Epoch 98/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.0030 - mean_absolute_error: 9.0030 - val_loss: 8.4338 - val_mean_absolute_error: 8.4338\n",
      "Epoch 99/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0031 - mean_absolute_error: 9.0031 - val_loss: 8.4118 - val_mean_absolute_error: 8.4118\n",
      "Epoch 100/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 8.9918 - mean_absolute_error: 8.9918 - val_loss: 8.3646 - val_mean_absolute_error: 8.3646\n",
      "Model training time was 51.98 minutes (3119.07 seconds).\n",
      "Average time for each epoch was 0.52 minutes (31.19 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 22:04:19.201457: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254800896 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 0, MAE: 9.355159161147167 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 22:06:52.896267: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254800896 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-05-17 22:07:03.903117: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 497396 of 535274\n",
      "2023-05-17 22:07:05.296814: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 53.7063 - mean_absolute_error: 53.7063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 22:07:44.156700: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254800896 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 64s 41ms/step - loss: 53.7063 - mean_absolute_error: 53.7063 - val_loss: 48.9975 - val_mean_absolute_error: 48.9975\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 48.2928 - mean_absolute_error: 48.2928 - val_loss: 44.2145 - val_mean_absolute_error: 44.2145\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 40.0669 - mean_absolute_error: 40.0669 - val_loss: 34.8361 - val_mean_absolute_error: 34.8361\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 29.0839 - mean_absolute_error: 29.0839 - val_loss: 21.5018 - val_mean_absolute_error: 21.5018\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 18.3860 - mean_absolute_error: 18.3860 - val_loss: 13.2309 - val_mean_absolute_error: 13.2309\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 12.7054 - mean_absolute_error: 12.7054 - val_loss: 10.5459 - val_mean_absolute_error: 10.5459\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 11.4250 - mean_absolute_error: 11.4250 - val_loss: 10.2856 - val_mean_absolute_error: 10.2856\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 11.1366 - mean_absolute_error: 11.1366 - val_loss: 10.1184 - val_mean_absolute_error: 10.1184\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.9769 - mean_absolute_error: 10.9769 - val_loss: 9.8407 - val_mean_absolute_error: 9.8407\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.8606 - mean_absolute_error: 10.8606 - val_loss: 9.7615 - val_mean_absolute_error: 9.7615\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.7447 - mean_absolute_error: 10.7447 - val_loss: 9.8956 - val_mean_absolute_error: 9.8956\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 10.6457 - mean_absolute_error: 10.6457 - val_loss: 9.8072 - val_mean_absolute_error: 9.8072\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.5674 - mean_absolute_error: 10.5674 - val_loss: 9.4935 - val_mean_absolute_error: 9.4935\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.4892 - mean_absolute_error: 10.4892 - val_loss: 9.5872 - val_mean_absolute_error: 9.5872\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.4262 - mean_absolute_error: 10.4262 - val_loss: 9.3791 - val_mean_absolute_error: 9.3791\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 27s 26ms/step - loss: 10.3545 - mean_absolute_error: 10.3545 - val_loss: 9.4179 - val_mean_absolute_error: 9.4179\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 10.3012 - mean_absolute_error: 10.3012 - val_loss: 9.4421 - val_mean_absolute_error: 9.4421\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.2546 - mean_absolute_error: 10.2546 - val_loss: 9.2766 - val_mean_absolute_error: 9.2766\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.2034 - mean_absolute_error: 10.2034 - val_loss: 9.2950 - val_mean_absolute_error: 9.2950\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.1597 - mean_absolute_error: 10.1597 - val_loss: 9.1322 - val_mean_absolute_error: 9.1322\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 10.1104 - mean_absolute_error: 10.1104 - val_loss: 9.1639 - val_mean_absolute_error: 9.1639\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 10.0742 - mean_absolute_error: 10.0742 - val_loss: 9.1796 - val_mean_absolute_error: 9.1796\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 21s 21ms/step - loss: 10.0329 - mean_absolute_error: 10.0329 - val_loss: 9.0476 - val_mean_absolute_error: 9.0476\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 27s 26ms/step - loss: 9.9987 - mean_absolute_error: 9.9987 - val_loss: 9.1493 - val_mean_absolute_error: 9.1493\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.9640 - mean_absolute_error: 9.9640 - val_loss: 9.0825 - val_mean_absolute_error: 9.0825\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.9392 - mean_absolute_error: 9.9392 - val_loss: 8.9548 - val_mean_absolute_error: 8.9548\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.9099 - mean_absolute_error: 9.9099 - val_loss: 8.9517 - val_mean_absolute_error: 8.9517\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.8824 - mean_absolute_error: 9.8824 - val_loss: 9.0986 - val_mean_absolute_error: 9.0986\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.8525 - mean_absolute_error: 9.8525 - val_loss: 9.0665 - val_mean_absolute_error: 9.0665\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.8270 - mean_absolute_error: 9.8270 - val_loss: 9.0093 - val_mean_absolute_error: 9.0093\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.8073 - mean_absolute_error: 9.8073 - val_loss: 8.9311 - val_mean_absolute_error: 8.9311\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.7751 - mean_absolute_error: 9.7751 - val_loss: 8.9732 - val_mean_absolute_error: 8.9732\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.7676 - mean_absolute_error: 9.7676 - val_loss: 8.9152 - val_mean_absolute_error: 8.9152\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.7280 - mean_absolute_error: 9.7280 - val_loss: 8.8128 - val_mean_absolute_error: 8.8128\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.7159 - mean_absolute_error: 9.7159 - val_loss: 8.8685 - val_mean_absolute_error: 8.8685\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.6866 - mean_absolute_error: 9.6866 - val_loss: 8.8214 - val_mean_absolute_error: 8.8214\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.6723 - mean_absolute_error: 9.6723 - val_loss: 8.7815 - val_mean_absolute_error: 8.7815\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 9.6469 - mean_absolute_error: 9.6469 - val_loss: 8.8311 - val_mean_absolute_error: 8.8311\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.6310 - mean_absolute_error: 9.6310 - val_loss: 8.7527 - val_mean_absolute_error: 8.7527\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.6130 - mean_absolute_error: 9.6130 - val_loss: 8.6929 - val_mean_absolute_error: 8.6929\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 9.6005 - mean_absolute_error: 9.6005 - val_loss: 8.6992 - val_mean_absolute_error: 8.6992\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.5784 - mean_absolute_error: 9.5784 - val_loss: 8.7453 - val_mean_absolute_error: 8.7453\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 9.5631 - mean_absolute_error: 9.5631 - val_loss: 8.7545 - val_mean_absolute_error: 8.7545\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.5489 - mean_absolute_error: 9.5489 - val_loss: 8.6691 - val_mean_absolute_error: 8.6691\n",
      "Epoch 45/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.5304 - mean_absolute_error: 9.5304 - val_loss: 8.6798 - val_mean_absolute_error: 8.6798\n",
      "Epoch 46/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.5141 - mean_absolute_error: 9.5141 - val_loss: 8.6399 - val_mean_absolute_error: 8.6399\n",
      "Epoch 47/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.4945 - mean_absolute_error: 9.4945 - val_loss: 8.6522 - val_mean_absolute_error: 8.6522\n",
      "Epoch 48/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.4810 - mean_absolute_error: 9.4810 - val_loss: 8.6725 - val_mean_absolute_error: 8.6725\n",
      "Epoch 49/100\n",
      "1046/1046 [==============================] - 32s 30ms/step - loss: 9.4741 - mean_absolute_error: 9.4741 - val_loss: 8.6266 - val_mean_absolute_error: 8.6266\n",
      "Epoch 50/100\n",
      "1046/1046 [==============================] - 32s 31ms/step - loss: 9.4524 - mean_absolute_error: 9.4524 - val_loss: 8.6473 - val_mean_absolute_error: 8.6473\n",
      "Epoch 51/100\n",
      "1046/1046 [==============================] - 26s 24ms/step - loss: 9.4417 - mean_absolute_error: 9.4417 - val_loss: 8.6218 - val_mean_absolute_error: 8.6218\n",
      "Epoch 52/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 9.4233 - mean_absolute_error: 9.4233 - val_loss: 8.6325 - val_mean_absolute_error: 8.6325\n",
      "Epoch 53/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 9.4108 - mean_absolute_error: 9.4108 - val_loss: 8.5526 - val_mean_absolute_error: 8.5526\n",
      "Epoch 54/100\n",
      "1046/1046 [==============================] - 29s 27ms/step - loss: 9.3969 - mean_absolute_error: 9.3969 - val_loss: 8.5799 - val_mean_absolute_error: 8.5799\n",
      "Epoch 55/100\n",
      "1046/1046 [==============================] - 31s 30ms/step - loss: 9.3890 - mean_absolute_error: 9.3890 - val_loss: 8.5528 - val_mean_absolute_error: 8.5528\n",
      "Epoch 56/100\n",
      "1046/1046 [==============================] - 31s 30ms/step - loss: 9.3693 - mean_absolute_error: 9.3693 - val_loss: 8.5472 - val_mean_absolute_error: 8.5472\n",
      "Epoch 57/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.3696 - mean_absolute_error: 9.3696 - val_loss: 8.6394 - val_mean_absolute_error: 8.6394\n",
      "Epoch 58/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.3502 - mean_absolute_error: 9.3502 - val_loss: 8.5412 - val_mean_absolute_error: 8.5412\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.3435 - mean_absolute_error: 9.3435 - val_loss: 8.5177 - val_mean_absolute_error: 8.5177\n",
      "Epoch 60/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.3262 - mean_absolute_error: 9.3262 - val_loss: 8.5635 - val_mean_absolute_error: 8.5635\n",
      "Epoch 61/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.3160 - mean_absolute_error: 9.3160 - val_loss: 8.5449 - val_mean_absolute_error: 8.5449\n",
      "Epoch 62/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.2991 - mean_absolute_error: 9.2991 - val_loss: 8.5455 - val_mean_absolute_error: 8.5455\n",
      "Epoch 63/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2941 - mean_absolute_error: 9.2941 - val_loss: 8.5183 - val_mean_absolute_error: 8.5183\n",
      "Epoch 64/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.2909 - mean_absolute_error: 9.2909 - val_loss: 8.5665 - val_mean_absolute_error: 8.5665\n",
      "Epoch 65/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 9.2748 - mean_absolute_error: 9.2748 - val_loss: 8.5472 - val_mean_absolute_error: 8.5472\n",
      "Epoch 66/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.2592 - mean_absolute_error: 9.2592 - val_loss: 8.5136 - val_mean_absolute_error: 8.5136\n",
      "Epoch 67/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2559 - mean_absolute_error: 9.2559 - val_loss: 8.4643 - val_mean_absolute_error: 8.4643\n",
      "Epoch 68/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.2368 - mean_absolute_error: 9.2368 - val_loss: 8.4735 - val_mean_absolute_error: 8.4735\n",
      "Epoch 69/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2344 - mean_absolute_error: 9.2344 - val_loss: 8.4957 - val_mean_absolute_error: 8.4957\n",
      "Epoch 70/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.2237 - mean_absolute_error: 9.2237 - val_loss: 8.4641 - val_mean_absolute_error: 8.4641\n",
      "Epoch 71/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2118 - mean_absolute_error: 9.2118 - val_loss: 8.4088 - val_mean_absolute_error: 8.4088\n",
      "Epoch 72/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.2059 - mean_absolute_error: 9.2059 - val_loss: 8.5050 - val_mean_absolute_error: 8.5050\n",
      "Epoch 73/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1868 - mean_absolute_error: 9.1868 - val_loss: 8.4974 - val_mean_absolute_error: 8.4974\n",
      "Epoch 74/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.1878 - mean_absolute_error: 9.1878 - val_loss: 8.4653 - val_mean_absolute_error: 8.4653\n",
      "Epoch 75/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1756 - mean_absolute_error: 9.1756 - val_loss: 8.4570 - val_mean_absolute_error: 8.4570\n",
      "Epoch 76/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 9.1685 - mean_absolute_error: 9.1685 - val_loss: 8.4594 - val_mean_absolute_error: 8.4594\n",
      "Epoch 77/100\n",
      "1046/1046 [==============================] - 32s 31ms/step - loss: 9.1552 - mean_absolute_error: 9.1552 - val_loss: 8.4888 - val_mean_absolute_error: 8.4888\n",
      "Epoch 78/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.1455 - mean_absolute_error: 9.1455 - val_loss: 8.4301 - val_mean_absolute_error: 8.4301\n",
      "Epoch 79/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.1412 - mean_absolute_error: 9.1412 - val_loss: 8.4477 - val_mean_absolute_error: 8.4477\n",
      "Epoch 80/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1195 - mean_absolute_error: 9.1195 - val_loss: 8.4373 - val_mean_absolute_error: 8.4373\n",
      "Epoch 81/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.1185 - mean_absolute_error: 9.1185 - val_loss: 8.4074 - val_mean_absolute_error: 8.4074\n",
      "Epoch 82/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1093 - mean_absolute_error: 9.1093 - val_loss: 8.4276 - val_mean_absolute_error: 8.4276\n",
      "Epoch 83/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.1042 - mean_absolute_error: 9.1042 - val_loss: 8.4266 - val_mean_absolute_error: 8.4266\n",
      "Epoch 84/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 9.0954 - mean_absolute_error: 9.0954 - val_loss: 8.4259 - val_mean_absolute_error: 8.4259\n",
      "Epoch 85/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.0863 - mean_absolute_error: 9.0863 - val_loss: 8.4750 - val_mean_absolute_error: 8.4750\n",
      "Epoch 86/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 9.0816 - mean_absolute_error: 9.0816 - val_loss: 8.4409 - val_mean_absolute_error: 8.4409\n",
      "Epoch 87/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.0696 - mean_absolute_error: 9.0696 - val_loss: 8.4146 - val_mean_absolute_error: 8.4146\n",
      "Epoch 88/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0683 - mean_absolute_error: 9.0683 - val_loss: 8.4010 - val_mean_absolute_error: 8.4010\n",
      "Epoch 89/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.0586 - mean_absolute_error: 9.0586 - val_loss: 8.3929 - val_mean_absolute_error: 8.3929\n",
      "Epoch 90/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.0499 - mean_absolute_error: 9.0499 - val_loss: 8.3948 - val_mean_absolute_error: 8.3948\n",
      "Epoch 91/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.0473 - mean_absolute_error: 9.0473 - val_loss: 8.3612 - val_mean_absolute_error: 8.3612\n",
      "Epoch 92/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 9.0380 - mean_absolute_error: 9.0380 - val_loss: 8.3949 - val_mean_absolute_error: 8.3949\n",
      "Epoch 93/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 9.0380 - mean_absolute_error: 9.0380 - val_loss: 8.4085 - val_mean_absolute_error: 8.4085\n",
      "Epoch 94/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 9.0232 - mean_absolute_error: 9.0232 - val_loss: 8.3626 - val_mean_absolute_error: 8.3626\n",
      "Epoch 95/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.0230 - mean_absolute_error: 9.0230 - val_loss: 8.3984 - val_mean_absolute_error: 8.3984\n",
      "Epoch 96/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 9.0090 - mean_absolute_error: 9.0090 - val_loss: 8.4028 - val_mean_absolute_error: 8.4028\n",
      "Epoch 97/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.0039 - mean_absolute_error: 9.0039 - val_loss: 8.3509 - val_mean_absolute_error: 8.3509\n",
      "Epoch 98/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 8.9960 - mean_absolute_error: 8.9960 - val_loss: 8.5075 - val_mean_absolute_error: 8.5075\n",
      "Epoch 99/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 8.9921 - mean_absolute_error: 8.9921 - val_loss: 8.3418 - val_mean_absolute_error: 8.3418\n",
      "Epoch 100/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 8.9861 - mean_absolute_error: 8.9861 - val_loss: 8.3652 - val_mean_absolute_error: 8.3652\n",
      "Model training time was 50.60 minutes (3035.98 seconds).\n",
      "Average time for each epoch was 0.51 minutes (30.36 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 22:57:54.690743: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254800896 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 1, MAE: 9.334133239468683 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 23:00:33.361313: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254800896 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - ETA: 0s - loss: 53.7062 - mean_absolute_error: 53.7062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 23:01:24.616418: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14254800896 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046/1046 [==============================] - 64s 44ms/step - loss: 53.7062 - mean_absolute_error: 53.7062 - val_loss: 48.9828 - val_mean_absolute_error: 48.9828\n",
      "Epoch 2/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 48.2923 - mean_absolute_error: 48.2923 - val_loss: 44.3741 - val_mean_absolute_error: 44.3741\n",
      "Epoch 3/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 40.0659 - mean_absolute_error: 40.0659 - val_loss: 35.0953 - val_mean_absolute_error: 35.0953\n",
      "Epoch 4/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 29.0865 - mean_absolute_error: 29.0865 - val_loss: 20.8163 - val_mean_absolute_error: 20.8163\n",
      "Epoch 5/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 18.3913 - mean_absolute_error: 18.3913 - val_loss: 13.6177 - val_mean_absolute_error: 13.6177\n",
      "Epoch 6/100\n",
      "1046/1046 [==============================] - 28s 26ms/step - loss: 12.7044 - mean_absolute_error: 12.7044 - val_loss: 10.4787 - val_mean_absolute_error: 10.4787\n",
      "Epoch 7/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 11.4231 - mean_absolute_error: 11.4231 - val_loss: 10.1596 - val_mean_absolute_error: 10.1596\n",
      "Epoch 8/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 11.1348 - mean_absolute_error: 11.1348 - val_loss: 9.9769 - val_mean_absolute_error: 9.9769\n",
      "Epoch 9/100\n",
      "1046/1046 [==============================] - 31s 29ms/step - loss: 10.9729 - mean_absolute_error: 10.9729 - val_loss: 10.0654 - val_mean_absolute_error: 10.0654\n",
      "Epoch 10/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.8548 - mean_absolute_error: 10.8548 - val_loss: 9.9264 - val_mean_absolute_error: 9.9264\n",
      "Epoch 11/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.7403 - mean_absolute_error: 10.7403 - val_loss: 9.7322 - val_mean_absolute_error: 9.7322\n",
      "Epoch 12/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 10.6417 - mean_absolute_error: 10.6417 - val_loss: 9.5695 - val_mean_absolute_error: 9.5695\n",
      "Epoch 13/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.5608 - mean_absolute_error: 10.5608 - val_loss: 9.5173 - val_mean_absolute_error: 9.5173\n",
      "Epoch 14/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.4814 - mean_absolute_error: 10.4814 - val_loss: 9.5519 - val_mean_absolute_error: 9.5519\n",
      "Epoch 15/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.4239 - mean_absolute_error: 10.4239 - val_loss: 9.5201 - val_mean_absolute_error: 9.5201\n",
      "Epoch 16/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.3564 - mean_absolute_error: 10.3564 - val_loss: 9.3381 - val_mean_absolute_error: 9.3381\n",
      "Epoch 17/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.3012 - mean_absolute_error: 10.3012 - val_loss: 9.5909 - val_mean_absolute_error: 9.5909\n",
      "Epoch 18/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 10.2543 - mean_absolute_error: 10.2543 - val_loss: 9.3479 - val_mean_absolute_error: 9.3479\n",
      "Epoch 19/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.2085 - mean_absolute_error: 10.2085 - val_loss: 9.3419 - val_mean_absolute_error: 9.3419\n",
      "Epoch 20/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.1661 - mean_absolute_error: 10.1661 - val_loss: 9.2224 - val_mean_absolute_error: 9.2224\n",
      "Epoch 21/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.1168 - mean_absolute_error: 10.1168 - val_loss: 9.3417 - val_mean_absolute_error: 9.3417\n",
      "Epoch 22/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 10.0842 - mean_absolute_error: 10.0842 - val_loss: 9.1386 - val_mean_absolute_error: 9.1386\n",
      "Epoch 23/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 10.0428 - mean_absolute_error: 10.0428 - val_loss: 9.0974 - val_mean_absolute_error: 9.0974\n",
      "Epoch 24/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 10.0086 - mean_absolute_error: 10.0086 - val_loss: 9.2290 - val_mean_absolute_error: 9.2290\n",
      "Epoch 25/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.9767 - mean_absolute_error: 9.9767 - val_loss: 9.0098 - val_mean_absolute_error: 9.0098\n",
      "Epoch 26/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.9573 - mean_absolute_error: 9.9573 - val_loss: 9.0805 - val_mean_absolute_error: 9.0805\n",
      "Epoch 27/100\n",
      "1046/1046 [==============================] - 27s 26ms/step - loss: 9.9206 - mean_absolute_error: 9.9206 - val_loss: 9.1292 - val_mean_absolute_error: 9.1292\n",
      "Epoch 28/100\n",
      "1046/1046 [==============================] - 27s 26ms/step - loss: 9.8930 - mean_absolute_error: 9.8930 - val_loss: 8.9134 - val_mean_absolute_error: 8.9134\n",
      "Epoch 29/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.8664 - mean_absolute_error: 9.8664 - val_loss: 9.0067 - val_mean_absolute_error: 9.0067\n",
      "Epoch 30/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.8398 - mean_absolute_error: 9.8398 - val_loss: 9.0337 - val_mean_absolute_error: 9.0337\n",
      "Epoch 31/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.8127 - mean_absolute_error: 9.8127 - val_loss: 8.9247 - val_mean_absolute_error: 8.9247\n",
      "Epoch 32/100\n",
      "1046/1046 [==============================] - 21s 20ms/step - loss: 9.7837 - mean_absolute_error: 9.7837 - val_loss: 8.8555 - val_mean_absolute_error: 8.8555\n",
      "Epoch 33/100\n",
      "1046/1046 [==============================] - 26s 25ms/step - loss: 9.7790 - mean_absolute_error: 9.7790 - val_loss: 8.9380 - val_mean_absolute_error: 8.9380\n",
      "Epoch 34/100\n",
      "1046/1046 [==============================] - 19s 18ms/step - loss: 9.7374 - mean_absolute_error: 9.7374 - val_loss: 8.8632 - val_mean_absolute_error: 8.8632\n",
      "Epoch 35/100\n",
      "1046/1046 [==============================] - 24s 23ms/step - loss: 9.7275 - mean_absolute_error: 9.7275 - val_loss: 8.8531 - val_mean_absolute_error: 8.8531\n",
      "Epoch 36/100\n",
      "1046/1046 [==============================] - 30s 28ms/step - loss: 9.6937 - mean_absolute_error: 9.6937 - val_loss: 8.7554 - val_mean_absolute_error: 8.7554\n",
      "Epoch 37/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.6820 - mean_absolute_error: 9.6820 - val_loss: 8.7608 - val_mean_absolute_error: 8.7608\n",
      "Epoch 38/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.6574 - mean_absolute_error: 9.6574 - val_loss: 8.7914 - val_mean_absolute_error: 8.7914\n",
      "Epoch 39/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.6393 - mean_absolute_error: 9.6393 - val_loss: 8.7316 - val_mean_absolute_error: 8.7316\n",
      "Epoch 40/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.6152 - mean_absolute_error: 9.6152 - val_loss: 8.7640 - val_mean_absolute_error: 8.7640\n",
      "Epoch 41/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.6051 - mean_absolute_error: 9.6051 - val_loss: 8.7159 - val_mean_absolute_error: 8.7159\n",
      "Epoch 42/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.5807 - mean_absolute_error: 9.5807 - val_loss: 8.7226 - val_mean_absolute_error: 8.7226\n",
      "Epoch 43/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.5728 - mean_absolute_error: 9.5728 - val_loss: 8.8062 - val_mean_absolute_error: 8.8062\n",
      "Epoch 44/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.5580 - mean_absolute_error: 9.5580 - val_loss: 8.6718 - val_mean_absolute_error: 8.6718\n",
      "Epoch 45/100\n",
      "1046/1046 [==============================] - 32s 30ms/step - loss: 9.5408 - mean_absolute_error: 9.5408 - val_loss: 8.7490 - val_mean_absolute_error: 8.7490\n",
      "Epoch 46/100\n",
      "1046/1046 [==============================] - 29s 28ms/step - loss: 9.5248 - mean_absolute_error: 9.5248 - val_loss: 8.6408 - val_mean_absolute_error: 8.6408\n",
      "Epoch 47/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 9.5087 - mean_absolute_error: 9.5087 - val_loss: 8.6538 - val_mean_absolute_error: 8.6538\n",
      "Epoch 48/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.4887 - mean_absolute_error: 9.4887 - val_loss: 8.6853 - val_mean_absolute_error: 8.6853\n",
      "Epoch 49/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.4768 - mean_absolute_error: 9.4768 - val_loss: 8.6456 - val_mean_absolute_error: 8.6456\n",
      "Epoch 50/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.4581 - mean_absolute_error: 9.4581 - val_loss: 8.6660 - val_mean_absolute_error: 8.6660\n",
      "Epoch 51/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.4520 - mean_absolute_error: 9.4520 - val_loss: 8.5844 - val_mean_absolute_error: 8.5844\n",
      "Epoch 52/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.4376 - mean_absolute_error: 9.4376 - val_loss: 8.6349 - val_mean_absolute_error: 8.6349\n",
      "Epoch 53/100\n",
      "1046/1046 [==============================] - 34s 33ms/step - loss: 9.4258 - mean_absolute_error: 9.4258 - val_loss: 8.6568 - val_mean_absolute_error: 8.6568\n",
      "Epoch 54/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.4095 - mean_absolute_error: 9.4095 - val_loss: 8.7096 - val_mean_absolute_error: 8.7096\n",
      "Epoch 55/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.3938 - mean_absolute_error: 9.3938 - val_loss: 8.5602 - val_mean_absolute_error: 8.5602\n",
      "Epoch 56/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.3776 - mean_absolute_error: 9.3776 - val_loss: 8.6163 - val_mean_absolute_error: 8.6163\n",
      "Epoch 57/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.3723 - mean_absolute_error: 9.3723 - val_loss: 8.5670 - val_mean_absolute_error: 8.5670\n",
      "Epoch 58/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.3556 - mean_absolute_error: 9.3556 - val_loss: 8.5702 - val_mean_absolute_error: 8.5702\n",
      "Epoch 59/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.3535 - mean_absolute_error: 9.3535 - val_loss: 8.5921 - val_mean_absolute_error: 8.5921\n",
      "Epoch 60/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.3307 - mean_absolute_error: 9.3307 - val_loss: 8.5252 - val_mean_absolute_error: 8.5252\n",
      "Epoch 61/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.3231 - mean_absolute_error: 9.3231 - val_loss: 8.5610 - val_mean_absolute_error: 8.5610\n",
      "Epoch 62/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.3079 - mean_absolute_error: 9.3079 - val_loss: 8.5542 - val_mean_absolute_error: 8.5542\n",
      "Epoch 63/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.3021 - mean_absolute_error: 9.3021 - val_loss: 8.4720 - val_mean_absolute_error: 8.4720\n",
      "Epoch 64/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2838 - mean_absolute_error: 9.2838 - val_loss: 8.5170 - val_mean_absolute_error: 8.5170\n",
      "Epoch 65/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.2756 - mean_absolute_error: 9.2756 - val_loss: 8.6010 - val_mean_absolute_error: 8.6010\n",
      "Epoch 66/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2715 - mean_absolute_error: 9.2715 - val_loss: 8.5302 - val_mean_absolute_error: 8.5302\n",
      "Epoch 67/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.2551 - mean_absolute_error: 9.2551 - val_loss: 8.5996 - val_mean_absolute_error: 8.5996\n",
      "Epoch 68/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2469 - mean_absolute_error: 9.2469 - val_loss: 8.4705 - val_mean_absolute_error: 8.4705\n",
      "Epoch 69/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.2417 - mean_absolute_error: 9.2417 - val_loss: 8.5000 - val_mean_absolute_error: 8.5000\n",
      "Epoch 70/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2215 - mean_absolute_error: 9.2215 - val_loss: 8.4841 - val_mean_absolute_error: 8.4841\n",
      "Epoch 71/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.2188 - mean_absolute_error: 9.2188 - val_loss: 8.5277 - val_mean_absolute_error: 8.5277\n",
      "Epoch 72/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.2097 - mean_absolute_error: 9.2097 - val_loss: 8.5452 - val_mean_absolute_error: 8.5452\n",
      "Epoch 73/100\n",
      "1046/1046 [==============================] - 33s 31ms/step - loss: 9.1989 - mean_absolute_error: 9.1989 - val_loss: 8.5389 - val_mean_absolute_error: 8.5389\n",
      "Epoch 74/100\n",
      "1046/1046 [==============================] - 32s 30ms/step - loss: 9.1827 - mean_absolute_error: 9.1827 - val_loss: 8.5269 - val_mean_absolute_error: 8.5269\n",
      "Epoch 75/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1765 - mean_absolute_error: 9.1765 - val_loss: 8.4399 - val_mean_absolute_error: 8.4399\n",
      "Epoch 76/100\n",
      "1046/1046 [==============================] - 34s 32ms/step - loss: 9.1664 - mean_absolute_error: 9.1664 - val_loss: 8.4665 - val_mean_absolute_error: 8.4665\n",
      "Epoch 77/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1579 - mean_absolute_error: 9.1579 - val_loss: 8.4294 - val_mean_absolute_error: 8.4294\n",
      "Epoch 78/100\n",
      "1046/1046 [==============================] - 33s 32ms/step - loss: 9.1504 - mean_absolute_error: 9.1504 - val_loss: 8.4644 - val_mean_absolute_error: 8.4644\n",
      "Epoch 79/100\n",
      "1046/1046 [==============================] - 28s 27ms/step - loss: 9.1438 - mean_absolute_error: 9.1438 - val_loss: 8.4754 - val_mean_absolute_error: 8.4754\n",
      "Epoch 80/100\n",
      " 143/1046 [===>..........................] - ETA: 22s - loss: 9.5207 - mean_absolute_error: 9.5207"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(4):\n",
    "    history, model = train_model_new(params, normalizers, x_train, y_train, x_val, y_val, True, shuffle_buffer = 0.5)\n",
    "    pred = model.predict(x_test)\n",
    "    predictions.append(pred)\n",
    "    print('='*25+f' TRIAL {i}, MAE: {mean_absolute_error(pred,y_test)} '+'='*25)\n",
    "    results.append([history, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4ff15239-8f1e-4f6d-b431-f369b3e26348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.355159161147167\n",
      "9.334133239468683\n",
      "9.372519303479649\n",
      "9.307194837975006\n"
     ]
    }
   ],
   "source": [
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'{mean_absolute_error(prediction, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135478fa-7ea7-4b10-8b24-cab25b887839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
