{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5cb26db-f0f8-42fd-9303-5ff5e3b52096",
   "metadata": {},
   "source": [
    "Last Updated 19/7/2023\n",
    "\n",
    "This notebook is part of a broader investigation into how we can use ratings more effectively in the neural network. This includes: \n",
    "- incorporating Moody's ratings in some way \n",
    "- incorporating rating downgrades effectively, whether explicit or implicit (such as when a bond is prerefunded)\n",
    "\n",
    "The following notebook is an investigation into the effectiveness of ratings in the neural network. **Jump to the section *Pricing Hypothetical Trades* for the analysis**.  \n",
    "\n",
    "Initial analysis showed that the current model (tested using the model in deployment right now) is not as sensitive to exogenous ratings changes as expected (a downgrade from 'AAA' to Junk yielded a change in predictions ranging between 1-40bps). A look into the embeddings from the production model, however, showed that the embeddings did preserve the semantics of different ratings (ratings close together have similar vectors). \n",
    "\n",
    "My suspicion from this is that the model is not learning to use ratings appropriately downstream, since vector embeddings appear sensible but predictions do not. Before moving forward with using Moody's ratings, I looked into trying to help the network get more out of ratings.\n",
    "\n",
    "**Intuition (if there is a more concrete way of testing this please let me know)**: The current network concatenates the multi-dimensional output from the LSTM sub-model and reference data sub-model and feeds that output through a series of dense layers to output a predicted yield spread. Because the outputs of each of the sub-models is multi-dimensional, we can think of them more as encodings of trade_history and reference data. My intuition is that this combination of encodings -> several dense layers downstream creates multiple interactions between the trade history and the reference data inputs and, since using the previous yield is very often the single best predictor of current yield, this muddles the model's ability to learn from reference data.\n",
    "\n",
    "**TLDR:** The idea implemented here is simple: separate the trade history and reference sub-models more clearly. Each sub-model outputs a single scalar value which is combined in the final layer, which aligns the sub-models more closely with the idea of each of them predicting a yield spread and combining those predictions for a final predicted yield spread. Over 8 runs and in the data used in this notebook, MAE improves on average by ~0.4bps. Moreover, this new model is more sensitive to changes in ratings (and presumably, other reference data features, which I'll test some other time). This is ascertained in the same way that the original model was deemed to be insufficiently sensitive - we alter ratings for real trades and see how predictions change under the altered ratings, all else equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54acdc5b-7dc8-4578-a0bd-02740ba377a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load Packages, Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58de4fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 17:55:14.991069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 17:55:15.241574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 17:55:15.243347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pandarallel with 16.0 cores\n",
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "TF Version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import gcsfs\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "from ficc.utils.nelson_siegel_model import *\n",
    "from ficc.utils.diff_in_days import *\n",
    "from ficc.utils.auxiliary_functions import sqltodf\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, NON_CAT_FEATURES, BINARY, CATEGORICAL_FEATURES, IDENTIFIERS, PURPOSE_CLASS_DICT, NUM_OF_DAYS_IN_YEAR\n",
    "from ficc.utils.gcp_storage_functions import upload_data, download_data\n",
    "from ficc.utils.auxiliary_variables import RELATED_TRADE_BINARY_FEATURES, RELATED_TRADE_NON_CAT_FEATURES, RELATED_TRADE_CATEGORICAL_FEATURES\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from ficc_keras_utils import *\n",
    "import ficc_keras_utils\n",
    "from lgbm_tools import *\n",
    "from ficc_debiasing import *\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(f'TF Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c11246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/ficc/isaac_creds.json\"\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()\n",
    "\n",
    "##COMMON VARIABLES\n",
    "#DATA WINDOW\n",
    "train_start = '2023-05-01'\n",
    "train_end = '2023-06-01'\n",
    "test_start = '2023-06-01'\n",
    "test_end = '2023-07-01'\n",
    "#MODEL PARAMETERS \n",
    "VALIDATION_SPLIT = ficc_keras_utils.VALIDATION_SPLIT\n",
    "LEARNING_RATE = ficc_keras_utils.LEARNING_RATE\n",
    "BATCH_SIZE = 1000 #ficc_keras_utils.BATCH_SIZE\n",
    "NUM_EPOCHS = 75 #ficc_keras_utils.NUM_EPOCHS\n",
    "DROPOUT = 0.01 #ficc_keras_utils.DROPOUT\n",
    "\n",
    "##NOTEBOOK SPECIFIC VARIABLES \n",
    "TRADE_SEQUENCE_LENGTH = 2\n",
    "NUM_FEATURES = 6\n",
    "# target_variable = 'new_ys_diff'\n",
    "# target_variable = 'new_ys' \n",
    "target_variable = 'new_ys' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca18089-58e8-4a2e-9c50-11898bfde236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-01 2023-06-01 2023-06-01 2023-07-01\n"
     ]
    }
   ],
   "source": [
    "print(train_start ,\n",
    "train_end ,\n",
    "test_start ,\n",
    "test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f52d4-5834-401a-a2ac-46559494098f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load Data and Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "29fc421e-1f46-4eac-ae37-d944b2071c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processed_file_FULL_2023-07-12-17:22.pkl uploaded to isaac_data.\n"
     ]
    }
   ],
   "source": [
    "# upload_data(storage_client, 'isaac_data', 'processed_file_FULL_2023-07-12-17:22.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "877a208b-c665-48ad-a8da-316b29c256b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File available, loading pickle\n",
      "CPU times: user 11.6 s, sys: 4.14 s, total: 15.8 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "%time processed_data = load_data_from_pickle('processed_file_FULL_2023-07-12-17:22.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e934f6f-e216-4871-aea7-598e8c16140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data[~(processed_data.trade_history.apply(lambda x: x.shape) == (5,6))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ab6562f-cb41-4dcf-91a5-17d7373d4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['trade_history'] = processed_data.trade_history.apply(lambda x: x[:,[0,2,3,4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a792e5f4-76fa-48db-8746-63e50f1603c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['target_attention_features'] = processed_data['target_attention_features'].apply(lambda x: x[[0],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91f2d6b6-4d22-474c-9482-1c0a333e930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data['target_attention_features'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c184fe-3bff-410b-9bfe-44392274d494",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e94dfab-86e9-4cc1-91eb-c017cee0d551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2023-05-01 00:00:00'), Timestamp('2023-07-11 00:00:00'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.trade_date.min(), processed_data.trade_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be6e3073-3be5-4b5c-a7fa-c0f42f623aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yield</th>\n",
       "      <th>new_real_time_ficc_ycl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1746702.000</td>\n",
       "      <td>1746702.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>364.498</td>\n",
       "      <td>323.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>91.917</td>\n",
       "      <td>41.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100</td>\n",
       "      <td>263.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>307.000</td>\n",
       "      <td>297.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>350.300</td>\n",
       "      <td>310.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>411.000</td>\n",
       "      <td>336.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9892.500</td>\n",
       "      <td>541.456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            yield  new_real_time_ficc_ycl\n",
       "count 1746702.000             1746702.000\n",
       "mean      364.498                 323.013\n",
       "std        91.917                  41.183\n",
       "min         0.100                 263.663\n",
       "25%       307.000                 297.164\n",
       "50%       350.300                 310.806\n",
       "75%       411.000                 336.136\n",
       "max      9892.500                 541.456"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[['yield','new_real_time_ficc_ycl']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a60e40-35a7-4769-9fd2-399bb2f0cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f5c8ed7-c8f9-433b-92db-2868d3c716f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data['new_ys_realtime'] = processed_data['yield'] - processed_data['new_real_time_ficc_ycl']\n",
    "processed_data['new_ys'] = processed_data['yield'] - processed_data['new_ficc_ycl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a46c03ad-d7d5-4492-bba2-4cf4aef63c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### EXTRA DATA PREPROCESSING #####\n",
    "ttype_dict = { (0,0):'D', (0,1):'S', (1,0):'P' }\n",
    "\n",
    "ys_variants = [\"max_ys\", \"min_ys\", \"max_qty\", \"min_ago\", \"D_min_ago\", \"P_min_ago\", \"S_min_ago\"]\n",
    "ys_feats = [\"_ys\", \"_ttypes\", \"_ago\", \"_qdiff\"]\n",
    "D_prev = dict()\n",
    "P_prev = dict()\n",
    "S_prev = dict()\n",
    "\n",
    "def get_trade_history_columns():\n",
    "    '''\n",
    "    This function is used to create a list of columns\n",
    "    '''\n",
    "    YS_COLS = []\n",
    "    for prefix in ys_variants:\n",
    "        for suffix in ys_feats:\n",
    "            YS_COLS.append(prefix + suffix)\n",
    "    return YS_COLS\n",
    "\n",
    "def extract_feature_from_trade(row, name, trade):\n",
    "    yield_spread = trade[0]\n",
    "    ttypes = ttype_dict[(trade[3],trade[4])] + row.trade_type\n",
    "    seconds_ago = trade[5]\n",
    "    quantity_diff = np.log10(1 + np.abs(10**trade[2] - 10**row.quantity))\n",
    "    return [yield_spread, ttypes,  seconds_ago, quantity_diff]\n",
    "\n",
    "def trade_history_derived_features(row):\n",
    "    trade_history = row.trade_history\n",
    "    trade = trade_history[0]\n",
    "    \n",
    "    D_min_ago_t = D_prev.get(row.cusip,trade)\n",
    "    D_min_ago = 9        \n",
    "\n",
    "    P_min_ago_t = P_prev.get(row.cusip,trade)\n",
    "    P_min_ago = 9\n",
    "    \n",
    "    S_min_ago_t = S_prev.get(row.cusip,trade)\n",
    "    S_min_ago = 9\n",
    "    \n",
    "    max_ys_t = trade; max_ys = trade[0]\n",
    "    min_ys_t = trade; min_ys = trade[0]\n",
    "    max_qty_t = trade; max_qty = trade[2]\n",
    "    min_ago_t = trade; min_ago = trade[5]\n",
    "    \n",
    "    for trade in trade_history[0:]:\n",
    "        #Checking if the first trade in the history is from the same block\n",
    "        if trade[5] == 0: \n",
    "            continue\n",
    " \n",
    "        if trade[0] > max_ys: \n",
    "            max_ys_t = trade\n",
    "            max_ys = trade[0]\n",
    "        elif trade[0] < min_ys: \n",
    "            min_ys_t = trade; \n",
    "            min_ys = trade[0]\n",
    "\n",
    "        if trade[2] > max_qty: \n",
    "            max_qty_t = trade \n",
    "            max_qty = trade[2]\n",
    "        if trade[5] < min_ago: \n",
    "            min_ago_t = trade; \n",
    "            min_ago = trade[5]\n",
    "            \n",
    "        side = ttype_dict[(trade[3],trade[4])]\n",
    "        if side == \"D\":\n",
    "            if trade[5] < D_min_ago: \n",
    "                D_min_ago_t = trade; D_min_ago = trade[5]\n",
    "                D_prev[row.cusip] = trade\n",
    "        elif side == \"P\":\n",
    "            if trade[5] < P_min_ago: \n",
    "                P_min_ago_t = trade; P_min_ago = trade[5]\n",
    "                P_prev[row.cusip] = trade\n",
    "        elif side == \"S\":\n",
    "            if trade[5] < S_min_ago: \n",
    "                S_min_ago_t = trade; S_min_ago = trade[5]\n",
    "                S_prev[row.cusip] = trade\n",
    "        else: \n",
    "            print(\"invalid side\", trade)\n",
    "    \n",
    "    trade_history_dict = {\"max_ys\":max_ys_t,\n",
    "                          \"min_ys\":min_ys_t,\n",
    "                          \"max_qty\":max_qty_t,\n",
    "                          \"min_ago\":min_ago_t,\n",
    "                          \"D_min_ago\":D_min_ago_t,\n",
    "                          \"P_min_ago\":P_min_ago_t,\n",
    "                          \"S_min_ago\":S_min_ago_t}\n",
    "\n",
    "    return_list = []\n",
    "    for variant in ys_variants:\n",
    "        feature_list = extract_feature_from_trade(row,variant,trade_history_dict[variant])\n",
    "        return_list += feature_list\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "def process_data(data): \n",
    "    data['ted-rate'] = (data['t_rate_10'] - data['t_rate_2']) * 100\n",
    "    \n",
    "    data = data[(data.days_to_call == 0) | (data.days_to_call > np.log10(400))]\n",
    "    data = data[(data.days_to_refund == 0) | (data.days_to_refund > np.log10(400))]\n",
    "    data = data[(data.days_to_maturity == 0) | (data.days_to_maturity > np.log10(400))]\n",
    "    data = data[data.days_to_maturity < np.log10(30000)]\n",
    "    data['trade_history_sum'] = data.trade_history.parallel_apply(lambda x: np.sum(x))\n",
    "    data.issue_amount = data.issue_amount.replace([np.inf, -np.inf], np.nan)\n",
    "    data.dropna(inplace=True, subset=PREDICTORS+['trade_history_sum'])\n",
    "    data.purpose_sub_class.fillna(0, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "964a86ed-8535-4195-8ff8-88f9da5e8999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.8 s, sys: 5.51 s, total: 40.3 s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temp = processed_data[['cusip','trade_history','quantity','trade_type']].parallel_apply(trade_history_derived_features, axis=1)\n",
    "YS_COLS = get_trade_history_columns()\n",
    "processed_data[YS_COLS] = pd.DataFrame(temp.tolist(), index=processed_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06f9fae8-c191-49ac-af98-2f6b720b663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 832 ms, sys: 19 ms, total: 851 ms\n",
      "Wall time: 868 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_data['ttypes'] = (processed_data.last_trade_type.astype(str) + processed_data.trade_type.astype(str)).astype('category')\n",
    "processed_data['diff_size'] = (processed_data.par_traded.astype(float) - processed_data.last_size).astype(np.float32)\n",
    "processed_data['abs_last_yield_spread'] = np.abs(processed_data['last_yield_spread'])\n",
    "processed_data['abs_diff_size'] = np.abs(processed_data['diff_size'])\n",
    "processed_data['days_duration'] = (processed_data.last_calc_date - processed_data.last_settlement_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddf12468-0634-4ac8-8085-17777a34d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 3.99 s, total: 22.1 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_data['trade_history_sum'] = processed_data.trade_history.parallel_apply(lambda x: np.sum(x))\n",
    "processed_data = processed_data.dropna(subset=['trade_history_sum'])\n",
    "processed_data.purpose_sub_class.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e294b38-2ba3-49ec-930e-8f8d3a5a0187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in NON_CAT_FEATURES:\n",
    "#     print(col + ':' + str(train_dataframe[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26e3d97e-c3b0-4511-b6de-79717352924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['new_ficc_ycl', 'yield_spread']:\n",
    "    if col in NON_CAT_FEATURES:\n",
    "        NON_CAT_FEATURES.remove(col)\n",
    "    if col in PREDICTORS:\n",
    "        PREDICTORS.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "302404ee-098f-4e8f-9bd3-cfc57fc96974",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = process_data(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc47f4e4-9a1a-4ffa-932c-5413827d0731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "incorporated_state_code\n",
      "trade_type\n",
      "purpose_class\n",
      "max_ys_ttypes\n",
      "min_ys_ttypes\n",
      "max_qty_ttypes\n",
      "min_ago_ttypes\n",
      "D_min_ago_ttypes\n",
      "P_min_ago_ttypes\n",
      "S_min_ago_ttypes\n"
     ]
    }
   ],
   "source": [
    "additional_features = ['ttypes', 'diff_size', 'abs_last_yield_spread', 'abs_diff_size', 'days_duration']\n",
    "YS_COLS = ['max_ys_ys', 'max_ys_ttypes', 'max_ys_ago', 'max_ys_qdiff', 'min_ys_ys', 'min_ys_ttypes', 'min_ys_ago', 'min_ys_qdiff', 'max_qty_ys', 'max_qty_ttypes', \\\n",
    "           'max_qty_ago', 'max_qty_qdiff', 'min_ago_ys', 'min_ago_ttypes', 'min_ago_ago', 'min_ago_qdiff', 'D_min_ago_ys', 'D_min_ago_ttypes', 'D_min_ago_ago', 'D_min_ago_qdiff',\\\n",
    "           'P_min_ago_ys', 'P_min_ago_ttypes', 'P_min_ago_ago', 'P_min_ago_qdiff', 'S_min_ago_ys', 'S_min_ago_ttypes', 'S_min_ago_ago', 'S_min_ago_qdiff']\n",
    "    \n",
    "for col in YS_COLS:\n",
    "    if 'ttypes' in col and col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        CATEGORICAL_FEATURES.append(col)\n",
    "    elif col not in PREDICTORS:\n",
    "        NON_CAT_FEATURES.append(col)\n",
    "        PREDICTORS.append(col)\n",
    "        \n",
    "if 'target_attention_features' not in PREDICTORS:\n",
    "    PREDICTORS.append('target_attention_features')\n",
    "    \n",
    "if 'ficc_treasury_spread' not in PREDICTORS:\n",
    "    PREDICTORS.append('ficc_treasury_spread')\n",
    "    NON_CAT_FEATURES.append('ficc_treasury_spread')\n",
    "    \n",
    "# for col in ['new_ficc_ycl', 'new_real_time_ficc_ycl']:     \n",
    "#     if col not in PREDICTORS:\n",
    "#         PREDICTORS.append(col)\n",
    "#         NON_CAT_FEATURES.append(col)\n",
    "        \n",
    "encoders = {}\n",
    "fmax = {}\n",
    "for f in CATEGORICAL_FEATURES:\n",
    "    print(f)\n",
    "    if f in ['rating', 'incorporated_state_code', 'trade_type', 'purpose_class']:\n",
    "        fprep = preprocessing.LabelEncoder().fit(categorical_feature_values[f])\n",
    "    else:\n",
    "        fprep = preprocessing.LabelEncoder().fit(processed_data[f].drop_duplicates())\n",
    "    fmax[f] = np.max(fprep.transform(fprep.classes_))\n",
    "    encoders[f] = fprep\n",
    "    \n",
    "with open('encoders.pkl','wb') as file:\n",
    "    pickle.dump(encoders,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b92bf3e9-bd78-4aa1-a031-892a653b3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 790 ms, sys: 51.5 ms, total: 842 ms\n",
      "Wall time: 840 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_shortened'] = processed_data['trade_history'].apply(lambda x: x[:TRADE_SEQUENCE_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb0d6e5b-5e69-454e-9d53-348fc11ad2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 762 ms, sys: 91.7 ms, total: 853 ms\n",
      "Wall time: 853 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_fixed'] = processed_data['trade_history_shortened'].apply(lambda x: x[::-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "408ba4ae-31be-4b37-be1b-a6c143637c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2023-05-01 00:00:00'), Timestamp('2023-07-11 00:00:00'), 1590785)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.trade_date.min(), processed_data.trade_date.max(), len(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9daf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data start: 2023-05-01 00:00:00, end: 2023-05-31 00:00:00\n",
      "Test data start: 2023-06-01 00:00:00, end: 2023-06-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_filter = (processed_data.trade_date < train_end) & (processed_data.trade_date >= train_start)\n",
    "test_filter = (processed_data.trade_date >= test_start) & (processed_data.trade_date <test_end)\n",
    "                                                            \n",
    "train_dataframe = processed_data[train_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "test_dataframe = processed_data[test_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "print('Training data start: {}, end: {}'.format(train_dataframe.trade_date.min(),train_dataframe.trade_date.max()))\n",
    "print('Test data start: {}, end: {}'.format(test_dataframe.trade_date.min(),test_dataframe.trade_date.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00361ac5-8d00-45be-a40e-9bd8fdbf09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-01 00:00:00 2023-05-31 00:00:00 705233\n",
      "2023-06-01 00:00:00 2023-06-30 00:00:00 697202\n"
     ]
    }
   ],
   "source": [
    "print(train_dataframe.trade_date.min(), train_dataframe.trade_date.max(), len(train_dataframe))\n",
    "print(test_dataframe.trade_date.min(), test_dataframe.trade_date.max(), len(test_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f44b3bb4-26e1-43ad-a85b-937a3f912834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_new(df, trade_history_col, yield_history_cols):\n",
    "    global encoders\n",
    "    datalist = []\n",
    "    \n",
    "    for col in yield_history_cols:\n",
    "        datalist.append(np.stack(df[col].to_numpy()))\n",
    "        \n",
    "    datalist.append(np.stack(df[trade_history_col].to_numpy()))\n",
    "    datalist.append(np.stack(df['target_attention_features'].to_numpy()))\n",
    "\n",
    "    noncat_and_binary = []\n",
    "    for f in NON_CAT_FEATURES + BINARY:\n",
    "        noncat_and_binary.append(np.expand_dims(df[f].to_numpy().astype('float32'), axis=1))\n",
    "    datalist.append(np.concatenate(noncat_and_binary, axis=-1))\n",
    "    \n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        encoded = encoders[f].transform(df[f])\n",
    "        datalist.append(encoded.astype('float32'))\n",
    "    \n",
    "    return datalist\n",
    "\n",
    "def generate_model_new(TRADE_SEQUENCE_LENGTH, yield_history_cols, yield_history_lengths, num_yield_history,\n",
    "                      yield_history_normalizers, trade_history_normalizer, noncat_binary_normalizer):\n",
    "    inputs = []\n",
    "    layer = []\n",
    "\n",
    "    ############## INPUT BLOCK ###################\n",
    "    # for i in range(num_yield_history):\n",
    "    #     inputs.append(layers.Input(name=f\"yield_history_input_{yield_history_cols[i]}\", \n",
    "    #                                        shape=(yield_history_lengths[i], 1), \n",
    "    #                                        dtype = tf.float32))\n",
    "    \n",
    "    trade_history_input = layers.Input(name=\"trade_history_input\", \n",
    "                                       shape=(TRADE_SEQUENCE_LENGTH, NUM_FEATURES), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    target_attention_input = layers.Input(name=\"target_attention_input\", \n",
    "                                       shape=(1, 3), \n",
    "                                       dtype = tf.float32) \n",
    "    inputs.append(trade_history_input)\n",
    "    inputs.append(target_attention_input)\n",
    "\n",
    "    inputs.append(layers.Input(\n",
    "        name=\"NON_CAT_AND_BINARY_FEATURES\",\n",
    "        shape=(len(NON_CAT_FEATURES + BINARY),)\n",
    "    ))\n",
    "\n",
    "\n",
    "    layer.append(noncat_binary_normalizer(inputs[num_yield_history+2]))\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    ############## TRADE HISTORY MODEL #################\n",
    "\n",
    "    lstm_layer = layers.Bidirectional(layers.LSTM(50, \n",
    "                             activation='tanh',\n",
    "                             input_shape=(TRADE_SEQUENCE_LENGTH,NUM_FEATURES),\n",
    "                             return_sequences = True,\n",
    "                             name='LSTM'))\n",
    "\n",
    "    lstm_layer_2 = layers.Bidirectional(layers.LSTM(100, \n",
    "                                                    activation='tanh',\n",
    "                                                    input_shape=(TRADE_SEQUENCE_LENGTH, 50),\n",
    "                                                    return_sequences = True,\n",
    "                                                    name='LSTM_2'))\n",
    "\n",
    "\n",
    "\n",
    "    features = lstm_layer(trade_history_normalizer(inputs[num_yield_history]))\n",
    "    features = lstm_layer_2(features)  \n",
    "    \n",
    "    \n",
    "    attention_sequence = layers.Dense(200, activation='relu', name='attention_dense')(target_attention_input)\n",
    "    attention = layers.Dot(axes=[2, 2])([features, attention_sequence])\n",
    "    attention = layers.Activation('softmax')(attention)\n",
    "\n",
    "    context_vector = layers.Dot(axes=[1, 1])([features, attention])\n",
    "    context_vector = layers.Flatten(name='context_vector_flatten')(context_vector)\n",
    "\n",
    "\n",
    "    trade_history_output = layers.Dense(100, \n",
    "                                        activation='relu')(context_vector)\n",
    "    \n",
    "    trade_history_output = layers.Dense(1)(trade_history_output)\n",
    "\n",
    "    ####################################################\n",
    "    \n",
    "#     ############## YIELD HISTORY MODEL #################\n",
    "#     yield_history_outputs = []\n",
    "#     for i in range(num_yield_history):\n",
    "#         yield_lstm_layer = layers.Bidirectional(layers.LSTM(50, \n",
    "#                                  activation='tanh',\n",
    "#                                  input_shape=(yield_history_lengths[i], 1),\n",
    "#                                  return_sequences = False,\n",
    "#                                  name=f'Yield_History_LSTM_{yield_history_cols[i]}'))\n",
    "\n",
    "#         yield_features = yield_lstm_layer(yield_history_normalizers[i](inputs[i]))\n",
    "#         yield_history_outputs.append(layers.Dense(25, activation='relu')(yield_features))\n",
    " \n",
    "    ####################################################\n",
    "\n",
    "    ############## REFERENCE DATA MODEL ################\n",
    "    global encoders\n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        fin = layers.Input(shape=(1,), name = f)\n",
    "        inputs.append(fin)\n",
    "        embedded = layers.Flatten(name = f + \"_flat\")( layers.Embedding(input_dim = fmax[f]+1,\n",
    "                                                                        output_dim = max(30,int(np.sqrt(fmax[f]))),\n",
    "                                                                        input_length= 1,\n",
    "                                                                        name = f + \"_embed\")(fin))\n",
    "        layer.append(embedded)\n",
    "\n",
    "\n",
    "    reference_hidden = layers.Dense(300,\n",
    "                                    activation='relu',\n",
    "                                    name='reference_hidden_1')(layers.concatenate(layer, axis=-1))\n",
    "    reference_hidden = layers.BatchNormalization()(reference_hidden)\n",
    "    reference_hidden = layers.Dropout(DROPOUT)(reference_hidden)\n",
    "\n",
    "    reference_hidden2 = layers.Dense(200,activation='relu',name='reference_hidden_2')(reference_hidden)\n",
    "    reference_hidden2 = layers.BatchNormalization()(reference_hidden2)\n",
    "    reference_hidden2 = layers.Dropout(DROPOUT)(reference_hidden2)\n",
    "\n",
    "    reference_hidden3 = layers.Dense(100,activation='tanh',name='reference_hidden_3')(reference_hidden2)\n",
    "    reference_hidden3 = layers.BatchNormalization()(reference_hidden3)\n",
    "    reference_hidden3 = layers.Dropout(DROPOUT)(reference_hidden3)\n",
    "    \n",
    "    reference_output = layers.Dense(1, name='reference_hidden_3')(reference_hidden2)\n",
    "    ####################################################\n",
    "\n",
    "    feed_forward_input = layers.concatenate(yield_history_outputs+[reference_output, trade_history_output])\n",
    "\n",
    "    # hidden = layers.Dense(10,activation='relu')(feed_forward_input)\n",
    "    # hidden = layers.BatchNormalization()(hidden)\n",
    "    # hidden = layers.Dropout(DROPOUT)(hidden)\n",
    "\n",
    "#     hidden2 = layers.Dense(100,activation='relu')(hidden)\n",
    "#     hidden2 = layers.BatchNormalization()(hidden2)\n",
    "#     hidden2 = layers.Dropout(DROPOUT)(hidden2)\n",
    "    # final = layers.Dense(1)(hidden2)\n",
    "    \n",
    "    final = layers.Dense(1)(feed_forward_input)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=final)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_data_set_and_model(train_dataframe, test_dataframe, trade_history_col, yield_history_cols):\n",
    "    \n",
    "    if not isinstance(trade_history_col, str):\n",
    "        raise ValueError('trade_history_col must be a string')\n",
    "    \n",
    "    if isinstance(yield_history_cols, str):\n",
    "        num_yield_history = 1\n",
    "        yield_history_cols = [yield_history_cols]\n",
    "    else:\n",
    "        num_yield_history = len(yield_history_cols)\n",
    "    \n",
    "    yield_history_lengths = [train_dataframe[x][0].shape[0] for x in yield_history_cols]\n",
    "    \n",
    "    TRADE_SEQUENCE_LENGTH = train_dataframe[trade_history_col][0].shape[0] \n",
    "    \n",
    "    params = {'TRADE_SEQUENCE_LENGTH':TRADE_SEQUENCE_LENGTH, \n",
    "           'yield_history_cols':yield_history_cols, \n",
    "           'yield_history_lengths':yield_history_lengths, \n",
    "           'num_yield_history':num_yield_history }\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    val_idx = np.random.choice(range(len(train_dataframe)), \n",
    "                     size = int(VALIDATION_SPLIT*len(train_dataframe)),\n",
    "                     replace=False)\n",
    "\n",
    "    print(f'TRAINING DATA: N = {len(train_dataframe)-len(val_idx)}, MIN DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.min()}, MAX DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.max()}')\n",
    "    print(f'VALIDATION DATA: N = {len(val_idx)}, MIN DATE = {train_dataframe.iloc[val_idx].trade_date.min()}, MAX DATE = {train_dataframe.iloc[val_idx].trade_date.max()}')\n",
    "    print(f'TEST DATA: N = {len(test_dataframe)}, MIN DATE = {test_dataframe.trade_date.min()}, MAX DATE = {test_dataframe.trade_date.max()}')\n",
    "\n",
    "    x_train = create_input_new(train_dataframe.drop(val_idx, axis=0), trade_history_col, yield_history_cols)\n",
    "    y_train = train_dataframe.drop(val_idx, axis=0)[target_variable]\n",
    "\n",
    "    x_val = create_input_new(train_dataframe.iloc[val_idx], trade_history_col, yield_history_cols)\n",
    "    y_val = train_dataframe.iloc[val_idx][target_variable]\n",
    "\n",
    "    x_test = create_input_new(test_dataframe, trade_history_col, yield_history_cols)\n",
    "    y_test = test_dataframe[target_variable]    \n",
    "    \n",
    "    # Normalization layer for the yield history\n",
    "    yield_history_normalizers = []\n",
    "    for i in range(num_yield_history):\n",
    "        yield_history_normalizers.append(Normalization(name=f'Yield_history_normalizer_{yield_history_cols[i]}'))\n",
    "        yield_history_normalizers[i].adapt(x_train[i],batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Normalization layer for the trade history\n",
    "    trade_history_normalizer = Normalization(name='Trade_history_normalizer')\n",
    "    trade_history_normalizer.adapt(x_train[num_yield_history],batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Normalization layer for the non-categorical and binary features\n",
    "    noncat_binary_normalizer = Normalization(name='Numerical_binary_normalizer')\n",
    "    noncat_binary_normalizer.adapt(x_train[num_yield_history+2], batch_size = BATCH_SIZE)\n",
    "\n",
    "    normalizers = {'yield_history_normalizers': yield_history_normalizers,\n",
    "                  'trade_history_normalizer': trade_history_normalizer,\n",
    "                  'noncat_binary_normalizer': noncat_binary_normalizer}\n",
    "\n",
    "    return  params, normalizers, x_train, y_train, x_val, y_val, x_test, y_test, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16e33f76-449a-4655-882f-8b3fe873099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_data(x_train, y_train, shuffle=False, shuffle_buffer=1):\n",
    "                     \n",
    "    X=()\n",
    "    for x in x_train:\n",
    "        X += (tf.data.Dataset.from_tensor_slices(x),)\n",
    "        \n",
    "\n",
    "    temp = tf.data.Dataset.zip((X))\n",
    "    del X\n",
    "    dataset = tf.data.Dataset.zip((temp,\n",
    "                        tf.data.Dataset.from_tensor_slices(y_train)))\n",
    "    del temp\n",
    "    if shuffle:\n",
    "        shuffle_buffer = int(len(x_train[0])*shuffle_buffer)\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c7eea81-0c51-4ac7-bb58-4aef23343c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_new(params, normalizers, x_train, y_train, x_val, y_val, shuffle, shuffle_buffer=1):\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    TRADE_SEQUENCE_LENGTH = params.get('TRADE_SEQUENCE_LENGTH')\n",
    "    yield_history_cols = params.get('yield_history_cols')\n",
    "    yield_history_lengths = params.get('yield_history_lengths')\n",
    "    num_yield_history = params.get('num_yield_history')\n",
    "      \n",
    "    yield_history_normalizers = normalizers.get('yield_history_normalizers')\n",
    "    trade_history_normalizer = normalizers.get('trade_history_normalizer')\n",
    "    noncat_binary_normalizer = normalizers.get('noncat_binary_normalizer')\n",
    "       \n",
    "    tf.keras.utils.set_random_seed(10)\n",
    "    model = generate_model_new(TRADE_SEQUENCE_LENGTH, yield_history_cols, yield_history_lengths, num_yield_history, \n",
    "                               yield_history_normalizers, trade_history_normalizer, noncat_binary_normalizer)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H-%M')\n",
    "    \n",
    "    fit_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True),\n",
    "        # time_callback,\n",
    "        CSVLoggerTimeHistory(timestamp+'_training_logs_yield_history.csv', separator=\",\", append=False)]\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        train_ds = create_tf_data(x_train, y_train, shuffle, shuffle_buffer)\n",
    "        train_ds = train_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "        val_ds = create_tf_data(x_val, y_val, shuffle = False)\n",
    "        val_ds = val_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "          loss=keras.losses.MeanAbsoluteError())\n",
    "\n",
    "    history= model.fit(train_ds,\n",
    "                                      validation_data=val_ds,\n",
    "                                        epochs=NUM_EPOCHS,     \n",
    "                                        verbose=1, \n",
    "                                        callbacks=fit_callbacks,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        workers=8)\n",
    "    \n",
    "    return history, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9af4c49-d1ec-4499-b03f-ca71444133d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['new_ficc_ycl', 'new_real_time_ficc_ycl']:     \n",
    "    if col in PREDICTORS:\n",
    "        PREDICTORS.remove(col)\n",
    "    if col in NON_CAT_FEATURES:\n",
    "        NON_CAT_FEATURES.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e40d5dc8-31a6-4c39-a36c-8377f2afa2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_history_col = 'trade_history_shortened'\n",
    "yield_history_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "404fc0cb-bb04-4d79-875b-ba91eb490e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA: N = 634710, MIN DATE = 2023-05-01 00:00:00, MAX DATE = 2023-05-31 00:00:00\n",
      "VALIDATION DATA: N = 70523, MIN DATE = 2023-05-01 00:00:00, MAX DATE = 2023-05-31 00:00:00\n",
      "TEST DATA: N = 235624, MIN DATE = 2023-06-01 00:00:00, MAX DATE = 2023-06-09 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 18:05:58.788269: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-19 18:05:58.792029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 18:05:58.795655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 18:05:58.798224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 18:06:08.946559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 18:06:08.948716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 18:06:08.950604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-19 18:06:08.982744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13594 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# params, normalizers, x_train, y_train, x_val, y_val, x_test, y_test, val_idx = create_data_set_and_model(train_dataframe, test_dataframe, trade_history_col, yield_history_cols)\n",
    "params, normalizers, x_train, y_train, x_val, y_val, x_test, y_test, val_idx = create_data_set_and_model(train_dataframe, test_dataframe[test_dataframe.trade_date<='2023-06-09'], trade_history_col, yield_history_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9623aff-b815-4a2b-94f7-6f2e8189dc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "(634710, 2, 6)\n",
      "(634710, 1, 3)\n",
      "(634710, 48)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n",
      "(634710,)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "for i in range(len(x_train)):\n",
    "    print(x_train[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f70c95-ac98-4efa-8dc6-d0b04d3b3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "predictions = []\n",
    "NUM_EPOCHS = 75\n",
    "\n",
    "for i in range(1):\n",
    "    tf.keras.utils.set_random_seed(10)\n",
    "    start = time.time()\n",
    "    history, model = train_model_new(params, normalizers, x_train, y_train, x_val, y_val, True, shuffle_buffer = .75)\n",
    "    pred = model.predict(x_test)\n",
    "    predictions.append(pred)\n",
    "    print('='*25+f' TRIAL {i}, MAE: {mean_absolute_error(pred,y_test)} '+'='*25)\n",
    "    results.append([history, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "94ded485-96ec-43a2-a374-6b77bd936e55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= TRIAL 0, MAE: 9.408028809369103, TIME TAKEN: 23.9 =========================\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "predictions = []\n",
    "NUM_EPOCHS = 75\n",
    "\n",
    "for i in range(1):\n",
    "    tf.keras.utils.set_random_seed(10)\n",
    "    start = time.time()\n",
    "    history, model = train_model_new(params, normalizers, x_train, y_train, x_val, y_val, True, shuffle_buffer = .75)\n",
    "    pred = model.predict(x_test)\n",
    "    predictions.append(pred)\n",
    "    print('='*25+f' TRIAL {i}, MAE: {mean_absolute_error(pred,y_test)} '+'='*25)\n",
    "    results.append([history, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "989574c5-7140-4d33-9489-3011f43feb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: 9.398\n",
      "Trial 2: 9.444\n",
      "Trial 3: 9.424\n",
      "Trial 4: 9.441\n",
      "Trial 5: 9.454\n",
      "Trial 6: 9.441\n",
      "Trial 7: 9.409\n",
      "Trial 8: 9.456\n",
      "Average MAE: 9.433\n"
     ]
    }
   ],
   "source": [
    "#SECOND RUN ON 07/15; 75 EPOCHS\n",
    "#NOTE: initial run erroneously included  the \n",
    "t = 0\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'Trial {i+1}: {mean_absolute_error(prediction, y_test):.3f}')\n",
    "    t += mean_absolute_error(prediction, y_test)\n",
    "print(f'Average MAE: {t/len(predictions):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e75445-6dc9-4801-9fa8-d61c4d8025dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pricing Hypothetical Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be408f9-455b-4f48-9539-933ee2b9bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_sampled_data = pd.read_pickle('synthetic_sampled_data_new.pkl')\n",
    "# baseline_data = pd.read_pickle('synthetic_sampled_data_baseline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2e72775-97c1-4783-a03b-c3024a2df763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days(row, col):\n",
    "    if pd.isna(row[col]) or pd.isna(row['settlement_date']):\n",
    "        return 0\n",
    "    else: \n",
    "        diff = diff_in_days_two_dates(row[col], row.settlement_date)\n",
    "        if diff <= 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return diff\n",
    "        \n",
    "def sample_dataframe(df, N):\n",
    "    '''Takes a dataframe from pd.groupby and samples N rows from it without replacement. The group name (in this case, the groupby index) is saved\n",
    "    to a dictionary, groupby_id_dict'''\n",
    "    \n",
    "    group_name = df.name\n",
    "    def index_to_dict(index_row):\n",
    "        is_callable = index_row[0]\n",
    "        interval = str(index_row[1].left)+'-'+str(index_row[1].right)\n",
    "        rating = index_row[2]\n",
    "        return {'is_callable':is_callable, 'interval': interval, 'rating':rating}\n",
    "    \n",
    "    df = df.drop_duplicates(subset='cusip')\n",
    "    \n",
    "    if len(df) < N:\n",
    "        N = len(df)\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    result = df.sample(N, replace=False) \n",
    "    group_id = next(COUNT)\n",
    "    result['group'] = group_id\n",
    "    groupby_id_dict[group_id] = index_to_dict(group_name)\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_synthetic_samples(df, col, vals):\n",
    "    '''For a given cusip, the first trade is sampled and hypothetical trades are appended with by varying the column defined in col with values in vals'''\n",
    "    for cusip in df.cusip.unique():\n",
    "        for val in vals:\n",
    "            temp = df[df.cusip == cusip].iloc[0] \n",
    "            if val != temp[col]:\n",
    "                temp[col] = val\n",
    "                df = df.append(temp)\n",
    "    return df\n",
    "\n",
    "def make_summary(col):\n",
    "    '''Calculates the Max-Min range by cusip'''\n",
    "    summary_df = synthetic_sampled_data.groupby(['cusip'])\\\n",
    "    ['predictions']\\\n",
    "    .agg(['std', max_min_f])\\\n",
    "    .rename({'<lambda_0>':'Max-Min'}, axis=1)\\\n",
    "    \n",
    "    summary_df = summary_df.join(synthetic_sampled_data.set_index('cusip')[col])\n",
    "    \n",
    "    summary_df = summary_df.groupby(col).mean()\n",
    "    # summary_df.columns = pd.MultiIndex.from_tuples(summary_df.columns)\n",
    "    \n",
    "    display(summary_df)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "216d09d0-8af5-4505-b85b-ecf18a12a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_dataframe[test_dataframe.trade_date <= '2023-06-09'].copy()\n",
    "# data['days_to_call'] = data[['settlement_date','next_call_date']].apply(lambda x: get_days(x, 'next_call_date'), axis = 1)/NUM_OF_DAYS_IN_YEAR\n",
    "data['maturity'] = data[['settlement_date','maturity_date']].apply(lambda x: get_days(x, 'maturity_date'), axis = 1)/NUM_OF_DAYS_IN_YEAR\n",
    "data['maturity_bucket'] = pd.cut(data['maturity'], [0, 5, 10, 15, 20, 30, data.maturity.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfe18d91-b534-4cc4-bfe0-2f0f53ba1a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 0 ns, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "#We just look at 5 rating values for efficiency \n",
    "RATINGS = ['AAA',  'BBB', 'CCC', 'NR']\n",
    "groupby_cols = ['is_callable','maturity_bucket','rating']\n",
    "\n",
    "sampled_data = data[data.rating.isin(RATINGS)].groupby(groupby_cols)\n",
    "COUNT = iter(range(len(sampled_data.groups)))\n",
    "groupby_id_dict = dict()\n",
    "\n",
    "#Sample 20 random cusips from each maturity bucket, rating and callable combination \n",
    "sampled_data = sampled_data.apply(lambda x: sample_dataframe(x, 20)).reset_index(drop=True)\n",
    "\n",
    "%time synthetic_sampled_data = create_synthetic_samples(sampled_data, 'rating', RATINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "784a817e-46aa-4d21-b5bf-57663b6bd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input for model using original sampled data and sampled data augmented with hypothetical trades \n",
    "X_sample = create_input_new(sampled_data, trade_history_col, [])\n",
    "X_sample_hypothetical_trades = create_input_new(synthetic_sampled_data, trade_history_col, [])\n",
    "\n",
    "sampled_data_predictions  = model.predict(X_sample).flatten()\n",
    "sampled_data_hypothetical_predictions  = model.predict(X_sample_hypothetical_trades).flatten()\n",
    "\n",
    "sampled_data['predictions'] = sampled_data_predictions\n",
    "synthetic_sampled_data['predictions'] = sampled_data_hypothetical_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b47e2e27-b4c9-48ea-aa40-054ab79277b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>Max-Min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_callable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>7.091</td>\n",
       "      <td>15.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>7.097</td>\n",
       "      <td>15.874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              std  Max-Min\n",
       "is_callable               \n",
       "False       7.091   15.712\n",
       "True        7.097   15.874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>Max-Min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAA</th>\n",
       "      <td>6.421</td>\n",
       "      <td>14.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBB</th>\n",
       "      <td>8.491</td>\n",
       "      <td>18.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCC</th>\n",
       "      <td>14.252</td>\n",
       "      <td>32.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>6.532</td>\n",
       "      <td>14.751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   std  Max-Min\n",
       "original_rating                \n",
       "AAA              6.421   14.320\n",
       "BBB              8.491   18.684\n",
       "CCC             14.252   32.472\n",
       "NR               6.532   14.751"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>Max-Min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maturity_bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 5.0]</th>\n",
       "      <td>10.316</td>\n",
       "      <td>23.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(5.0, 10.0]</th>\n",
       "      <td>7.594</td>\n",
       "      <td>16.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(10.0, 15.0]</th>\n",
       "      <td>6.681</td>\n",
       "      <td>14.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(15.0, 20.0]</th>\n",
       "      <td>6.455</td>\n",
       "      <td>14.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(20.0, 30.0]</th>\n",
       "      <td>5.786</td>\n",
       "      <td>12.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(30.0, 46.136]</th>\n",
       "      <td>2.408</td>\n",
       "      <td>5.353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   std  Max-Min\n",
       "maturity_bucket                \n",
       "(0.0, 5.0]      10.316   23.087\n",
       "(5.0, 10.0]      7.594   16.809\n",
       "(10.0, 15.0]     6.681   14.900\n",
       "(15.0, 20.0]     6.455   14.379\n",
       "(20.0, 30.0]     5.786   12.823\n",
       "(30.0, 46.136]   2.408    5.353"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to calculate max-min range within cusip\n",
    "max_min_f = lambda x: x.max() - x.min()\n",
    "\n",
    "synthetic_sampled_data['original_rating'] = synthetic_sampled_data['group'].apply(lambda x: groupby_id_dict[x]['rating'])\n",
    "\n",
    "make_summary('is_callable');\n",
    "make_summary('original_rating');\n",
    "make_summary('maturity_bucket');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e43f6c3-2496-484e-bbae-353e17560517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic_sampled_data.to_pickle('synthetic_sampled_data_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d4c090f-0fcd-4196-adf7-5730911c5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = pd.read_pickle('synthetic_sampled_data_baseline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4e6c9baf-7049-4559-b40b-9e7513ec2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = synthetic_sampled_data.copy().drop_duplicates(subset=['cusip','rating'])\n",
    "B = baseline_data.copy().drop_duplicates(subset=['cusip','rating'])\n",
    "# print(len(A), len(B))\n",
    "\n",
    "A['join'] = A['cusip']+'_'+A['rating']\n",
    "B['join'] = B['cusip']+'_'+B['rating']\n",
    "\n",
    "comp = pd.merge(A, \n",
    "             B[[ 'predictions', 'join']].rename({'predictions':'baseline_model_predictions'}, axis=1),\n",
    "             left_on='join',\n",
    "             right_on='join').drop('join',axis=1)\n",
    "\n",
    "comp['predictions'] = comp['predictions'] + comp['new_ficc_ycl']\n",
    "comp['baseline_model_predictions'] = comp['baseline_model_predictions'] + comp['new_ficc_ycl']\n",
    "\n",
    "comp['baseline_error'] = comp['yield'] - comp['baseline_model_predictions']\n",
    "comp['error'] = comp['yield'] - comp['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "77f65614-876a-4824-a4e9-7ac1c397205b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8349471065120854"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[['baseline_error','error']].corr().iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c01d68cc-2e98-4a40-9ffc-b8c14bfe0d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>original_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>yield</th>\n",
       "      <th>predictions</th>\n",
       "      <th>baseline_model_predictions</th>\n",
       "      <th>error</th>\n",
       "      <th>baseline_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>13033DAL9</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB</td>\n",
       "      <td>443.700</td>\n",
       "      <td>445.462</td>\n",
       "      <td>443.663</td>\n",
       "      <td>-1.762</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>414005S82</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>331.000</td>\n",
       "      <td>336.567</td>\n",
       "      <td>331.039</td>\n",
       "      <td>-5.567</td>\n",
       "      <td>-0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>9771234C9</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>325.800</td>\n",
       "      <td>323.041</td>\n",
       "      <td>325.911</td>\n",
       "      <td>2.759</td>\n",
       "      <td>-0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5917455N0</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>283.000</td>\n",
       "      <td>276.238</td>\n",
       "      <td>283.166</td>\n",
       "      <td>6.762</td>\n",
       "      <td>-0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>346843VR3</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>377.700</td>\n",
       "      <td>379.924</td>\n",
       "      <td>377.495</td>\n",
       "      <td>-2.224</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cusip original_rating rating   yield  predictions  \\\n",
       "139  13033DAL9             BBB    BBB 443.700      445.462   \n",
       "8    414005S82             AAA    AAA 331.000      336.567   \n",
       "346  9771234C9             AAA    AAA 325.800      323.041   \n",
       "61   5917455N0             AAA    AAA 283.000      276.238   \n",
       "481  346843VR3             AAA    AAA 377.700      379.924   \n",
       "\n",
       "     baseline_model_predictions  error  baseline_error  \n",
       "139                     443.663 -1.762           0.037  \n",
       "8                       331.039 -5.567          -0.039  \n",
       "346                     325.911  2.759          -0.111  \n",
       "61                      283.166  6.762          -0.166  \n",
       "481                     377.495 -2.224           0.205  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>original_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>yield</th>\n",
       "      <th>predictions</th>\n",
       "      <th>baseline_model_predictions</th>\n",
       "      <th>error</th>\n",
       "      <th>baseline_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>41422MHD0</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB</td>\n",
       "      <td>487.500</td>\n",
       "      <td>425.365</td>\n",
       "      <td>408.090</td>\n",
       "      <td>62.135</td>\n",
       "      <td>79.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>592240UN3</td>\n",
       "      <td>NR</td>\n",
       "      <td>NR</td>\n",
       "      <td>426.000</td>\n",
       "      <td>501.400</td>\n",
       "      <td>518.592</td>\n",
       "      <td>-75.400</td>\n",
       "      <td>-92.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>881830K28</td>\n",
       "      <td>NR</td>\n",
       "      <td>NR</td>\n",
       "      <td>513.900</td>\n",
       "      <td>420.316</td>\n",
       "      <td>417.852</td>\n",
       "      <td>93.584</td>\n",
       "      <td>96.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>919526AG8</td>\n",
       "      <td>NR</td>\n",
       "      <td>NR</td>\n",
       "      <td>503.300</td>\n",
       "      <td>392.138</td>\n",
       "      <td>398.941</td>\n",
       "      <td>111.162</td>\n",
       "      <td>104.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>13080STQ7</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB</td>\n",
       "      <td>673.000</td>\n",
       "      <td>554.534</td>\n",
       "      <td>529.582</td>\n",
       "      <td>118.466</td>\n",
       "      <td>143.418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cusip original_rating rating   yield  predictions  \\\n",
       "275  41422MHD0             BBB    BBB 487.500      425.365   \n",
       "285  592240UN3              NR     NR 426.000      501.400   \n",
       "381  881830K28              NR     NR 513.900      420.316   \n",
       "59   919526AG8              NR     NR 503.300      392.138   \n",
       "459  13080STQ7             BBB    BBB 673.000      554.534   \n",
       "\n",
       "     baseline_model_predictions   error  baseline_error  \n",
       "275                     408.090  62.135          79.410  \n",
       "285                     518.592 -75.400         -92.592  \n",
       "381                     417.852  93.584          96.048  \n",
       "59                      398.941 111.162         104.359  \n",
       "459                     529.582 118.466         143.418  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>original_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>yield</th>\n",
       "      <th>predictions</th>\n",
       "      <th>baseline_model_predictions</th>\n",
       "      <th>error</th>\n",
       "      <th>baseline_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>696344LC2</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>307.000</td>\n",
       "      <td>306.975</td>\n",
       "      <td>307.656</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>646080XL0</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB</td>\n",
       "      <td>500.800</td>\n",
       "      <td>500.827</td>\n",
       "      <td>501.599</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>914713S60</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>341.300</td>\n",
       "      <td>341.271</td>\n",
       "      <td>351.052</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-9.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>542264GP5</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>331.500</td>\n",
       "      <td>331.439</td>\n",
       "      <td>325.646</td>\n",
       "      <td>0.061</td>\n",
       "      <td>5.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>134159YL0</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>280.000</td>\n",
       "      <td>280.112</td>\n",
       "      <td>281.319</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>-1.319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cusip original_rating rating   yield  predictions  \\\n",
       "268  696344LC2             AAA    AAA 307.000      306.975   \n",
       "493  646080XL0             BBB    BBB 500.800      500.827   \n",
       "385  914713S60             AAA    AAA 341.300      341.271   \n",
       "260  542264GP5             AAA    AAA 331.500      331.439   \n",
       "129  134159YL0             AAA    AAA 280.000      280.112   \n",
       "\n",
       "     baseline_model_predictions  error  baseline_error  \n",
       "268                     307.656  0.025          -0.656  \n",
       "493                     501.599 -0.027          -0.799  \n",
       "385                     351.052  0.029          -9.752  \n",
       "260                     325.646  0.061           5.854  \n",
       "129                     281.319 -0.112          -1.319  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>original_rating</th>\n",
       "      <th>rating</th>\n",
       "      <th>yield</th>\n",
       "      <th>predictions</th>\n",
       "      <th>baseline_model_predictions</th>\n",
       "      <th>error</th>\n",
       "      <th>baseline_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>592240UN3</td>\n",
       "      <td>NR</td>\n",
       "      <td>NR</td>\n",
       "      <td>426.000</td>\n",
       "      <td>501.400</td>\n",
       "      <td>518.592</td>\n",
       "      <td>-75.400</td>\n",
       "      <td>-92.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>64986AJB8</td>\n",
       "      <td>NR</td>\n",
       "      <td>NR</td>\n",
       "      <td>322.200</td>\n",
       "      <td>400.288</td>\n",
       "      <td>379.557</td>\n",
       "      <td>-78.088</td>\n",
       "      <td>-57.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>881830K28</td>\n",
       "      <td>NR</td>\n",
       "      <td>NR</td>\n",
       "      <td>513.900</td>\n",
       "      <td>420.316</td>\n",
       "      <td>417.852</td>\n",
       "      <td>93.584</td>\n",
       "      <td>96.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>919526AG8</td>\n",
       "      <td>NR</td>\n",
       "      <td>NR</td>\n",
       "      <td>503.300</td>\n",
       "      <td>392.138</td>\n",
       "      <td>398.941</td>\n",
       "      <td>111.162</td>\n",
       "      <td>104.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>13080STQ7</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB</td>\n",
       "      <td>673.000</td>\n",
       "      <td>554.534</td>\n",
       "      <td>529.582</td>\n",
       "      <td>118.466</td>\n",
       "      <td>143.418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cusip original_rating rating   yield  predictions  \\\n",
       "285  592240UN3              NR     NR 426.000      501.400   \n",
       "54   64986AJB8              NR     NR 322.200      400.288   \n",
       "381  881830K28              NR     NR 513.900      420.316   \n",
       "59   919526AG8              NR     NR 503.300      392.138   \n",
       "459  13080STQ7             BBB    BBB 673.000      554.534   \n",
       "\n",
       "     baseline_model_predictions   error  baseline_error  \n",
       "285                     518.592 -75.400         -92.592  \n",
       "54                      379.557 -78.088         -57.357  \n",
       "381                     417.852  93.584          96.048  \n",
       "59                      398.941 111.162         104.359  \n",
       "459                     529.582 118.466         143.418  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize some of the predictions with smallest and largest errors \n",
    "temp_df = comp[comp.rating == comp.original_rating]\n",
    "select_cols = ['cusip', 'original_rating', 'rating', 'yield', 'predictions','baseline_model_predictions','error', 'baseline_error']\n",
    "display(temp_df[select_cols].sort_values(by='baseline_error', key = abs).head())\n",
    "display(temp_df[select_cols].sort_values(by='baseline_error', key = abs).tail())\n",
    "display(temp_df[select_cols].sort_values(by='error', key = abs).head())\n",
    "display(temp_df[select_cols].sort_values(by='error', key = abs).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a1c87-b9a6-411a-a9ae-155986b3c292",
   "metadata": {},
   "source": [
    "Here we look at the average and standard deviation of the within-CUSIP Max-Min Range between the new model and the original model. The mean range and standard deviation of the ranges are larger for the new model's predictions, suggesting that it is more sensitive to ratings changes. Based on the histogram below, we see the same trend, though subtle - predicted yields stretch further out for the new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e75f1040-00d9-4750-9f02-31c20c98a62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Max-Min Range across all CUSIPS:\n",
      " predictions                  15.792\n",
      "baseline_model_predictions   11.027\n",
      "dtype: float64\n",
      "\n",
      "Std of Max-Min Range across all CUSIPS:\n",
      " predictions                  12.728\n",
      "baseline_model_predictions    9.027\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAHiCAYAAABsqbQnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiY0lEQVR4nO3dfbBtZ10f8O+PXCIhIOHN25gEbhSEiaYEm2Ko1p7yUgOXmkylqI2UaJxIB1us18IF3x3oXDoqQWWwKW9xRF4GRSgRFSGn2LEgCSABoiXgDUkICUoCXLTghad/7HXI5pyzzz3v+zl7fz4ze7LXXnvt/VvPXdnP+p71rLWqtRYAAACm6x7TLgAAAADhDAAAoAvCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognMEaqupoVT1heP78qnr5Jj/nw1W1sJ21AdCv8f5jl76vVdXDhue/WVU/u1vfvd3G1+UE71uoqlt2o6YT1GFfgW2zb9oFwF7RWvuv63lfVb06yS2ttZ8ZW/Zbd6ouABjXWnvmtGuYV/YV2CpHzpgbVeWPEQDARPYVmDbhjD1vGE7wvKr6SFXdWVWvqqp7LQ13qKrnVtWnkryqqu5RVYer6mNV9bdV9YaqesDYZz29qm4a5v30su/5har67bHp76qqP6uqu6rq5qq6tKouT3JJkudU1bGq+p9jNS4Nefi6qrqiqj45PK6oqq8b5i3VfKiq7qiq26rqh8e+88nDen6+qm6tqp/a0cYFYCv+6Sp90/2r6q1V9enh9bdW1ZlLCwx9yceH3/m/rqpLxub9SFXdMCz3R1X10NW+tKpeXVUvGJ6fqF/5uqr65ar6RFXdPgyJPGWtlRr7zOeMfebFQx/1f6vqM1X1/GXfsWq/N8z/L8NnfLKqfmTZd224vlXqXXU/Ydm62FegC8IZs+KSJN+T5JuTfEuSpWEC/yjJA5I8NMnlSf5jkouT/Isk35jkziQvTZKqOifJy5I8fZj3wCRf7TDHDR3i25L8epIHJzkvyQdaa1cmeU2S/9Zau09r7V+vsvhPJ7lgWOZRSR4zVu9SzfdLckaSy5K8tKruP8x7RZIfa63dN8m3JXnniZsGgClZrW+6R5JXZdQvPSTJ3yf5jSSpqlOT/FqSJw2/8/8syQeGeRcleX6Sf5NRv/OnSV67zjrW6leODLWdl+Rhw3t+bp2fea+x9/+PJD+U5J8k+edJfraqzh7eO7Hfq6oLk/xUkicmeXiS5efpbba+5SbtJyyti30F+tBa8/DY048kR5M8c2z6yUk+lmQhyZeS3Gts3g1JHj82fXqSf8jo/MufS/K6sXmnDss/YZj+hSS/PTx/XpI3Tajn1UlesEqNS5/zsSRPHpv3PUmODs8XMuqo943NvyPJBcPzTyT5sSRfP+129/Dw8PCY/JjUN63yvvOS3Dk8PzXJXUm+L8kpy973tiSXjU3fI8nfJXnoMN2SPGx4/tV+aK1+JUkl+UKSbx6b99gkf32CdVv6zJOG6fsO3/8dY++5LsnFw/O1+r1XJjkyNu9bltblRPUNddyylX+L2Ffw6OzhyBmz4uax5zdl9NesJPl0a+3/jc17aJI3DcML7sroB/jLSfYPy3z1c1prX0jytxO+76yMfjg34xuHGlerN0n+trV2fGz675LcZ3j+fRl1KjdV1f+qqsdusgYAdt6Kvqmq7l1V/30YFve5JO9KclpVnTT0O9+f5JlJbquqq6vqkcPyD03ykrH+6zMZhZcz1lHHpH7lwUnuneS6sc/9w+H19Xzml4fnfz/89/ax+X+fu/uutfq9r+l7l71vK/UtN2k/IbGvQEeEM2bFWWPPH5Lkk8Pztux9N2c0XOS0sce9Wmu3Jrlt/HOq6t4ZDVdYzc0ZDY1YzfLvXO6TGf3wr1bvmlpr722tXZTkG5L8fpI3rGc5AKZitb7pUJJHZHSU6euTfPcwv5KktfZHrbUnZnS05i8zGi6YjPqdH1vWf53SWvuzLdT3NxmFqG8d+8z7tdbuc6IFN2itfu9r+t5h3k7UN2k/IbGvQEeEM2bFs6rqzOGE3Z9O8voJ7/vNJC8cxoGnqh48jONPkjcmecpw8u7JSX4pk/8feU2SJ1TV06pqX1U9sKrOG+bdnuSb1qj1tUl+ZvjuB2U0ROK313h/hlpPrqpLqup+rbV/SPK5JF850XIATM1qfdN9Mwocdw2v//zSm6tqf1VdNJx79sUkx3L37/xvJnleVX3r8N77VdW/3UpxrbWvZBT+XlxV3zB87hlV9T1b+dxVrNXvvSHJpVV1zhB0vtoe21zfevcTEvsKTJFwxqz4nSR/nOTjGQ0heMGE970kyVuS/HFVfT7Ju5N8R5K01j6c5FnDZ92W0QnAq97csrX2iYyGDBzKaGjJBzI6YTcZnYh7zjAc4vdXWfwFSa5N8sEk1yd53xr1Lvf0JEeHoTDPzOgEZwD6tFrfdEWSUzI6KvTujIbpLblHkp/M6AjJZzK6IMV/SJLW2puSvCjJ64Y+4ENJnrQNNT43yY1J3j187p9kdGRvO03s91prb8uoTd451LH84hXbVd969xMS+wpMUbV2oqOq0LeqOprkR1trfzLtWgCAvthPYC9x5AwAAKADwhkAAF+jqp4/3CB5+eNt065tuap6yIRaj1XVQ078CdAPwxoBAAA64MgZAABAB4QzAACADuzbzS970IMe1A4cOLDh5b7whS/k1FNP3f6C9jBtspI2WUmbrKRNVlqtTa677rq/aa09eEolsQn62K9lvfaWWV2vZHbXzXpt3lp97K6GswMHDuTaa6/d8HKLi4tZWFjY/oL2MG2ykjZZSZuspE1WWq1Nquqm6VTDZuljv5b12ltmdb2S2V0367V5a/WxhjUCAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANCBfdMuYJoOHL564ryjRw7uYiUAMD/0vwCrc+QMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0IGZuQm1G1oCAAB7mSNnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA7MzE2oAYC978Dhq1d9/eiRg7tcCcDuc+QMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0IE9dRPqSTemBACmw02jAbaPI2cAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADuypm1ADALtv0o2mAdhejpwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB9YdzqrqpKp6f1W9dZg+u6reU1U3VtXrq+rknSsTAABgtm3kyNmzk9wwNv2iJC9urT0syZ1JLtvOwgAAAObJusJZVZ2Z5GCSlw/TleRxSd44vOWqJBfvQH0AAABzYb03ob4iyXOS3HeYfmCSu1prx4fpW5Kcsb2lAQB7lRtXA2zcCcNZVT0lyR2tteuqamGjX1BVlye5PEn279+fxcXFjX5Ejh07lsXFxRw69/iJ37yKSd+51udtps7dtNQm3E2brKRNVtImK2kTAOjDeo6cfWeS762qJye5V5KvT/KSJKdV1b7h6NmZSW5dbeHW2pVJrkyS888/vy0sLGy4yMXFxSwsLOTSTf4V7uglq3/nWp83aZleLLUJd9MmK2mTlbTJStoEAPpwwnPOWmvPa62d2Vo7kOQHkryztXZJkmuSPHV42zOSvHnHqgQAAJhxW7nP2XOT/GRV3ZjROWiv2J6SAAAA5s96LwiSJGmtLSZZHJ5/PMljtr8kAJgvVXVSkmuT3Npae0pVnZ3kdRn98fO6JE9vrX1pmjUCsPO2cuQMANge7iUKgHAGANPkXqIALBHOAGC6rsjoXqJfGabdSxRgTm3onDMAYPv0dC/RtWz2PqPbaaPrNqv377Nee8+srpv12hnCGQBMTzf3El3LZu8zup02ev/RWb1/n/Xae2Z13azXzjCsEQCmxL1EARgnnAFAf9xLFGAOGdYIAB1wL1EAHDkDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADrha4wQHJtxw8+iRg7tcCQAAMA8cOQMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0YC5uQj3phtI91OCm1gAAQOLIGQAAQBeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADc3ET6u201g2t3VAaAADYLEfOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADowL5pFwAAsNsOHL564ryjRw7uYiUAd3PkDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOjACcNZVd2rqv68qv6iqj5cVb84vH52Vb2nqm6sqtdX1ck7Xy4AAMBsWs+Rsy8meVxr7VFJzktyYVVdkORFSV7cWntYkjuTXLZjVQIAAMy4E4azNnJsmLzn8GhJHpfkjcPrVyW5eCcKBAAAmAfrOuesqk6qqg8kuSPJ25N8LMldrbXjw1tuSXLGjlQIAAAwB/at502ttS8nOa+qTkvypiSPXO8XVNXlSS5Pkv3792dxcXHDRR47diyLi4s5dO7xE795itZat0m1b6Y9krvbZLnrb/3sxGXOPeN+m/quvWJSm8wzbbKSNllJmwBAH9YVzpa01u6qqmuSPDbJaVW1bzh6dmaSWycsc2WSK5Pk/PPPbwsLCxsucnFxMQsLC7n08NUbXnY3Hb1kYeK8SbWvtcxaltpkvd+zle/aKya1yTzTJitpk5W0CQD0YT1Xa3zwcMQsVXVKkicmuSHJNUmeOrztGUnevEM1AsBMckVkAMat55yz05NcU1UfTPLeJG9vrb01yXOT/GRV3ZjkgUlesXNlAsBMckVkAL7qhMMaW2sfTPLoVV7/eJLH7ERRADAPWmstyaQrIv+74fWrkvxCkpftdn0A7K51Xa0RANgZrogMwJINXRAEANhevVwReS09XC15o+t2ovVaa516vnrprF5ddVbXK5nddbNeO0M4A4AOTPuKyGvp4WrJG73i8InWa69e3XhWr646q+uVzO66Wa+dYVgjAEyJKyIDMM6RMwCYntOTXFVVJ2X0B9M3tNbeWlUfSfK6qnpBkvfHFZEB5oJwBgBT4orIAIwzrBEAAKADwhkAAEAHhDMAAIAOCGcAAAAdcEEQAGBPO7DKPcsOnXs8C7tfCsCWOHIGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6ICbUAMA3VvtRtMAs8aRMwAAgA4IZwAAAB0wrHHK1hqmcfTIwV2sBAAAmCZHzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOjAvmkXwOZcf+tnc+nhq6ddBgAAsE0cOQMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0wE2ot9EBN4UGAAA2yZEzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOjAvmkXAACwEw4cvnrXPu/okYPb+l3AfHLkDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADJwxnVXVWVV1TVR+pqg9X1bOH1x9QVW+vqo8O/73/zpcLAAAwm9Zz5Ox4kkOttXOSXJDkWVV1TpLDSd7RWnt4kncM0wAAAGzCCcNZa+221tr7huefT3JDkjOSXJTkquFtVyW5eIdqBAAAmHkbOuesqg4keXSS9yTZ31q7bZj1qST7t7c0AACA+bFvvW+sqvsk+d0kP9Fa+1xVfXVea61VVZuw3OVJLk+S/fv3Z3FxccNFHjt2LIuLizl07vENL7uXrdVW+0/JhttjM22/lyxtJ9xNm6ykTVbSJtNTVWcl+a2M/sDZklzZWntJVT0gyeuTHEhyNMnTWmt3TqtOAHbHusJZVd0zo2D2mtba7w0v315Vp7fWbquq05PcsdqyrbUrk1yZJOeff35bWFjYcJGLi4tZWFjIpYev3vCye9nRSxYmzvv117w5v3L9urP1CT9vFixtJ9xNm6ykTVbSJlO1dF73+6rqvkmuq6q3J7k0o/O6j1TV4YzO637uFOsEYBes52qNleQVSW5orf3q2Ky3JHnG8PwZSd68/eUBwOxyXjcA49Zz6OU7kzw9yfVV9YHhtecnOZLkDVV1WZKbkjxtRyoEgDngvG4AThjOWmv/O0lNmP347S0HAOZPD+d1r2UvnvO9mXOzl0xqj7U+b7fO25zVc0Rndb2S2V0367UzNnbSEgCwrXo5r3ste/Gc70PnHt/wudlLJp2jvVY77NZ53bN6juisrlcyu+tmvXbGhi6lDwBsH+d1AzDOkTMAmB7ndQPwVcIZAEyJ87oBGCeczZEDE8bKHz1ycJcrAQAAlnPOGQAAQAeEMwAAgA4IZwAAAB1wzhkAMPG8ZAB2jyNnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOrBv2gUAAPTkwOGrt22Zo0cObrUcYI44cgYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdcLXGjq11tahD5+5iIQAAwI5z5AwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6IBwBgAA0AHhDAAAoAPCGQAAQAeEMwAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAH9k27APauA4evXvX1o0cO7nIlAACw9zlyBgAA0AHhDAAAoAOGNQIA7BHX3/rZXOq0AphZjpwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOuAm1AAAU3Bgws2kEzeUhnnlyBkAAEAHhDMAAIAOnDCcVdUrq+qOqvrQ2GsPqKq3V9VHh//ef2fLBAAAmG3rOXL26iQXLnvtcJJ3tNYenuQdwzQAAACbdMJw1lp7V5LPLHv5oiRXDc+vSnLx9pYFALPP6BQAxm32nLP9rbXbhuefSrJ/m+oBgHny6hidAsBgy5fSb621qmqT5lfV5UkuT5L9+/dncXFxw99x7NixLC4u5tC5xzdd56zZf0q2rT0282+STP7+zX7eVi1tJ9xNm6ykTVbSJtPTWntXVR1Y9vJFSRaG51clWUzy3N2rCoBp2Ww4u72qTm+t3VZVpye5Y9IbW2tXJrkySc4///y2sLCw4S9bXFzMwsJCLl3jfiDz5tC5x/Mr12/PbeqOXrKwqeUm/Xts9vO2amk74W7aZCVtspI26Y7RKQBzarN7929J8owkR4b/vnnbKgIAkhidshXbOcJkK9b6N1mrvknLrbVee/kI+CwfwZ/VdbNeO+OE4ayqXpvR8IoHVdUtSX4+o1D2hqq6LMlNSZ62k0UCwBwxOmUbbOcIk61YazTJWm0+ablff82bJ67XtEaubIdZPoI/q+tmvXbGCX+1Wms/OGHW47e5FgDA6BSAubXZqzUCAFs0jE75P0keUVW3DCNSjiR5YlV9NMkThmkA5sD0j/cDwJwyOgWAcY6cAQAAdEA4AwAA6IBhjeTAWleLOnJwFysBAID55cgZAABABxw5AwDozKRRLYfO3fgyyeSRMLs5embSdxmlA3dz5AwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0wKX02XY93NS6hxoAAGAjHDkDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdMBNqOnCWjeNXosbSgMAMCscOQMAAOiAI2cAADtksyNDgPnkyBkAAEAHhDMAAIAOCGcAAAAdEM4AAAA6IJwBAAB0QDgDAADogHAGAADQAfc5Y1e53wsAAKxOOAMAYIVJf1A9euTgLlcC88OwRgAAgA4IZwAAAB0QzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKAD7nPGmnq/afR4fYfOPZ5LO68XAAAmEc4AAGZc739sBUYMawQAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAOCGcAAAAdEM4AAAA64D5nMGbSfWCOHjm4rcsAAMByjpwBAAB0QDgDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdGDftAsAAICNOHD46onzjh45uIuVrG68vkPnHs+lY9M91Ee/HDkDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdMBNqAEA2BZr3Rx6rWWW36h5t/V+U+seLG+j8X8zbbR9HDkDAADogHAGAADQAeEMAACgA8IZAABAB4QzAACADghnAAAAHRDOAAAAOiCcAQAAdMBNqJk7m7lB5m5+z3beyPH6Wz+7qZt6Tqqhh5t09lBDLya1xby1A7C7dqsf3aztrm+v9jt7te7N2u4+cVp9rCNnAAAAHRDOAAAAOiCcAQAAdEA4AwAA6MCWwllVXVhVf1VVN1bV4e0qCgDmnT4WYP5sOpxV1UlJXprkSUnOSfKDVXXOdhUGAPNKHwswn7Zy5OwxSW5srX28tfalJK9LctH2lAUAc00fCzCHthLOzkhy89j0LcNrAMDW6GMB5lC11ja3YNVTk1zYWvvRYfrpSb6jtfbjy953eZLLh8lHJPmrTXzdg5L8zaYKnV3aZCVtspI2WUmbrLRamzy0tfbgaRSDPnabWK+9ZVbXK5nddbNemzexj923hQ+9NclZY9NnDq99jdbalUmu3ML3pKquba2dv5XPmDXaZCVtspI2WUmbrKRNuqSP3SLrtbfM6nols7tu1mtnbGVY43uTPLyqzq6qk5P8QJK3bE9ZADDX9LEAc2jTR85aa8er6seT/FGSk5K8srX24W2rDADmlD4WYD5tZVhjWmt/kOQPtqmWtWxpyMaM0iYraZOVtMlK2mQlbdIhfeyWWa+9ZVbXK5nddbNeO2DTFwQBAABg+2zlnDMAAAC2SffhrKourKq/qqobq+rwtOuZhqo6q6quqaqPVNWHq+rZw+sPqKq3V9VHh//ef9q17raqOqmq3l9Vbx2mz66q9wzby+uHE+nnRlWdVlVvrKq/rKobquqx876dVNV/Hv6/+VBVvbaq7jVv20lVvbKq7qiqD429tup2USO/NrTNB6vq26dXOTttVvrYjWzje8ms9v/D7/CfV9VfDOv1i8PrM/HbPIv7JlV1tKqur6oPVNW1w2t7ejtM+txv6jqcVdVJSV6a5ElJzknyg1V1znSrmorjSQ611s5JckGSZw3tcDjJO1prD0/yjmF63jw7yQ1j0y9K8uLW2sOS3JnksqlUNT0vSfKHrbVHJnlURm0zt9tJVZ2R5D8lOb+19m0ZXVjhBzJ/28mrk1y47LVJ28WTkjx8eFye5GW7VCO7bMb62Fdn/dv4XjKr/f8XkzyutfaoJOclubCqLsjs/DbP6r7Jv2ytnTd2mfm9vh0mHe43dR3OkjwmyY2ttY+31r6U5HVJLppyTbuutXZba+19w/PPZ7ThnJFRW1w1vO2qJBdPpcApqaozkxxM8vJhupI8Lskbh7fMVZtU1f2SfHeSVyRJa+1LrbW7MufbSUYXPjqlqvYluXeS2zJn20lr7V1JPrPs5UnbxUVJfquNvDvJaVV1+q4Uym6bmT52g9v4njGr/f/w+3JsmLzn8GiZgd/mOds32dPbYa/7Tb2HszOS3Dw2fcvw2tyqqgNJHp3kPUn2t9ZuG2Z9Ksn+adU1JVckeU6SrwzTD0xyV2vt+DA9b9vL2Uk+neRVw3CKl1fVqZnj7aS1dmuSX07yiYxC2WeTXJf53k6WTNou/O7Oj1n/t56p375Z6/+HoX8fSHJHkrcn+Vhm47f5iszmvklL8sdVdV1VXT68tte3wy73m3oPZ4ypqvsk+d0kP9Fa+9z4vDa67ObcXHqzqp6S5I7W2nXTrqUj+5J8e5KXtdYeneQLWXYofg63k/tn9Bews5N8Y5JTs3Lo09ybt+2C+bPXt/FZ7P9ba19urZ2X5MyMjuI+croVbd2M75t8V2vt2zMaBv2sqvru8Zl7dDvscr+p93B2a5KzxqbPHF6bO1V1z4x+mF/TWvu94eXbl4YbDf+9Y1r1TcF3Jvneqjqa0VCcx2U0bvi0YfhaMn/byy1JbmmtvWeYfmNGPzrzvJ08Iclft9Y+3Vr7hyS/l9G2M8/byZJJ24Xf3fkx6//WM/HbN+v9/zCM7Jokj83e/22e2X2TYSRKWmt3JHlTRoF6r2+HXe439R7O3pvk4cNVbk7O6ET+t0y5pl03jFd+RZIbWmu/OjbrLUmeMTx/RpI373Zt09Jae15r7czW2oGMtot3ttYuyegH/qnD2+atTT6V5OaqesTw0uOTfCRzvJ1kNJzxgqq69/D/0VKbzO12MmbSdvGWJP++Ri5I8tmx4R3MllnvY/f8b9+s9v9V9eCqOm14fkqSJ2Z0Pt2e/m2e1X2Tqjq1qu679DzJv0ryoezx7bDX/abub0JdVU/OaPzuSUle2Vp74XQr2n1V9V1J/jTJ9bl7DPPzMxp3/oYkD0lyU5KntdaWnxA986pqIclPtdaeUlXflNFfqx6Q5P1Jfqi19sUplrerquq8jE5CPjnJx5P8cEZ/hJnb7WS4RPP3Z3TVs/cn+dGMxvvPzXZSVa9NspDkQUluT/LzSX4/q2wXw87gb2Q0/PPvkvxwa+3aKZTNLpiVPnYj2/iUStyUWe3/q+ofZ3ShhZMy9FGttV+apT58lvZNhvrfNEzuS/I7rbUXVtUDs4e3w6TP/abuwxkAAMA86H1YIwAAwFwQzgAAADognAEAAHRAOAMAAOiAcAYAANAB4QwAAKADwhkAAEAHhDMAAIAO/H9wZ3MNXd7kVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = comp.groupby('cusip')[['predictions','baseline_model_predictions']].apply(max_min_f)\n",
    "print('Average Max-Min Range across all CUSIPS:\\n', temp.mean())\n",
    "print()\n",
    "print('Std of Max-Min Range across all CUSIPS:\\n', temp.std())\n",
    "temp.hist(figsize=(15, 8), bins = 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ad345-3ea3-4951-bd5e-6ce005638332",
   "metadata": {},
   "source": [
    "Where the new_model has a larger range, that range averages 9.1bps. Where the baseline model has a larger range, that range averages 4.7bps. It is also twice as common for the new model to have a larger range (342 v 158)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ef5355b-ed63-4d13-8363-7038effafe14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 158)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp[temp.predictions>temp.baseline_model_predictions]), len(temp[temp.predictions<temp.baseline_model_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "57d399de-4290-4304-bd0d-32cc5be9767a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions                     NaN\n",
       "baseline_model_predictions   -9.156\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp.predictions>temp.baseline_model_predictions].diff(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83f47fbb-505d-434a-a3e2-e7f6207aa4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions                    NaN\n",
       "baseline_model_predictions   4.740\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp.predictions<temp.baseline_model_predictions].diff(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd7986-22da-46bf-92c7-43b5b6fb2a11",
   "metadata": {},
   "source": [
    "Here we look at the average Max-Min range based on original rating and maturity. Predictions are more sensitive for bonds with lower ratings and shorter maturities. Obviously the impact of features like ratings on predictions is non-linear in the network, but this trend likely tells us also that bonds with lower ratings systematically have other features in favor of higher yields. In any case, the predictions of the new model are more sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c97d4a16-9c34-4007-aa83-b195362105a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>baseline_model_predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAA</th>\n",
       "      <td>14.320</td>\n",
       "      <td>9.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBB</th>\n",
       "      <td>18.684</td>\n",
       "      <td>12.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCC</th>\n",
       "      <td>32.472</td>\n",
       "      <td>21.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR</th>\n",
       "      <td>14.751</td>\n",
       "      <td>11.453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predictions  baseline_model_predictions\n",
       "original_rating                                         \n",
       "AAA                   14.320                       9.505\n",
       "BBB                   18.684                      12.805\n",
       "CCC                   32.472                      21.623\n",
       "NR                    14.751                      11.453"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.groupby(['cusip','original_rating'])\\\n",
    "[['predictions','baseline_model_predictions']].apply(max_min_f)\\\n",
    ".reset_index()\\\n",
    ".groupby('original_rating')\\\n",
    ".mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d979f1d2-8f5f-468d-867b-1e4995c50a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>baseline_model_predictions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maturity_bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 5.0]</th>\n",
       "      <td>23.087</td>\n",
       "      <td>17.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(5.0, 10.0]</th>\n",
       "      <td>16.809</td>\n",
       "      <td>12.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(10.0, 15.0]</th>\n",
       "      <td>14.900</td>\n",
       "      <td>9.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(15.0, 20.0]</th>\n",
       "      <td>14.379</td>\n",
       "      <td>9.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(20.0, 30.0]</th>\n",
       "      <td>12.823</td>\n",
       "      <td>8.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(30.0, 46.136]</th>\n",
       "      <td>5.353</td>\n",
       "      <td>4.827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 predictions  baseline_model_predictions\n",
       "maturity_bucket                                         \n",
       "(0.0, 5.0]            23.087                      17.145\n",
       "(5.0, 10.0]           16.809                      12.383\n",
       "(10.0, 15.0]          14.900                       9.303\n",
       "(15.0, 20.0]          14.379                       9.152\n",
       "(20.0, 30.0]          12.823                       8.708\n",
       "(30.0, 46.136]         5.353                       4.827"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp.groupby(['cusip','maturity_bucket'])\\\n",
    "[['predictions','baseline_model_predictions']].apply(max_min_f)\\\n",
    ".reset_index()\\\n",
    ".groupby('maturity_bucket')\\\n",
    ".mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6b1a443a-b7e8-411c-88d9-199521091b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = comp.groupby(['cusip','original_rating', 'maturity_bucket'])\\\n",
    "[['predictions','baseline_model_predictions']].apply(max_min_f)\\\n",
    ".reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2f2e7212-75ea-46b4-8ba5-560e81c49024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>original_rating</th>\n",
       "      <th>maturity_bucket</th>\n",
       "      <th>predictions</th>\n",
       "      <th>baseline_model_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>491501DX7</td>\n",
       "      <td>NR</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>36.510</td>\n",
       "      <td>61.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>41420LRE1</td>\n",
       "      <td>BBB</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>49.885</td>\n",
       "      <td>57.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>080401RB0</td>\n",
       "      <td>AAA</td>\n",
       "      <td>(20.0, 30.0]</td>\n",
       "      <td>22.446</td>\n",
       "      <td>49.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>57584XAF8</td>\n",
       "      <td>BBB</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>44.560</td>\n",
       "      <td>46.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>235839CZ8</td>\n",
       "      <td>BBB</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>37.524</td>\n",
       "      <td>40.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>486189GS6</td>\n",
       "      <td>BBB</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>29.103</td>\n",
       "      <td>40.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>34282CLH2</td>\n",
       "      <td>NR</td>\n",
       "      <td>(10.0, 15.0]</td>\n",
       "      <td>35.861</td>\n",
       "      <td>38.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>19648A6C4</td>\n",
       "      <td>NR</td>\n",
       "      <td>(5.0, 10.0]</td>\n",
       "      <td>12.524</td>\n",
       "      <td>35.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3733846D3</td>\n",
       "      <td>AAA</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>10.847</td>\n",
       "      <td>33.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>413890DK7</td>\n",
       "      <td>BBB</td>\n",
       "      <td>(30.0, 46.136]</td>\n",
       "      <td>12.189</td>\n",
       "      <td>32.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>838530QC0</td>\n",
       "      <td>BBB</td>\n",
       "      <td>(5.0, 10.0]</td>\n",
       "      <td>15.404</td>\n",
       "      <td>31.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>033177YT7</td>\n",
       "      <td>NR</td>\n",
       "      <td>(5.0, 10.0]</td>\n",
       "      <td>16.457</td>\n",
       "      <td>31.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>4684306L2</td>\n",
       "      <td>BBB</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>18.343</td>\n",
       "      <td>30.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>92817LRK1</td>\n",
       "      <td>AAA</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>24.452</td>\n",
       "      <td>30.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>940157R69</td>\n",
       "      <td>AAA</td>\n",
       "      <td>(20.0, 30.0]</td>\n",
       "      <td>15.524</td>\n",
       "      <td>29.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>56574RBG2</td>\n",
       "      <td>BBB</td>\n",
       "      <td>(20.0, 30.0]</td>\n",
       "      <td>5.213</td>\n",
       "      <td>29.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>95640HEY0</td>\n",
       "      <td>AAA</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>15.012</td>\n",
       "      <td>28.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>15504RET2</td>\n",
       "      <td>AAA</td>\n",
       "      <td>(15.0, 20.0]</td>\n",
       "      <td>10.488</td>\n",
       "      <td>26.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>64986DKA2</td>\n",
       "      <td>AAA</td>\n",
       "      <td>(5.0, 10.0]</td>\n",
       "      <td>18.047</td>\n",
       "      <td>25.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>60412AEY5</td>\n",
       "      <td>AAA</td>\n",
       "      <td>(0.0, 5.0]</td>\n",
       "      <td>25.096</td>\n",
       "      <td>25.902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cusip original_rating maturity_bucket  predictions  \\\n",
       "211  491501DX7              NR      (0.0, 5.0]       36.510   \n",
       "157  41420LRE1             BBB      (0.0, 5.0]       49.885   \n",
       "25   080401RB0             AAA    (20.0, 30.0]       22.446   \n",
       "246  57584XAF8             BBB      (0.0, 5.0]       44.560   \n",
       "99   235839CZ8             BBB      (0.0, 5.0]       37.524   \n",
       "204  486189GS6             BBB      (0.0, 5.0]       29.103   \n",
       "122  34282CLH2              NR    (10.0, 15.0]       35.861   \n",
       "76   19648A6C4              NR     (5.0, 10.0]       12.524   \n",
       "135  3733846D3             AAA      (0.0, 5.0]       10.847   \n",
       "154  413890DK7             BBB  (30.0, 46.136]       12.189   \n",
       "424  838530QC0             BBB     (5.0, 10.0]       15.404   \n",
       "7    033177YT7              NR     (5.0, 10.0]       16.457   \n",
       "192  4684306L2             BBB      (0.0, 5.0]       18.343   \n",
       "479  92817LRK1             AAA      (0.0, 5.0]       24.452   \n",
       "485  940157R69             AAA    (20.0, 30.0]       15.524   \n",
       "236  56574RBG2             BBB    (20.0, 30.0]        5.213   \n",
       "488  95640HEY0             AAA      (0.0, 5.0]       15.012   \n",
       "63   15504RET2             AAA    (15.0, 20.0]       10.488   \n",
       "317  64986DKA2             AAA     (5.0, 10.0]       18.047   \n",
       "267  60412AEY5             AAA      (0.0, 5.0]       25.096   \n",
       "\n",
       "     baseline_model_predictions  \n",
       "211                      61.609  \n",
       "157                      57.531  \n",
       "25                       49.999  \n",
       "246                      46.915  \n",
       "99                       40.577  \n",
       "204                      40.356  \n",
       "122                      38.203  \n",
       "76                       35.102  \n",
       "135                      33.524  \n",
       "154                      32.947  \n",
       "424                      31.688  \n",
       "7                        31.682  \n",
       "192                      30.615  \n",
       "479                      30.548  \n",
       "485                      29.715  \n",
       "236                      29.437  \n",
       "488                      28.372  \n",
       "63                       26.109  \n",
       "317                      25.963  \n",
       "267                      25.902  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[temp.baseline_model_predictions>temp.predictions].sort_values('baseline_model_predictions', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd20b4-44ce-49f8-90c0-1a8d9e99f905",
   "metadata": {},
   "source": [
    "We also check the model for consistency - in general, there is little reason for yields to go down if a bond's rating is downgraded. In other words, the relationship between rating and yield should be monotonically increasing. The model is more consistent if this happens. The code below checks for the consistency of yields in hypothetical trades if the yields are increasing from AAA -> BBB -> CCC (we drop NR hypothetical trades). We also check for the more general case where yields are higher when rating is AAA compared to CCC. \n",
    "\n",
    "Again, we see that the new model is more consistent. In particular, it is twice more likely to have monotonically increasing yields as rating decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1b91fb2f-54bf-4f0b-9580-2b31fdd836c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions                  0.550\n",
       "baseline_model_predictions   0.238\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "predictions                  0.884\n",
       "baseline_model_predictions   0.830\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_monotonic(df):\n",
    "    df = df[df.rating!='NR'].sort_values(by='rating')[['predictions','baseline_model_predictions']].diff()\n",
    "    return ~(df <= 0).any(axis=0)\n",
    "\n",
    "def check_monotonic_start_end(df):\n",
    "    df = df[df.rating!='NR'].sort_values(by='rating')[['predictions','baseline_model_predictions']]\n",
    "    df = df.iloc[-1] - df.iloc[0]\n",
    "    return df >= 0\n",
    "\n",
    "is_monotonic = comp.groupby('cusip').apply(check_monotonic)\n",
    "is_monotonic_start_end = comp.groupby('cusip').apply(check_monotonic_start_end)\n",
    "\n",
    "display(is_monotic.mean())\n",
    "display(is_monotonic_start_end.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872383e-0440-4baa-a70c-2edc0f9dff87",
   "metadata": {},
   "source": [
    "Look at embeddings: \n",
    "(in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0ada4753-077f-46de-9a2a-de7091576220",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = keras.models.load_model('baseline_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "daf7ad0e-910a-4c0d-9c7c-212c014d841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7adeea2c-3f34-4495-a5f5-b43ae23e2536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: ['AA+', 'AAA', 'CCC']\n",
      "A+: ['AAA', 'B-', 'CCC+']\n",
      "A-: ['AA+', 'AAA', 'CCC-']\n",
      "AA: ['BB+', 'BB-', 'D']\n",
      "AA+: ['B', 'BB-', 'CC']\n",
      "AA-: ['B-', 'CCC', 'CCC+']\n",
      "AAA: ['A-', 'BB+', 'BBB']\n",
      "B: ['AA', 'AA+', 'B+']\n",
      "B+: ['BB+', 'CCC+', 'MR']\n",
      "B-: ['AA+', 'AA-', 'B+']\n",
      "BB: ['A', 'A+', 'AA+']\n",
      "BB+: ['AAA', 'B+', 'CC']\n",
      "BB-: ['AA', 'AA+', 'B+']\n",
      "BBB: ['AA+', 'AAA', 'D']\n",
      "BBB+: ['AA+', 'AA-', 'AAA']\n",
      "BBB-: ['AA-', 'AAA', 'CC']\n",
      "CC: ['AA+', 'BB+', 'CCC+']\n",
      "CCC: ['AA-', 'B+', 'CC']\n",
      "CCC+: ['AA-', 'B+', 'CC']\n",
      "CCC-: ['A-', 'AA', 'CC']\n",
      "D: ['AA', 'BBB', 'MR']\n",
      "NR: ['A+', 'A-', 'B+']\n",
      "MR: ['AA+', 'AA-', 'B+']\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "rating_embedding_layer = baseline_model.get_layer('rating_embed')\n",
    "rating_embedding_weights = rating_embedding_layer.get_weights()[0]\n",
    "\n",
    "dist_all = []\n",
    "for i, arr1 in enumerate(rating_embedding_weights):\n",
    "    dist = []\n",
    "    for j, arr2 in enumerate(rating_embedding_weights):\n",
    "        dist.append(cosine_similarity(arr1.reshape(1,-1),\n",
    "                                      arr2.reshape(1,-1))[0][0])\n",
    "    dist_all.append(dist)\n",
    "\n",
    "# encoded_ratings = pd.DataFrame({x:[y] for x, y in zip(categorical_feature_values['rating'], rating_embedding_weights)}).T\n",
    "\n",
    "encoded_ratings = pd.DataFrame(dist_all, \n",
    "             index = categorical_feature_values['rating'],\n",
    "            columns = categorical_feature_values['rating'])\n",
    "\n",
    "for col in encoded_ratings.columns:\n",
    "    print(f'{col}: {sorted(encoded_ratings[col].drop(col).sort_values(ascending=True).head(3).index.values)}')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
