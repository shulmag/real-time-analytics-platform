{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9089ae53-5e6a-46ba-a9c0-a3df8c3a83e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reviewing Charles' Work [here](https://github.com/Ficc-ai/ficc/blob/ficc_ml/ml_models/sequence_predictors/history_20230419.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "A few things to explore: \n",
    "1. Why is diff_ys the better label \n",
    "2. Paired t-test for model testing \n",
    "3. Custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58de4fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 16:32:35.640275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 16:32:35.742960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 16:32:35.744720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pandarallel with 16.0 cores\n",
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "TF Version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "\n",
    "\n",
    "from ficc.utils.nelson_siegel_model import *\n",
    "from ficc.utils.diff_in_days import *\n",
    "from ficc.utils.auxiliary_functions import sqltodf\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "\n",
    "\n",
    "from ficc.data.process_data import process_data\n",
    "from ficc.utils.auxiliary_variables import PREDICTORS, NON_CAT_FEATURES, BINARY, CATEGORICAL_FEATURES, IDENTIFIERS, PURPOSE_CLASS_DICT, NUM_OF_DAYS_IN_YEAR\n",
    "from ficc.utils.gcp_storage_functions import upload_data, download_data\n",
    "from ficc.utils.auxiliary_variables import RELATED_TRADE_BINARY_FEATURES, RELATED_TRADE_NON_CAT_FEATURES, RELATED_TRADE_CATEGORICAL_FEATURES\n",
    "\n",
    "from ficc_keras_utils import *\n",
    "import ficc_keras_utils\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "print(f'TF Version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c11246",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/ficc/isaac_creds.json\"\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "storage_client = storage.Client()\n",
    "\n",
    "##COMMON VARIABLES\n",
    "#DATA WINDOW\n",
    "train_start = ficc_keras_utils.train_start\n",
    "train_end = ficc_keras_utils.train_end\n",
    "test_start = ficc_keras_utils.test_start\n",
    "test_end = ficc_keras_utils.test_end\n",
    "#MODEL PARAMETERS \n",
    "VALIDATION_SPLIT = ficc_keras_utils.VALIDATION_SPLIT\n",
    "LEARNING_RATE = ficc_keras_utils.LEARNING_RATE\n",
    "BATCH_SIZE = ficc_keras_utils.BATCH_SIZE\n",
    "NUM_EPOCHS = ficc_keras_utils.NUM_EPOCHS\n",
    "DROPOUT = ficc_keras_utils.DROPOUT\n",
    "\n",
    "##NOTEBOOK SPECIFIC VARIABLES \n",
    "TRADE_SEQUENCE_LENGTH = 5\n",
    "YIELD_SEQUENCE_LENGTH = 12\n",
    "NUM_FEATURES = 6\n",
    "# target_variable = 'new_ys_diff'\n",
    "target_variable = 'new_ys'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8a90a-c634-4424-9acf-4ea0238c6a49",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade4ed4f-d47d-4c65-9038-9d2f85c81a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ficc_keras_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685f0c18-06c4-4c79-9e43-059a1e0ea55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not available, downloading from cloud storage and saving to processed_file_FULL_2023-05-03-17:08_extended.pkl\n",
      "isaac_data/processed_file_FULL_2023-05-03-17:08_extended.pkl\n",
      "CPU times: user 12min 27s, sys: 58.6 s, total: 13min 25s\n",
      "Wall time: 24min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path = 'processed_file_FULL_2023-05-03-17:08_extended.pkl' #'processed_file_FULL_2023-05-03-17:08.pkl'#'../processed_file_FULL_2023-04-12-20:44.pkl'\n",
    "data = load_data_from_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afabed04-a496-434e-910d-5971913abd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_ys'] = data['yield'] - data['new_ficc_ycl']\n",
    "data['new_ys_realtime'] = data['yield'] - data['new_real_time_ficc_ycl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016f225c-d7a6-4a27-834b-00a6a68c2e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2023-04-28 00:00:00'), Timestamp('2022-09-01 00:00:00'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.trade_date.max(), data.trade_date.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ab397-2c54-4cdd-b741-669bf056a8c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testing Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37a71950",
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_features = ['dollar_price',\n",
    "                      'last_calc_date',\n",
    "                     'calc_date', \n",
    "                     'trade_date',\n",
    "                      'last_trade_date',\n",
    "                     'trade_datetime', \n",
    "                     'purpose_sub_class', \n",
    "                     'called_redemption_type', \n",
    "                     'calc_day_cat',\n",
    "                     'yield',\n",
    "                     'ficc_ycl',\n",
    "                     #'same_ys',\n",
    "                     #'trade_history_sum',\n",
    "                     'new_ficc_ycl',\n",
    "                      'new_real_time_ficc_ycl',\n",
    "                     'days_to_refund',\n",
    "                      'last_dollar_price',\n",
    "                      'last_rtrs_control_number',\n",
    "                     'is_called',\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2476c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'target_attention_features' not in PREDICTORS:\n",
    "    PREDICTORS.append('target_attention_features')\n",
    "    \n",
    "if 'ficc_treasury_spread' not in PREDICTORS:\n",
    "    PREDICTORS.append('ficc_treasury_spread')\n",
    "    NON_CAT_FEATURES.append('ficc_treasury_spread')\n",
    "    \n",
    "for col in ['new_ficc_ycl', 'new_real_time_ficc_ycl']:     \n",
    "    if col not in PREDICTORS:\n",
    "        PREDICTORS.append(col)\n",
    "        NON_CAT_FEATURES.append(col)\n",
    "\n",
    "# for col in ['extraordinary_make_whole_call', 'make_whole_call', 'has_unexpired_lines_of_credit']:     \n",
    "#     if col not in data.columns:\n",
    "#         try: \n",
    "#             print(f'Removing {col} from PREDICTORS and BINARY')\n",
    "#             BINARY.remove(col)\n",
    "#             PREDICTORS.remove(col) \n",
    "#         except:\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e97d1342-f725-45f2-8121-3ba449966606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data): \n",
    "    data['ted-rate'] = (data['t_rate_10'] - data['t_rate_2']) * 100\n",
    "    \n",
    "    # Here is a list of exclusions that we will be experimenting with. The model is trained with these exclusions. These exclusions were discussed with a team member.\n",
    "    # Callable less than a year in the future\n",
    "    # Maturity less than a year in the future and more than 30 years in the future\n",
    "    \n",
    "    data = data[(data.days_to_call == 0) | (data.days_to_call > np.log10(400))]\n",
    "    data = data[(data.days_to_refund == 0) | (data.days_to_refund > np.log10(400))]\n",
    "    data = data[(data.days_to_maturity == 0) | (data.days_to_maturity > np.log10(400))]\n",
    "    data = data[data.days_to_maturity < np.log10(30000)]\n",
    "    data['trade_history_sum'] = data.trade_history.parallel_apply(lambda x: np.sum(x))\n",
    "    data.issue_amount = data.issue_amount.replace([np.inf, -np.inf], np.nan)\n",
    "    data.dropna(inplace=True, subset=PREDICTORS+['trade_history_sum'])\n",
    "    data.purpose_sub_class.fillna(0, inplace=True)\n",
    "    \n",
    "    # data['calc_date_duration'] = data[['last_calc_date','last_trade_date']].parallel_apply(get_calc_date_duration, axis=1)\n",
    "    # data['new_ficc_ycl_fixed_shape'] = data[['trade_date', 'calc_date_duration']].parallel_apply(lambda x: calculate_ycl(x, new_yc_params), axis = 1)\n",
    "    # data['new_ficc_ycl_prev_day'] = data[['last_calc_date', 'last_trade_date' ,'calc_date_duration','trade_date']].parallel_apply(get_yield_for_last_duration, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bfbe065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.4 s, sys: 26.4 s, total: 1min 25s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data = process_data(data) \n",
    "# processed_data = processed_data[IDENTIFIERS + PREDICTORS + auxiliary_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7bfa9c6-4b3b-431c-8f18-af60d271985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.drop(51570)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce15e2af-738a-41b6-9776-64e804c638b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66d92939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "incorporated_state_code\n",
      "trade_type\n",
      "purpose_class\n"
     ]
    }
   ],
   "source": [
    "encoders = {}\n",
    "fmax = {}\n",
    "for f in CATEGORICAL_FEATURES:\n",
    "    print(f)\n",
    "    fprep = preprocessing.LabelEncoder().fit(processed_data[f].drop_duplicates()) #note that there are apparently no trades with CC \n",
    "    fmax[f] = np.max(fprep.transform(fprep.classes_))\n",
    "    encoders[f] = fprep\n",
    "    \n",
    "with open('encoders.pkl','wb') as file:\n",
    "    pickle.dump(encoders,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cde1120-b422-410b-b128-ce88743ea5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# processed_data['yield_curve_history_sq'] = processed_data['yield_curve_history'].parallel_apply(lambda x: np.stack((x, np.square(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d05e1f5d-1b2a-40ef-98e4-abe37068cecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yield_curve_history_5min_12', 'yield_curve_history_1min_20',\n",
       "       'yield_curve_history_30min_5', 'yield_curve_history_30min_5_averaged',\n",
       "       'yield_curve_history_1min_20_averaged',\n",
       "       'yield_curve_history_5min_12_averaged'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.filter(regex='yield_curve').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8e9cb49-8e29-46da-baef-b009a27580d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.57 s, sys: 123 ms, total: 2.69 s\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['yield_curve_history_5min_12_averaged_fixed'] = processed_data['yield_curve_history_5min_12_averaged'].apply(lambda x: x[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f3e04f-f113-4c86-843c-c52c588ac3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.51 s, sys: 146 ms, total: 3.66 s\n",
      "Wall time: 3.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_data['trade_history_fixed'] = processed_data['trade_history'].apply(lambda x: x[::-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9daf580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data start: 2022-11-01 00:00:00, end: 2023-02-28 00:00:00\n",
      "Test data start: 2023-03-01 00:00:00, end: 2023-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_filter = (processed_data.trade_date < train_end) & (processed_data.trade_date >= train_start)\n",
    "test_filter = (processed_data.trade_date >= test_start) & (processed_data.trade_date <test_end)\n",
    "                                                            \n",
    "train_dataframe = processed_data[train_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "test_dataframe = processed_data[test_filter]\\\n",
    ".sort_values(by='trade_date', ascending=True)\\\n",
    ".reset_index(drop=True)\n",
    "\n",
    "print('Training data start: {}, end: {}'.format(train_dataframe.trade_date.min(),train_dataframe.trade_date.max()))\n",
    "print('Test data start: {}, end: {}'.format(test_dataframe.trade_date.min(),test_dataframe.trade_date.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1e5fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(df):\n",
    "    global encoders\n",
    "    datalist = []\n",
    "    # datalist.append(np.stack(df['yield_curve_history_sq'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['yield_curve_history'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['yield_curve_history_fixed'].to_numpy()))\n",
    "    datalist.append(np.stack(df['yield_curve_history_5min_12_averaged_fixed'].to_numpy()))\n",
    "    # datalist.append(np.stack(df['trade_history'].to_numpy()))\n",
    "    datalist.append(np.stack(df['trade_history_fixed'].to_numpy()))\n",
    "    datalist.append(np.stack(df['target_attention_features'].to_numpy()))\n",
    "\n",
    "    noncat_and_binary = []\n",
    "    for f in NON_CAT_FEATURES + BINARY:\n",
    "        noncat_and_binary.append(np.expand_dims(df[f].to_numpy().astype('float32'), axis=1))\n",
    "    datalist.append(np.concatenate(noncat_and_binary, axis=-1))\n",
    "    \n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        encoded = encoders[f].transform(df[f])\n",
    "        datalist.append(encoded.astype('float32'))\n",
    "    \n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2b65617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA: N = 2600040, MIN DATE = 2022-11-01 00:00:00, MAX DATE = 2023-02-28 00:00:00\n",
      "VALIDATION DATA: N = 650010, MIN DATE = 2022-11-01 00:00:00, MAX DATE = 2023-02-28 00:00:00\n",
      "TEST DATA: N = 708432, MIN DATE = 2023-03-01 00:00:00, MAX DATE = 2023-03-31 00:00:00\n",
      "CPU times: user 40.7 s, sys: 2.55 s, total: 43.2 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "val_idx = np.random.choice(range(len(train_dataframe)), \n",
    "                 size = int(VALIDATION_SPLIT*len(train_dataframe)),\n",
    "                 replace=False)\n",
    "\n",
    "print(f'TRAINING DATA: N = {len(train_dataframe)-len(val_idx)}, MIN DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.min()}, MAX DATE = {train_dataframe.drop(val_idx, axis=0).trade_date.max()}')\n",
    "print(f'VALIDATION DATA: N = {len(val_idx)}, MIN DATE = {train_dataframe.iloc[val_idx].trade_date.min()}, MAX DATE = {train_dataframe.iloc[val_idx].trade_date.max()}')\n",
    "print(f'TEST DATA: N = {len(test_dataframe)}, MIN DATE = {test_dataframe.trade_date.min()}, MAX DATE = {test_dataframe.trade_date.max()}')\n",
    "\n",
    "x_train = create_input(train_dataframe.drop(val_idx, axis=0))\n",
    "y_train = train_dataframe.drop(val_idx, axis=0)[target_variable]\n",
    "\n",
    "x_val = create_input(train_dataframe.iloc[val_idx])\n",
    "y_val = train_dataframe.iloc[val_idx][target_variable]\n",
    "\n",
    "x_test = create_input(test_dataframe)\n",
    "y_test = test_dataframe[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6aa16",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cdb94f2-09a4-4c7f-8a07-b3fbac7a14d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 17:22:57.898258: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 17:22:57.902560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 17:22:57.906173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 17:22:57.908866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 17:22:58.591266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 17:22:58.592979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 17:22:58.594393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-11 17:22:58.595835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13594 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Normalization layer for the yield history\n",
    "yield_history_normalizer = Normalization(name='Yield_history_normalizer')\n",
    "yield_history_normalizer.adapt(x_train[0],batch_size=BATCH_SIZE)\n",
    "\n",
    "# Normalization layer for the trade history\n",
    "trade_history_normalizer = Normalization(name='Trade_history_normalizer')\n",
    "trade_history_normalizer.adapt(x_train[1],batch_size=BATCH_SIZE)\n",
    "\n",
    "# Normalization layer for the non-categorical and binary features\n",
    "noncat_binary_normalizer = Normalization(name='Numerical_binary_normalizer')\n",
    "noncat_binary_normalizer.adapt(x_train[3], batch_size = BATCH_SIZE)\n",
    "\n",
    "tf.keras.utils.set_random_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "63d9d0d8-e8ee-4f99-9788-98bd4c43ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "def generate_model(TRADE_SEQUENCE_LENGTH = 5, YIELD_SEQUENCE_LENGTH = 12, NUM_FEATURES = NUM_FEATURES, trade_history_normalizer = trade_history_normalizer):\n",
    "    inputs = []\n",
    "    layer = []\n",
    "\n",
    "    ############## INPUT BLOCK ###################\n",
    "    yield_history_input = layers.Input(name=\"yield_curve_history_input\", \n",
    "                                       # shape=(2, YIELD_SEQUENCE_LENGTH),\n",
    "                                       shape=(YIELD_SEQUENCE_LENGTH, 1), \n",
    "                                       dtype = tf.float32) \n",
    "    \n",
    "    trade_history_input = layers.Input(name=\"trade_history_input\", \n",
    "                                       shape=(TRADE_SEQUENCE_LENGTH,NUM_FEATURES), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    target_attention_input = layers.Input(name=\"target_attention_input\", \n",
    "                                       shape=(SEQUENCE_LENGTH, 3), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    inputs.append(yield_history_input)\n",
    "    inputs.append(trade_history_input)\n",
    "    inputs.append(target_attention_input)\n",
    "\n",
    "    inputs.append(layers.Input(\n",
    "        name=\"NON_CAT_AND_BINARY_FEATURES\",\n",
    "        shape=(len(NON_CAT_FEATURES + BINARY),)\n",
    "    ))\n",
    "\n",
    "\n",
    "    layer.append(noncat_binary_normalizer(inputs[3]))\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    ############## TRADE HISTORY MODEL #################\n",
    "\n",
    "    lstm_layer = layers.LSTM(50, \n",
    "                             activation='tanh',\n",
    "                             input_shape=(SEQUENCE_LENGTH,NUM_FEATURES),\n",
    "                             return_sequences = True,\n",
    "                             name='TRADE_HISTORY_LSTM')\n",
    "\n",
    "    lstm_attention_layer = CustomAttention(50)\n",
    "\n",
    "    lstm_layer_2 = layers.LSTM(100, \n",
    "                               activation='tanh',\n",
    "                               input_shape=(SEQUENCE_LENGTH,50),\n",
    "                               return_sequences = False,\n",
    "                               name='TRADE_HISTORY_LSTM_2')\n",
    "\n",
    "\n",
    "    features = lstm_layer(trade_history_normalizer(inputs[1]))\n",
    "    features = lstm_attention_layer(features, features, inputs[2])\n",
    "    features = layers.BatchNormalization()(features)\n",
    "    # features = layers.Dropout(DROPOUT)(features)\n",
    "\n",
    "    features = lstm_layer_2(features)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "    # features = layers.Dropout(DROPOUT)(features)\n",
    "\n",
    "    trade_history_output = layers.Dense(100, \n",
    "                                        activation='relu')(features)\n",
    "\n",
    "    ####################################################\n",
    "    \n",
    "    ############## YIELD HISTORY MODEL #################\n",
    "\n",
    "    yield_lstm_layer = layers.LSTM(50, \n",
    "                             activation='tanh',\n",
    "                             input_shape=(1, SEQUENCE_LENGTH),\n",
    "                             return_sequences = False,\n",
    "                             name='Yield_History_LSTM')\n",
    "\n",
    "   \n",
    "    # constant = tf.keras.layers.Lambda(lambda x:x+tf.constant(np.random.rand(12).astype('float32')))(inputs[0]) \n",
    "    # yield_features = tf.keras.layers.Add()([inputs[0], constant])\n",
    "    yield_features = yield_lstm_layer(yield_history_normalizer(inputs[0]))\n",
    "    # yield_features = yield_lstm_layer(yield_features) #yield_lstm_layer(yield_history_normalizer(inputs[0]))\n",
    "    yield_features = layers.Dense(25, activation='relu')(yield_features)\n",
    "    # yield_history_output = layers.LeakyReLU(alpha = 0.05)(yield_features)\n",
    "\n",
    "    yield_history_output =  layers.BatchNormalization()(yield_features)\n",
    "    ####################################################\n",
    "\n",
    "    ############## REFERENCE DATA MODEL ################\n",
    "    global encoders\n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        fin = layers.Input(shape=(1,), name = f)\n",
    "        inputs.append(fin)\n",
    "        embedded = layers.Flatten(name = f + \"_flat\")( layers.Embedding(input_dim = fmax[f]+1,\n",
    "                                                                        output_dim = max(30,int(np.sqrt(fmax[f]))),\n",
    "                                                                        input_length= 1,\n",
    "                                                                        name = f + \"_embed\")(fin))\n",
    "        layer.append(embedded)\n",
    "\n",
    "\n",
    "    reference_hidden = layers.Dense(400,\n",
    "                                    activation='relu',\n",
    "                                    name='reference_hidden_1')(layers.concatenate(layer, axis=-1))\n",
    "\n",
    "    reference_hidden = layers.BatchNormalization()(reference_hidden)\n",
    "    reference_hidden = layers.Dropout(DROPOUT)(reference_hidden)\n",
    "\n",
    "    reference_hidden2 = layers.Dense(200,activation='relu',name='reference_hidden_2')(reference_hidden)\n",
    "    reference_hidden2 = layers.BatchNormalization()(reference_hidden2)\n",
    "    reference_hidden2 = layers.Dropout(DROPOUT)(reference_hidden2)\n",
    "\n",
    "    reference_output = layers.Dense(100,activation='tanh',name='reference_hidden_3')(reference_hidden2)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    feed_forward_input = layers.concatenate([yield_history_output, reference_output, trade_history_output])\n",
    "\n",
    "    hidden = layers.Dense(300,activation='relu')(feed_forward_input)\n",
    "    hidden = layers.BatchNormalization()(hidden)\n",
    "    hidden = layers.Dropout(DROPOUT)(hidden)\n",
    "\n",
    "    hidden2 = layers.Dense(100,activation='tanh')(hidden)\n",
    "    hidden2 = layers.BatchNormalization()(hidden2)\n",
    "    hidden2 = layers.Dropout(DROPOUT)(hidden2)\n",
    "    \n",
    "#     hidden = layers.Dense(300, activation=)(feed_forward_input)\n",
    "#     hidden = layers.LeakyReLU(alpha=0.05)(hidden)\n",
    "#     hidden = layers.BatchNormalization()(hidden)\n",
    "#     hidden = layers.Dropout(DROPOUT)(hidden)\n",
    "\n",
    "#     hidden2 = layers.Dense(100)(hidden)\n",
    "#     hidden2 = layers.LeakyReLU(alpha=0.05)(hidden2)\n",
    "#     hidden2 = layers.BatchNormalization()(hidden2)\n",
    "#     hidden2 = layers.Dropout(DROPOUT)(hidden2)\n",
    "\n",
    "    final = layers.Dense(1)(hidden2)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=final)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_tf_data(x_train, y_train, shuffle=False, shuffle_buffer=1):\n",
    "                     \n",
    "    X=()\n",
    "    for x in x_train:\n",
    "        X += (tf.data.Dataset.from_tensor_slices(x),)\n",
    "        \n",
    "\n",
    "    temp = tf.data.Dataset.zip((X))\n",
    "    del X\n",
    "    dataset = tf.data.Dataset.zip((temp,\n",
    "                        tf.data.Dataset.from_tensor_slices(y_train)))\n",
    "    del temp\n",
    "    if shuffle:\n",
    "        shuffle_buffer = int(len(x_train[0])*shuffle_buffer)\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2c7eea81-0c51-4ac7-bb58-4aef23343c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_val, y_val, shuffle, shuffle_buffer=1):\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H-%M')\n",
    "    \n",
    "    fit_callbacks = fit_callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True),\n",
    "        # time_callback,\n",
    "        CSVLoggerTimeHistory(timestamp+'_training_logs_yield_history.csv', separator=\",\", append=False)]\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        train_ds = create_tf_data(x_train, y_train, shuffle, shuffle_buffer)\n",
    "        train_ds = train_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "        val_ds = create_tf_data(x_val, y_val, shuffle = False)\n",
    "        val_ds = val_ds.batch(BATCH_SIZE).prefetch(2).cache()\n",
    "\n",
    "    model_new_ys = generate_model(TRADE_SEQUENCE_LENGTH=TRADE_SEQUENCE_LENGTH,\n",
    "                                  YIELD_SEQUENCE_LENGTH=YIELD_SEQUENCE_LENGTH,\n",
    "                                  NUM_FEATURES=6, \n",
    "                                  trade_history_normalizer = trade_history_normalizer)\n",
    "    \n",
    "    model_new_ys.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "          loss=keras.losses.MeanAbsoluteError(),\n",
    "          metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history_new_ys = model_new_ys.fit(train_ds,\n",
    "                                      validation_data=val_ds,\n",
    "                                        epochs=NUM_EPOCHS,     \n",
    "                                        verbose=1, \n",
    "                                        callbacks=fit_callbacks,\n",
    "                                        use_multiprocessing=True,\n",
    "                                        workers=8)\n",
    "    \n",
    "    return history_new_ys, model_new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e1cb2-1368-496c-a0c2-2f2a4bc26b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:50:54.708102: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 859703 of 1950030\n",
      "2023-05-10 21:51:04.708107: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 1606317 of 1950030\n",
      "2023-05-10 21:51:10.619188: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540/2540 [==============================] - 102s 27ms/step - loss: 17.0318 - mean_absolute_error: 17.0318 - val_loss: 10.7192 - val_mean_absolute_error: 10.7192\n",
      "Epoch 2/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 11.0121 - mean_absolute_error: 11.0121 - val_loss: 10.4007 - val_mean_absolute_error: 10.4007\n",
      "Epoch 3/100\n",
      "2540/2540 [==============================] - 46s 18ms/step - loss: 10.7433 - mean_absolute_error: 10.7433 - val_loss: 10.5005 - val_mean_absolute_error: 10.5005\n",
      "Epoch 4/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 10.5510 - mean_absolute_error: 10.5510 - val_loss: 9.8806 - val_mean_absolute_error: 9.8806\n",
      "Epoch 5/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.4192 - mean_absolute_error: 10.4192 - val_loss: 9.9585 - val_mean_absolute_error: 9.9585\n",
      "Epoch 6/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 10.3235 - mean_absolute_error: 10.3235 - val_loss: 9.6601 - val_mean_absolute_error: 9.6601\n",
      "Epoch 7/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.2321 - mean_absolute_error: 10.2321 - val_loss: 9.4876 - val_mean_absolute_error: 9.4876\n",
      "Epoch 8/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 10.1642 - mean_absolute_error: 10.1642 - val_loss: 9.5278 - val_mean_absolute_error: 9.5278\n",
      "Epoch 9/100\n",
      "2540/2540 [==============================] - 44s 18ms/step - loss: 10.1065 - mean_absolute_error: 10.1065 - val_loss: 9.5433 - val_mean_absolute_error: 9.5433\n",
      "Epoch 10/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.0385 - mean_absolute_error: 10.0385 - val_loss: 9.5403 - val_mean_absolute_error: 9.5403\n",
      "Epoch 11/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.9903 - mean_absolute_error: 9.9903 - val_loss: 9.2989 - val_mean_absolute_error: 9.2989\n",
      "Epoch 12/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.9545 - mean_absolute_error: 9.9545 - val_loss: 9.3202 - val_mean_absolute_error: 9.3202\n",
      "Epoch 13/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.9002 - mean_absolute_error: 9.9002 - val_loss: 9.4222 - val_mean_absolute_error: 9.4222\n",
      "Epoch 14/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.8487 - mean_absolute_error: 9.8487 - val_loss: 9.5877 - val_mean_absolute_error: 9.5877\n",
      "Epoch 15/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.8174 - mean_absolute_error: 9.8174 - val_loss: 9.4982 - val_mean_absolute_error: 9.4982\n",
      "Epoch 16/100\n",
      "2540/2540 [==============================] - 52s 20ms/step - loss: 9.7887 - mean_absolute_error: 9.7887 - val_loss: 9.3315 - val_mean_absolute_error: 9.3315\n",
      "Epoch 17/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.7466 - mean_absolute_error: 9.7466 - val_loss: 9.1059 - val_mean_absolute_error: 9.1059\n",
      "Epoch 18/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.7141 - mean_absolute_error: 9.7141 - val_loss: 9.1556 - val_mean_absolute_error: 9.1556\n",
      "Epoch 19/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.6814 - mean_absolute_error: 9.6814 - val_loss: 9.2829 - val_mean_absolute_error: 9.2829\n",
      "Epoch 20/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.6587 - mean_absolute_error: 9.6587 - val_loss: 9.1411 - val_mean_absolute_error: 9.1411\n",
      "Epoch 21/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.6460 - mean_absolute_error: 9.6460 - val_loss: 9.1630 - val_mean_absolute_error: 9.1630\n",
      "Epoch 22/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.6035 - mean_absolute_error: 9.6035 - val_loss: 9.0784 - val_mean_absolute_error: 9.0784\n",
      "Epoch 23/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.6125 - mean_absolute_error: 9.6125 - val_loss: 9.2802 - val_mean_absolute_error: 9.2802\n",
      "Epoch 24/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5660 - mean_absolute_error: 9.5660 - val_loss: 9.1183 - val_mean_absolute_error: 9.1183\n",
      "Epoch 25/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5559 - mean_absolute_error: 9.5559 - val_loss: 9.3334 - val_mean_absolute_error: 9.3334\n",
      "Epoch 26/100\n",
      "2540/2540 [==============================] - 47s 18ms/step - loss: 9.5337 - mean_absolute_error: 9.5337 - val_loss: 10.7069 - val_mean_absolute_error: 10.7069\n",
      "Epoch 27/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5175 - mean_absolute_error: 9.5175 - val_loss: 9.2784 - val_mean_absolute_error: 9.2784\n",
      "Epoch 28/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5035 - mean_absolute_error: 9.5035 - val_loss: 8.9961 - val_mean_absolute_error: 8.9961\n",
      "Epoch 29/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.4797 - mean_absolute_error: 9.4797 - val_loss: 9.0463 - val_mean_absolute_error: 9.0463\n",
      "Epoch 30/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.4769 - mean_absolute_error: 9.4769 - val_loss: 8.9130 - val_mean_absolute_error: 8.9130\n",
      "Epoch 31/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.4416 - mean_absolute_error: 9.4416 - val_loss: 8.9096 - val_mean_absolute_error: 8.9096\n",
      "Epoch 32/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4258 - mean_absolute_error: 9.4258 - val_loss: 8.9985 - val_mean_absolute_error: 8.9985\n",
      "Epoch 33/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4076 - mean_absolute_error: 9.4076 - val_loss: 9.0500 - val_mean_absolute_error: 9.0500\n",
      "Epoch 34/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4075 - mean_absolute_error: 9.4075 - val_loss: 8.9008 - val_mean_absolute_error: 8.9008\n",
      "Epoch 35/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.3832 - mean_absolute_error: 9.3832 - val_loss: 9.3201 - val_mean_absolute_error: 9.3201\n",
      "Epoch 36/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.3802 - mean_absolute_error: 9.3802 - val_loss: 9.4818 - val_mean_absolute_error: 9.4818\n",
      "Epoch 37/100\n",
      "2540/2540 [==============================] - 47s 18ms/step - loss: 9.3543 - mean_absolute_error: 9.3543 - val_loss: 9.4530 - val_mean_absolute_error: 9.4530\n",
      "Epoch 38/100\n",
      "2540/2540 [==============================] - 41s 16ms/step - loss: 9.3340 - mean_absolute_error: 9.3340 - val_loss: 9.1722 - val_mean_absolute_error: 9.1722\n",
      "Epoch 39/100\n",
      "2540/2540 [==============================] - 48s 19ms/step - loss: 9.3188 - mean_absolute_error: 9.3188 - val_loss: 9.0828 - val_mean_absolute_error: 9.0828\n",
      "Epoch 40/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.3175 - mean_absolute_error: 9.3175 - val_loss: 8.9468 - val_mean_absolute_error: 8.9468\n",
      "Epoch 41/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.3003 - mean_absolute_error: 9.3003 - val_loss: 8.9347 - val_mean_absolute_error: 8.9347\n",
      "Epoch 42/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.2869 - mean_absolute_error: 9.2869 - val_loss: 8.9547 - val_mean_absolute_error: 8.9547\n",
      "Epoch 43/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.2671 - mean_absolute_error: 9.2671 - val_loss: 9.1972 - val_mean_absolute_error: 9.1972\n",
      "Epoch 44/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.2680 - mean_absolute_error: 9.2680 - val_loss: 8.9560 - val_mean_absolute_error: 8.9560\n",
      "Model training time was 36.66 minutes (2199.71 seconds).\n",
      "Average time for each epoch was 0.37 minutes (22.00 seconds).\n",
      "========================= TRIAL 0, MAE: 9.727299753801523 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:31:04.613791: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 754782 of 1950030\n",
      "2023-05-10 22:31:14.613747: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 1454351 of 1950030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2540 [..............................] - ETA: 22:10:02 - loss: 56.7734 - mean_absolute_error: 56.7734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:31:20.230682: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540/2540 [==============================] - 102s 28ms/step - loss: 16.9290 - mean_absolute_error: 16.9290 - val_loss: 10.6959 - val_mean_absolute_error: 10.6959\n",
      "Epoch 2/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 11.0208 - mean_absolute_error: 11.0208 - val_loss: 10.4035 - val_mean_absolute_error: 10.4035\n",
      "Epoch 3/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.7540 - mean_absolute_error: 10.7540 - val_loss: 10.1139 - val_mean_absolute_error: 10.1139\n",
      "Epoch 4/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 10.5633 - mean_absolute_error: 10.5633 - val_loss: 10.0646 - val_mean_absolute_error: 10.0646\n",
      "Epoch 5/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 10.4260 - mean_absolute_error: 10.4260 - val_loss: 9.7275 - val_mean_absolute_error: 9.7275\n",
      "Epoch 6/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.3037 - mean_absolute_error: 10.3037 - val_loss: 9.8584 - val_mean_absolute_error: 9.8584\n",
      "Epoch 7/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.2190 - mean_absolute_error: 10.2190 - val_loss: 10.6157 - val_mean_absolute_error: 10.6157\n",
      "Epoch 8/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 10.1367 - mean_absolute_error: 10.1367 - val_loss: 9.6957 - val_mean_absolute_error: 9.6957\n",
      "Epoch 9/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.0820 - mean_absolute_error: 10.0820 - val_loss: 9.5198 - val_mean_absolute_error: 9.5198\n",
      "Epoch 10/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 10.0243 - mean_absolute_error: 10.0243 - val_loss: 9.3819 - val_mean_absolute_error: 9.3819\n",
      "Epoch 11/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.9619 - mean_absolute_error: 9.9619 - val_loss: 9.3768 - val_mean_absolute_error: 9.3768\n",
      "Epoch 12/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.9342 - mean_absolute_error: 9.9342 - val_loss: 9.3895 - val_mean_absolute_error: 9.3895\n",
      "Epoch 13/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.8859 - mean_absolute_error: 9.8859 - val_loss: 9.3626 - val_mean_absolute_error: 9.3626\n",
      "Epoch 14/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.8392 - mean_absolute_error: 9.8392 - val_loss: 9.4856 - val_mean_absolute_error: 9.4856\n",
      "Epoch 15/100\n",
      "2540/2540 [==============================] - 46s 18ms/step - loss: 9.8121 - mean_absolute_error: 9.8121 - val_loss: 9.4081 - val_mean_absolute_error: 9.4081\n",
      "Epoch 16/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.7640 - mean_absolute_error: 9.7640 - val_loss: 9.1955 - val_mean_absolute_error: 9.1955\n",
      "Epoch 17/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.7344 - mean_absolute_error: 9.7344 - val_loss: 9.2389 - val_mean_absolute_error: 9.2389\n",
      "Epoch 18/100\n",
      "2540/2540 [==============================] - 52s 20ms/step - loss: 9.7196 - mean_absolute_error: 9.7196 - val_loss: 9.2100 - val_mean_absolute_error: 9.2100\n",
      "Epoch 19/100\n",
      "2540/2540 [==============================] - 50s 19ms/step - loss: 9.6885 - mean_absolute_error: 9.6885 - val_loss: 9.1737 - val_mean_absolute_error: 9.1737\n",
      "Epoch 20/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.6698 - mean_absolute_error: 9.6698 - val_loss: 9.1871 - val_mean_absolute_error: 9.1871\n",
      "Epoch 21/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.6314 - mean_absolute_error: 9.6314 - val_loss: 9.7028 - val_mean_absolute_error: 9.7028\n",
      "Epoch 22/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.6131 - mean_absolute_error: 9.6131 - val_loss: 9.5587 - val_mean_absolute_error: 9.5587\n",
      "Epoch 23/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5841 - mean_absolute_error: 9.5841 - val_loss: 9.2080 - val_mean_absolute_error: 9.2080\n",
      "Epoch 24/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5727 - mean_absolute_error: 9.5727 - val_loss: 9.7606 - val_mean_absolute_error: 9.7606\n",
      "Epoch 25/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5428 - mean_absolute_error: 9.5428 - val_loss: 9.3717 - val_mean_absolute_error: 9.3717\n",
      "Epoch 26/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.5297 - mean_absolute_error: 9.5297 - val_loss: 9.6720 - val_mean_absolute_error: 9.6720\n",
      "Epoch 27/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.5226 - mean_absolute_error: 9.5226 - val_loss: 9.1453 - val_mean_absolute_error: 9.1453\n",
      "Epoch 28/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.4948 - mean_absolute_error: 9.4948 - val_loss: 9.7077 - val_mean_absolute_error: 9.7077\n",
      "Epoch 29/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4830 - mean_absolute_error: 9.4830 - val_loss: 9.1905 - val_mean_absolute_error: 9.1905\n",
      "Epoch 30/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4598 - mean_absolute_error: 9.4598 - val_loss: 9.7729 - val_mean_absolute_error: 9.7729\n",
      "Epoch 31/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4418 - mean_absolute_error: 9.4418 - val_loss: 8.9694 - val_mean_absolute_error: 8.9694\n",
      "Epoch 32/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4185 - mean_absolute_error: 9.4185 - val_loss: 9.3381 - val_mean_absolute_error: 9.3381\n",
      "Epoch 33/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.4199 - mean_absolute_error: 9.4199 - val_loss: 9.1663 - val_mean_absolute_error: 9.1663\n",
      "Epoch 34/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.3846 - mean_absolute_error: 9.3846 - val_loss: 8.9070 - val_mean_absolute_error: 8.9070\n",
      "Epoch 35/100\n",
      "2540/2540 [==============================] - 48s 19ms/step - loss: 9.3771 - mean_absolute_error: 9.3771 - val_loss: 9.7103 - val_mean_absolute_error: 9.7103\n",
      "Epoch 36/100\n",
      "2540/2540 [==============================] - 46s 18ms/step - loss: 9.3593 - mean_absolute_error: 9.3593 - val_loss: 9.1455 - val_mean_absolute_error: 9.1455\n",
      "Epoch 37/100\n",
      "2540/2540 [==============================] - 46s 18ms/step - loss: 9.3509 - mean_absolute_error: 9.3509 - val_loss: 8.9446 - val_mean_absolute_error: 8.9446\n",
      "Epoch 38/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.3390 - mean_absolute_error: 9.3390 - val_loss: 9.0926 - val_mean_absolute_error: 9.0926\n",
      "Epoch 39/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.3163 - mean_absolute_error: 9.3163 - val_loss: 8.9223 - val_mean_absolute_error: 8.9223\n",
      "Epoch 40/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.3083 - mean_absolute_error: 9.3083 - val_loss: 9.1458 - val_mean_absolute_error: 9.1458\n",
      "Epoch 41/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.2927 - mean_absolute_error: 9.2927 - val_loss: 8.8926 - val_mean_absolute_error: 8.8926\n",
      "Epoch 42/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.2857 - mean_absolute_error: 9.2857 - val_loss: 8.9935 - val_mean_absolute_error: 8.9935\n",
      "Epoch 43/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.2697 - mean_absolute_error: 9.2697 - val_loss: 8.9594 - val_mean_absolute_error: 8.9594\n",
      "Epoch 44/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.2682 - mean_absolute_error: 9.2682 - val_loss: 9.1453 - val_mean_absolute_error: 9.1453\n",
      "Epoch 45/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.2524 - mean_absolute_error: 9.2524 - val_loss: 8.9489 - val_mean_absolute_error: 8.9489\n",
      "Epoch 46/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.2405 - mean_absolute_error: 9.2405 - val_loss: 8.9275 - val_mean_absolute_error: 8.9275\n",
      "Epoch 47/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.2367 - mean_absolute_error: 9.2367 - val_loss: 9.1987 - val_mean_absolute_error: 9.1987\n",
      "Epoch 48/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.2172 - mean_absolute_error: 9.2172 - val_loss: 8.7899 - val_mean_absolute_error: 8.7899\n",
      "Epoch 49/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.2057 - mean_absolute_error: 9.2057 - val_loss: 9.0097 - val_mean_absolute_error: 9.0097\n",
      "Epoch 50/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.1940 - mean_absolute_error: 9.1940 - val_loss: 8.8553 - val_mean_absolute_error: 8.8553\n",
      "Epoch 51/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.1876 - mean_absolute_error: 9.1876 - val_loss: 8.8541 - val_mean_absolute_error: 8.8541\n",
      "Epoch 52/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.1734 - mean_absolute_error: 9.1734 - val_loss: 8.9988 - val_mean_absolute_error: 8.9988\n",
      "Epoch 53/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.1679 - mean_absolute_error: 9.1679 - val_loss: 9.0353 - val_mean_absolute_error: 9.0353\n",
      "Epoch 54/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.1531 - mean_absolute_error: 9.1531 - val_loss: 9.0636 - val_mean_absolute_error: 9.0636\n",
      "Epoch 55/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.1492 - mean_absolute_error: 9.1492 - val_loss: 8.7698 - val_mean_absolute_error: 8.7698\n",
      "Epoch 56/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.1404 - mean_absolute_error: 9.1404 - val_loss: 8.7971 - val_mean_absolute_error: 8.7971\n",
      "Epoch 57/100\n",
      "2540/2540 [==============================] - 52s 20ms/step - loss: 9.1244 - mean_absolute_error: 9.1244 - val_loss: 8.8985 - val_mean_absolute_error: 8.8985\n",
      "Epoch 58/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.1173 - mean_absolute_error: 9.1173 - val_loss: 9.0886 - val_mean_absolute_error: 9.0886\n",
      "Epoch 59/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.1098 - mean_absolute_error: 9.1098 - val_loss: 9.2517 - val_mean_absolute_error: 9.2517\n",
      "Epoch 60/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.0962 - mean_absolute_error: 9.0962 - val_loss: 8.8977 - val_mean_absolute_error: 8.8977\n",
      "Epoch 61/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.0831 - mean_absolute_error: 9.0831 - val_loss: 8.9765 - val_mean_absolute_error: 8.9765\n",
      "Epoch 62/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.0872 - mean_absolute_error: 9.0872 - val_loss: 9.0482 - val_mean_absolute_error: 9.0482\n",
      "Epoch 63/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.0716 - mean_absolute_error: 9.0716 - val_loss: 8.9259 - val_mean_absolute_error: 8.9259\n",
      "Epoch 64/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.0700 - mean_absolute_error: 9.0700 - val_loss: 8.7401 - val_mean_absolute_error: 8.7401\n",
      "Epoch 65/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.0622 - mean_absolute_error: 9.0622 - val_loss: 8.8167 - val_mean_absolute_error: 8.8167\n",
      "Epoch 66/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.0496 - mean_absolute_error: 9.0496 - val_loss: 8.8749 - val_mean_absolute_error: 8.8749\n",
      "Epoch 67/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.0402 - mean_absolute_error: 9.0402 - val_loss: 8.9379 - val_mean_absolute_error: 8.9379\n",
      "Epoch 68/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.0341 - mean_absolute_error: 9.0341 - val_loss: 8.8243 - val_mean_absolute_error: 8.8243\n",
      "Epoch 69/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.0322 - mean_absolute_error: 9.0322 - val_loss: 8.9369 - val_mean_absolute_error: 8.9369\n",
      "Epoch 70/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.0254 - mean_absolute_error: 9.0254 - val_loss: 8.9222 - val_mean_absolute_error: 8.9222\n",
      "Epoch 71/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.0154 - mean_absolute_error: 9.0154 - val_loss: 8.8314 - val_mean_absolute_error: 8.8314\n",
      "Epoch 72/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.0112 - mean_absolute_error: 9.0112 - val_loss: 8.8447 - val_mean_absolute_error: 8.8447\n",
      "Epoch 73/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.0022 - mean_absolute_error: 9.0022 - val_loss: 8.7451 - val_mean_absolute_error: 8.7451\n",
      "Epoch 74/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 8.9957 - mean_absolute_error: 8.9957 - val_loss: 8.9578 - val_mean_absolute_error: 8.9578\n",
      "Model training time was 61.11 minutes (3666.73 seconds).\n",
      "Average time for each epoch was 0.61 minutes (36.67 seconds).\n",
      "========================= TRIAL 1, MAE: 9.717669412464797 =========================\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 23:34:45.900586: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 822141 of 1950030\n",
      "2023-05-10 23:34:55.900567: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 1692162 of 1950030\n",
      "2023-05-10 23:34:58.841606: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540/2540 [==============================] - 103s 29ms/step - loss: 16.9041 - mean_absolute_error: 16.9041 - val_loss: 10.5899 - val_mean_absolute_error: 10.5899\n",
      "Epoch 2/100\n",
      "2540/2540 [==============================] - 41s 16ms/step - loss: 11.0437 - mean_absolute_error: 11.0437 - val_loss: 10.2778 - val_mean_absolute_error: 10.2778\n",
      "Epoch 3/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 10.7641 - mean_absolute_error: 10.7641 - val_loss: 10.1108 - val_mean_absolute_error: 10.1108\n",
      "Epoch 4/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.5758 - mean_absolute_error: 10.5758 - val_loss: 10.0413 - val_mean_absolute_error: 10.0413\n",
      "Epoch 5/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 10.4380 - mean_absolute_error: 10.4380 - val_loss: 9.9485 - val_mean_absolute_error: 9.9485\n",
      "Epoch 6/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 10.3327 - mean_absolute_error: 10.3327 - val_loss: 9.9326 - val_mean_absolute_error: 9.9326\n",
      "Epoch 7/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 10.2446 - mean_absolute_error: 10.2446 - val_loss: 11.8581 - val_mean_absolute_error: 11.8581\n",
      "Epoch 8/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.1855 - mean_absolute_error: 10.1855 - val_loss: 9.6013 - val_mean_absolute_error: 9.6013\n",
      "Epoch 9/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 10.0953 - mean_absolute_error: 10.0953 - val_loss: 9.6770 - val_mean_absolute_error: 9.6770\n",
      "Epoch 10/100\n",
      "2540/2540 [==============================] - 52s 21ms/step - loss: 10.0484 - mean_absolute_error: 10.0484 - val_loss: 9.4967 - val_mean_absolute_error: 9.4967\n",
      "Epoch 11/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.9890 - mean_absolute_error: 9.9890 - val_loss: 9.3732 - val_mean_absolute_error: 9.3732\n",
      "Epoch 12/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.9442 - mean_absolute_error: 9.9442 - val_loss: 9.5728 - val_mean_absolute_error: 9.5728\n",
      "Epoch 13/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.8964 - mean_absolute_error: 9.8964 - val_loss: 9.3529 - val_mean_absolute_error: 9.3529\n",
      "Epoch 14/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.8496 - mean_absolute_error: 9.8496 - val_loss: 9.7463 - val_mean_absolute_error: 9.7463\n",
      "Epoch 15/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.8140 - mean_absolute_error: 9.8140 - val_loss: 9.2734 - val_mean_absolute_error: 9.2734\n",
      "Epoch 16/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.7800 - mean_absolute_error: 9.7800 - val_loss: 9.3894 - val_mean_absolute_error: 9.3894\n",
      "Epoch 17/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.7470 - mean_absolute_error: 9.7470 - val_loss: 9.1787 - val_mean_absolute_error: 9.1787\n",
      "Epoch 18/100\n",
      "2540/2540 [==============================] - 50s 19ms/step - loss: 9.7265 - mean_absolute_error: 9.7265 - val_loss: 9.4026 - val_mean_absolute_error: 9.4026\n",
      "Epoch 19/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.6877 - mean_absolute_error: 9.6877 - val_loss: 9.4729 - val_mean_absolute_error: 9.4729\n",
      "Epoch 20/100\n",
      "2540/2540 [==============================] - 52s 20ms/step - loss: 9.6564 - mean_absolute_error: 9.6564 - val_loss: 9.1111 - val_mean_absolute_error: 9.1111\n",
      "Epoch 21/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.6320 - mean_absolute_error: 9.6320 - val_loss: 9.0838 - val_mean_absolute_error: 9.0838\n",
      "Epoch 22/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.6093 - mean_absolute_error: 9.6093 - val_loss: 9.5951 - val_mean_absolute_error: 9.5951\n",
      "Epoch 23/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5889 - mean_absolute_error: 9.5889 - val_loss: 9.3715 - val_mean_absolute_error: 9.3715\n",
      "Epoch 24/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.5672 - mean_absolute_error: 9.5672 - val_loss: 9.4937 - val_mean_absolute_error: 9.4937\n",
      "Epoch 25/100\n",
      "2540/2540 [==============================] - 44s 17ms/step - loss: 9.5502 - mean_absolute_error: 9.5502 - val_loss: 8.9855 - val_mean_absolute_error: 8.9855\n",
      "Epoch 26/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.5234 - mean_absolute_error: 9.5234 - val_loss: 9.3310 - val_mean_absolute_error: 9.3310\n",
      "Epoch 27/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.5032 - mean_absolute_error: 9.5032 - val_loss: 9.0051 - val_mean_absolute_error: 9.0051\n",
      "Epoch 28/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.4856 - mean_absolute_error: 9.4856 - val_loss: 9.2868 - val_mean_absolute_error: 9.2868\n",
      "Epoch 29/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4693 - mean_absolute_error: 9.4693 - val_loss: 9.0204 - val_mean_absolute_error: 9.0204\n",
      "Epoch 30/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.4548 - mean_absolute_error: 9.4548 - val_loss: 9.7441 - val_mean_absolute_error: 9.7441\n",
      "Epoch 31/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.4296 - mean_absolute_error: 9.4296 - val_loss: 9.1087 - val_mean_absolute_error: 9.1087\n",
      "Epoch 32/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.4091 - mean_absolute_error: 9.4091 - val_loss: 9.0638 - val_mean_absolute_error: 9.0638\n",
      "Epoch 33/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.3910 - mean_absolute_error: 9.3910 - val_loss: 9.5181 - val_mean_absolute_error: 9.5181\n",
      "Epoch 34/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.3864 - mean_absolute_error: 9.3864 - val_loss: 8.9668 - val_mean_absolute_error: 8.9668\n",
      "Epoch 35/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.3745 - mean_absolute_error: 9.3745 - val_loss: 9.0772 - val_mean_absolute_error: 9.0772\n",
      "Epoch 36/100\n",
      "2540/2540 [==============================] - 44s 18ms/step - loss: 9.3554 - mean_absolute_error: 9.3554 - val_loss: 9.0241 - val_mean_absolute_error: 9.0241\n",
      "Epoch 37/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.3404 - mean_absolute_error: 9.3404 - val_loss: 9.0273 - val_mean_absolute_error: 9.0273\n",
      "Epoch 38/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.3293 - mean_absolute_error: 9.3293 - val_loss: 9.0509 - val_mean_absolute_error: 9.0509\n",
      "Epoch 39/100\n",
      "2540/2540 [==============================] - 50s 20ms/step - loss: 9.3127 - mean_absolute_error: 9.3127 - val_loss: 8.8856 - val_mean_absolute_error: 8.8856\n",
      "Epoch 40/100\n",
      "2540/2540 [==============================] - 49s 19ms/step - loss: 9.3172 - mean_absolute_error: 9.3172 - val_loss: 9.0966 - val_mean_absolute_error: 9.0966\n",
      "Epoch 41/100\n",
      "2540/2540 [==============================] - 51s 20ms/step - loss: 9.2858 - mean_absolute_error: 9.2858 - val_loss: 8.8773 - val_mean_absolute_error: 8.8773\n",
      "Epoch 42/100\n",
      "2540/2540 [==============================] - 45s 18ms/step - loss: 9.2784 - mean_absolute_error: 9.2784 - val_loss: 8.9753 - val_mean_absolute_error: 8.9753\n",
      "Epoch 43/100\n",
      " 233/2540 [=>............................] - ETA: 53s - loss: 9.3181 - mean_absolute_error: 9.3181"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "predictions = []\n",
    "\n",
    "for i in range(8):\n",
    "    history, model = train_model(x_train, y_train, x_val, y_val, shuffle=True, shuffle_buffer=0.75)\n",
    "    pred = model.predict(x_test)\n",
    "    predictions.append(pred)\n",
    "    print('='*25+f' TRIAL {i}, MAE: {mean_absolute_error(pred,y_test)} '+'='*25)\n",
    "    results.append([history, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4ff15239-8f1e-4f6d-b431-f369b3e26348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.727299753801523\n",
      "9.717669412464797\n",
      "9.740593986327768\n",
      "9.750344895786744\n",
      "9.67288864488992\n",
      "9.755444177230974\n",
      "9.662624881636848\n",
      "9.82704817137997\n"
     ]
    }
   ],
   "source": [
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'{mean_absolute_error(prediction, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1914f1ac-6f49-4002-b083-cffa639fea90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5733a7a-9728-4e91-8cbc-029c5070ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.stack(predictions).reshape(8, -1).T, columns = [f'model_{i}' for i in range(1,9)])\n",
    "test_dataframe[[f'prediction_{i}' for i in range(1,9)]] = pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "194638de-adb8-4a01-9e09-afd3f6e04427",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe.to_pickle('diff_ys-yield_history_2-2023_05_09.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d91511-c477-4420-9dbe-9d2dbb416e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
