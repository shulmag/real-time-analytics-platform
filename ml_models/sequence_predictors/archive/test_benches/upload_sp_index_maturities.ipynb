{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook corresponds to the cloud function: `update_all_sp_maturities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce68003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../ahmad_creds.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54445992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import requests as r\n",
    "import datetime\n",
    "from google.cloud import secretmanager\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DATE = datetime.datetime(2023, 11, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_rebuild_for = pd.to_datetime(TARGET_DATE).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faeb60c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'eng-reactor-287421'\n",
    "\n",
    "# table names in Bigquery in `eng-reactor-287421.spBondIndexMaturities` group\n",
    "TABLE_NAMES = ['sp_15plus_year_national_amt_free_index',\n",
    "               'sp_12_22_year_national_amt_free_index',\n",
    "               'sp_7_12_year_national_amt_free_index',\n",
    "               'sp_high_quality_index',\n",
    "               'sp_high_quality_intermediate_managed_amt_free_index',\n",
    "               'sp_high_quality_short_index',\n",
    "               'sp_high_quality_short_intermediate_index',\n",
    "               'sp_long_term_national_amt_free_municipal_bond_index_yield']\n",
    "\n",
    "# defining IDs using dictionaries so we don't need to rely on indexing for lists, etc, to remove any ambiguity; the INDEX_IDS are unique identifiers for each S&P index to request their data from the S&P API, these values were scraped directly from S&P\n",
    "INDEX_IDS = {'sp_15plus_year_national_amt_free_index': 92346704, \n",
    "             'sp_12_22_year_national_amt_free_index': 946546, \n",
    "             'sp_7_12_year_national_amt_free_index': 946545, \n",
    "             'sp_high_quality_intermediate_managed_amt_free_index': 92404510, \n",
    "             'sp_high_quality_short_intermediate_index': 10001820, \n",
    "             'sp_high_quality_short_index': 10001819, \n",
    "             'sp_high_quality_index': 10001818, \n",
    "             'sp_long_term_national_amt_free_municipal_bond_index_yield': 946547}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to email error message if update fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d65a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_secret_version(project_id, secret_id, version_id):\n",
    "    client = secretmanager.SecretManagerServiceClient()    # create the Secret Manager client\n",
    "    name = f'projects/{project_id}/secrets/{secret_id}/versions/{version_id}'    # build the resource name of the secret version\n",
    "    response = client.access_secret_version(request={'name': name})    # access the secret version\n",
    "    payload = response.payload.data.decode('UTF-8')\n",
    "    return payload\n",
    "\n",
    "\n",
    "def send_error_email(subject,error_message):\n",
    "    sender_email = access_secret_version('eng-reactor-287421', 'notifications_username', 'latest')\n",
    "    password = access_secret_version('eng-reactor-287421', 'notifications_password', 'latest')\n",
    "    receiver_email = 'eng@ficc.ai'\n",
    "    \n",
    "    msg = MIMEText(error_message)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = sender_email\n",
    "    msg['To'] = receiver_email\n",
    "\n",
    "    smtp_server = 'smtp.gmail.com'\n",
    "    port = 587\n",
    "    sender_email = 'notifications@ficc.ai'\n",
    "\n",
    "    with smtplib.SMTP(smtp_server, port) as server:\n",
    "        try:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, password)\n",
    "            server.sendmail(sender_email, receiver_email, msg.as_string())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        finally:\n",
    "            server.quit() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to upload data to bigquery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90bc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema():\n",
    "    schema=[bigquery.SchemaField('effectivedate', bigquery.enums.SqlTypeNames.DATE),\n",
    "            bigquery.SchemaField('weightedAverageMaturity', bigquery.enums.SqlTypeNames.FLOAT),\n",
    "            bigquery.SchemaField('weightedAverageDuration', bigquery.enums.SqlTypeNames.FLOAT)]\n",
    "    return schema\n",
    "\n",
    "\n",
    "def upload_data(df, TABLE_ID):\n",
    "    client = bigquery.Client(project=PROJECT_ID, location='US')\n",
    "    job_config = bigquery.LoadJobConfig(schema=get_schema(), \n",
    "                                        write_disposition='WRITE_APPEND')\n",
    "    job = client.load_table_from_dataframe(df, TABLE_ID, job_config=job_config)\n",
    "    job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08949813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_maturities(index_id):\n",
    "    '''Scrape data from S&P website.'''\n",
    "    # the following link was obtained from S&P's html code, it requests the data for a given index identified by the indexId variable\n",
    "    action_url = f'https://www.spglobal.com/spdji/en/util/redesign/index-data/get-performance-data-for-datawidget-redesign.dot?indexId={index_id}&language_id=1&_=1627373317848'\n",
    "    \n",
    "    res = r.get(action_url)\n",
    "    res_json = res.json()    # the API returns a json file which, among other things, contains the average maturity and duration of the index and the date those figures were last updated (the effectivedate)\n",
    "    \n",
    "    weighted_average_maturity = res_json['indexPerformanceHolder']['indexPerformance']['totalReturn'].get('weightedAverageMaturity')\n",
    "    weighted_average_duration = res_json['indexPerformanceHolder']['indexPerformance']['totalReturn'].get('weightedAverageDuration')\n",
    "    \n",
    "    if not weighted_average_maturity:\n",
    "        weighted_average_maturity = np.nan\n",
    "    if not weighted_average_duration:\n",
    "        weighted_average_duration = np.nan\n",
    "    \n",
    "    # return a dictionary which will become a single dataframe row, which is appended to the current bigquery table\n",
    "    data = {'effectivedate': date_to_rebuild_for,\n",
    "            'weightedAverageMaturity': weighted_average_maturity,\n",
    "            'weightedAverageDuration': weighted_average_duration}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3ff041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    for table in TABLE_NAMES:    # for each index, we scrape maturities and upload\n",
    "        print(table)\n",
    "        index_id = INDEX_IDS[table]\n",
    "        try:\n",
    "            data = scrape_maturities(index_id)\n",
    "            data = pd.DataFrame(data, index=[0])    # save next entry as a single row dataframe and upload to bigquery\n",
    "            upload_data(data, f'eng-reactor-287421.spBondIndexMaturities.{table}')\n",
    "        except Exception as e:\n",
    "            print('Cloud function error raised:', e)\n",
    "            raise e    # this ensures that even after we catch an error and send an email alert, we raise the error to make the function fail. This allows the cloud function instance to fail and retry.\n",
    "\n",
    "    return 'Run Success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "271d77ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sp_15plus_year_national_amt_free_index\n",
      "sp_12_22_year_national_amt_free_index\n",
      "sp_7_12_year_national_amt_free_index\n",
      "sp_high_quality_index\n",
      "sp_high_quality_intermediate_managed_amt_free_index\n",
      "sp_high_quality_short_index\n",
      "sp_high_quality_short_intermediate_index\n",
      "sp_long_term_national_amt_free_municipal_bond_index_yield\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Run Success'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24246af1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
