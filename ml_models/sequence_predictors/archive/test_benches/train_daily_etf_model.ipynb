{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook corresponds to the cloud function: `train_daily_etf_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f43fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'ahmad_creds.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'eng-reactor-287421'\n",
    "ETF_DAILY_DATASET = 'ETF_daily_alphavantage'\n",
    "SP_INDEX_DATASET = 'spBondIndex'\n",
    "DATASET_NAME = 'yield_curves_v2'\n",
    "\n",
    "TRAIN_WINDOW_SIZE = 45    # number of days of prior data to train the etf model on; previously tuned hyperparameter\n",
    "\n",
    "sp_index_tables = ['sp_12_22_year_national_amt_free_index',\n",
    "                   'sp_15plus_year_national_amt_free_index',\n",
    "                   'sp_7_12_year_national_amt_free_municipal_bond_index_yield',\n",
    "                   'sp_muni_high_quality_index_yield',\n",
    "                   'sp_high_quality_intermediate_managed_amt_free_municipal_bond_index_yield',\n",
    "                   'sp_high_quality_short_intermediate_municipal_bond_index_yield',\n",
    "                   'sp_high_quality_short_municipal_bond_index_yield',\n",
    "                   'sp_long_term_national_amt_free_municipal_bond_index_yield']\n",
    "\n",
    "sp_maturity_tables = ['sp_12_22_year_national_amt_free_index',\n",
    "                      'sp_15plus_year_national_amt_free_index',\n",
    "                      'sp_7_12_year_national_amt_free_index',\n",
    "                      'sp_high_quality_index',\n",
    "                      'sp_high_quality_intermediate_managed_amt_free_index',\n",
    "                      'sp_high_quality_short_intermediate_index',\n",
    "                      'sp_high_quality_short_index',\n",
    "                      'sp_long_term_national_amt_free_municipal_bond_index_yield']\n",
    "\n",
    "# description of how these ETF's were chosen are in subsection 1a of section \"Why use ETFs?\" in https://www.notion.so/FICC-Yield-Curve-0e9d3fb1a49a4789826083361257a962\n",
    "best_funds = {'sp_12_22_year_national_amt_free_index' : ['FMHI', 'MUB'], \n",
    "              'sp_15plus_year_national_amt_free_index': ['FMHI', 'MLN', 'MUB', 'TFI', 'SUB', 'SHYD', 'HYMB', 'HYD'], \n",
    "              'sp_7_12_year_national_amt_free_index': ['TFI', 'PZA', 'ITM', 'MLN'], \n",
    "              'sp_high_quality_index': ['PZA', 'TFI', 'ITM'], \n",
    "              'sp_high_quality_intermediate_managed_amt_free_index': ['TFI', 'PZA', 'ITM', 'MLN'], \n",
    "              'sp_high_quality_short_intermediate_index': ['PZA', 'TFI', 'ITM'], \n",
    "              'sp_high_quality_short_index': ['PZA', 'HYMB', 'HYD', 'MLN', 'ITM', 'TFI', 'SHYD', 'SHM'], \n",
    "              'sp_long_term_national_amt_free_municipal_bond_index_yield' : ['FMHI', 'MLN', 'MUB', 'SUB']}\n",
    "\n",
    "best_lambdas = {'sp_12_22_year_national_amt_free_index' : 5.0,\n",
    "                'sp_15plus_year_national_amt_free_index': 5.0,\n",
    "                'sp_7_12_year_national_amt_free_index': 1.0,\n",
    "                'sp_high_quality_index': 1.0,\n",
    "                'sp_high_quality_intermediate_managed_amt_free_index': 1.0,\n",
    "                'sp_high_quality_short_intermediate_index': 1.0,\n",
    "                'sp_high_quality_short_index': 1.0,\n",
    "                'sp_long_term_national_amt_free_municipal_bond_index_yield': 5.0}    \n",
    "\n",
    "sp_index_table_to_sp_maturity_table = dict(zip(sp_index_tables, sp_maturity_tables))\n",
    "\n",
    "ETFS = ['FMHI',\n",
    "        'HYD',\n",
    "        'HYMB',\n",
    "        'IBMK',\n",
    "        'IBML',\n",
    "        'ITM',\n",
    "        'MLN',\n",
    "        'MMIN',\n",
    "        'MUB',\n",
    "        'PZA', \n",
    "        'SHM', \n",
    "        'SHYD', \n",
    "        'SMB', \n",
    "        'SUB' , \n",
    "        'TFI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_etf_data():\n",
    "    '''Loads the daily etf prices from BigQuery. The data for each etf is load as a dataframe and then combined \n",
    "    in a dictionary.'''\n",
    "    etf_data  = {}\n",
    "    for etf in ETFS:\n",
    "        query = f'''SELECT DISTINCT * FROM {ETF_DAILY_DATASET}.{etf} '''\n",
    "        df = pd.read_gbq(query, project_id=PROJECT_ID, dialect='standard')\n",
    "        \n",
    "        df['Date'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')\n",
    "        df.sort_values('Date', inplace=True)\n",
    "        df.set_index('Date', inplace=True, drop=True)    # `drop=True` removes the column that is to be used as the index\n",
    "        etf_data[etf] = df.drop_duplicates()\n",
    "    return etf_data\n",
    "\n",
    "\n",
    "def load_index_yields():\n",
    "    '''Loads the S&P index yields from BigQuery. Each individual index is read as a dataframe which are then \n",
    "    combined into a dictionary.'''\n",
    "    index_data  = {}\n",
    "    for sp_index_table in sp_index_tables:\n",
    "        query = f'''SELECT DISTINCT * FROM {SP_INDEX_DATASET}.{sp_index_table} '''\n",
    "        \n",
    "        df = pd.read_gbq(query, project_id=PROJECT_ID, dialect='standard')\n",
    "        df = df.drop_duplicates('date')\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "        df.sort_values('date', inplace=True, ascending=True)\n",
    "        df.set_index('date', inplace=True, drop=True)    # `drop=True` removes the column that is to be used as the index\n",
    "\n",
    "        df['ytw'] = df['ytw'] * 100    # convert to basis points\n",
    "        \n",
    "        sp_maturity_table = sp_index_table_to_sp_maturity_table[sp_index_table]    # standardize names between maturity and yield data\n",
    "        index_data[sp_maturity_table] = df \n",
    "    return index_data\n",
    "\n",
    "\n",
    "def preprocess_data(index_data: dict, etf_data: dict, index_name: str, etf_names: list, date_start='2020-05', var='Close'):\n",
    "    '''Takes as input the loaded S&P index data and ETF data from bigquery, which is stored as a dictionary \n",
    "    of dataframes. It also takes the name of a single S&P index and a list of ETFs that are relevant to predicting \n",
    "    that index. It then merges this data into a single dataframe, calculating the percent change, `pct_change`, in \n",
    "    ETF prices in basis points and the change in index ytw in basis points. This is done, by default, for \n",
    "    observations after May 2020 and for the Close prices of the ETFs. The merged result is returned.'''\n",
    "    data = []\n",
    "    \n",
    "    # preprocess etf data by retrieving ETFs of interest and calculating pct_change in basis points\n",
    "    for etf_name in etf_names:\n",
    "        etf = etf_data[etf_name].copy()\n",
    "        etf = etf.drop_duplicates()\n",
    "        data.append(etf[f'{var}_{etf_name}'].pct_change() / 0.0001)\n",
    "    etf = pd.concat(data, axis=1)\n",
    "    \n",
    "    # preprocess index data by first-differencing ytw\n",
    "    index = index_data[index_name].copy()\n",
    "    index['ytw_diff'] = index['ytw'].diff()\n",
    "    \n",
    "    # merge etf and index date\n",
    "    temp_df = pd.merge(etf, index, left_index=True, right_index=True).loc[date_start:]\n",
    "    return temp_df.dropna()\n",
    "\n",
    "\n",
    "def get_schema_etf(coefficient_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Gets the bq schema to upload the data to the bq table containing the coefficients \n",
    "    for the linear model using ETF prices to predict index yield, for each index.'''\n",
    "    schema = [bigquery.SchemaField('Date', 'DATE')] + [bigquery.SchemaField(column, 'FLOAT') for column in coefficient_df.columns]\n",
    "    return schema\n",
    "\n",
    "\n",
    "def upload_data(df, table_id, schema):\n",
    "    client = bigquery.Client(project=PROJECT_ID, location='US')\n",
    "    job_config = bigquery.LoadJobConfig(schema=schema, write_disposition='WRITE_APPEND')\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
    "    try:\n",
    "        job.result()\n",
    "        print(f'Upload Successful to {table_id}')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to Upload to {table_id}')\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    '''First, load the index and etf data. Then, for each S&P index, train a LASSO model using \n",
    "    the previously identified optimal subset of ETFs and previously identified optimal alpha \n",
    "    value to predict yields. Training data size is equal to the window size.'''\n",
    "    index_data = load_index_yields()\n",
    "    etf_data = load_etf_data()\n",
    "    \n",
    "    for index, best_funds_for_index in best_funds.items(): \n",
    "        coefficients_dict = {}    # used to save the coefficients \n",
    "\n",
    "        # load data and hyperparameters \n",
    "        best_lambda = best_lambdas[index]\n",
    "        data = preprocess_data(index_data, etf_data, index, best_funds_for_index)\n",
    "\n",
    "        # get X and Y data\n",
    "        X = data.drop(['ytw', 'ytw_diff'], axis=1)\n",
    "        y = data['ytw_diff']\n",
    "        X_cols = list(X.columns)\n",
    "\n",
    "        # training data size is the window size \n",
    "        X_train = X.iloc[-TRAIN_WINDOW_SIZE:, :]\n",
    "        y_train = y.iloc[-TRAIN_WINDOW_SIZE:]\n",
    "        assert len(X_train) == len(y_train)\n",
    "        \n",
    "        # get the date to index the model and train the model \n",
    "        date = X_train.index.max().date().isoformat()\n",
    "        lasso = Lasso(alpha=best_lambda, random_state=1, max_iter=5000).fit(X_train, y_train)    # inputs to the Lasso model: ETF prices, output: predicted S&P index value\n",
    "\n",
    "        # save the coefficients to one row dataframe\n",
    "        columns = ['constant'] + X_cols\n",
    "        coefficients = np.hstack([lasso.intercept_, lasso.coef_])\n",
    "        coefficients_dict[date] = dict(zip(columns, coefficients))\n",
    "        coefficient_df = pd.DataFrame(coefficients_dict).T\n",
    "        coefficient_df.index = pd.to_datetime(coefficient_df.index)\n",
    "        coefficient_df = coefficient_df.reset_index(drop=False).rename({'index': 'Date'}, axis=1)\n",
    "        \n",
    "        table_id = PROJECT_ID + '.' + DATASET_NAME + '.' + index\n",
    "        schema = get_schema_etf(coefficient_df)\n",
    "        upload_data(coefficient_df, table_id, schema)\n",
    "        \n",
    "    return 'SUCCESS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b72a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload Successful\n",
      "Upload Successful\n",
      "Upload Successful\n",
      "Upload Successful\n",
      "Upload Successful\n",
      "Upload Successful\n",
      "Upload Successful\n",
      "Upload Successful\n"
     ]
    }
   ],
   "source": [
    "main('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
