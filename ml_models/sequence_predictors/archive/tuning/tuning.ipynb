{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbb76b3",
   "metadata": {},
   "source": [
    "## Yield Spread Model hyperparameter tuning\n",
    "\n",
    "\n",
    "This model implements the combined yield spread model and the uses the Keras tuner to tune the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c82f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband, BayesianOptimization\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from data_preparation import process_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c8561",
   "metadata": {},
   "source": [
    "Setting the seed for layer initializer. We want the layers to be initialized with the same values in all the experiments to remove randomness from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "069ede42",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_initializer = initializers.RandomNormal(mean=0.0, stddev=0.1, seed=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb220a00",
   "metadata": {},
   "source": [
    "Setting up the credentials for GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e503164",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"eng-reactor-287421-112eb767e1b3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4cc69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f147675",
   "metadata": {},
   "source": [
    "Initializing the big query client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc77e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7536563",
   "metadata": {},
   "source": [
    "Checking if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598dea30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d84661a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a10a0c",
   "metadata": {},
   "source": [
    "#### Hyper-parameters for the model\n",
    "\n",
    "The batch size and learning rate have an impact on the smoothness of convergence of the model.\\\n",
    "Larger the batch size the smoother the convergence. For a larger batch size we need a higher learning rate and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cda4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.85\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 1000\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "SEQUENCE_LENGTH = 5\n",
    "NUM_FEATURES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00bee91",
   "metadata": {},
   "source": [
    "### Query to fetch data from BigQuery\n",
    "\n",
    "The SQL query uses the trade history for the training data view. All three trade directions, namely dealer-dealer (D), dealer-sells (S), and dealer-purchases (P) are included. We are limiting the training to bonds whose yield is a positive number less than three.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4122c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_QUERY = \"\"\" SELECT\n",
    "  *\n",
    "FROM\n",
    "  `eng-reactor-287421.primary_views.trade_history_for_training_no_neg_yields`\n",
    "WHERE\n",
    "  yield IS NOT NULL\n",
    "  AND yield > 0 \n",
    "  AND yield <= 3 \n",
    "  AND par_traded IS NOT NULL\n",
    "  AND sp_long IS NOT NULL\n",
    "  AND trade_date >= '2021-08-01' \n",
    "  AND trade_date <= '2021-10-01'\n",
    "  AND msrb_valid_to_date > current_date -- condition to remove cancelled trades\n",
    "ORDER BY\n",
    "  trade_date DESC\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac056d",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "We grab the data from BigQuery and convert it into a format suitable for input to the model. The process data function converts the dictionary of trade history into a list of lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee72fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file = 'training_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5196f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from processed file\n",
      "CPU times: user 2.06 s, sys: 549 ms, total: 2.61 s\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not os.path.isfile(processed_file):\n",
    "    reference_data = process_data(DATA_QUERY, \n",
    "                              bq_client,\n",
    "                              SEQUENCE_LENGTH,\n",
    "                              NUM_FEATURES,\n",
    "                              'data.pkl')\n",
    "    reference_data.to_pickle(processed_file)\n",
    "else:\n",
    "    print('Reading from processed file')\n",
    "    reference_data = pd.read_pickle('training_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb2e006",
   "metadata": {},
   "source": [
    "We use the dictionary to map the interest payment frequency code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e8db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUPON_FREQUENCY_DICT = {0:\"Unknown\",\n",
    "                        1:\"Semiannually\",\n",
    "                        2:\"Monthly\",\n",
    "                        3:\"Annually\",\n",
    "                        4:\"Weekly\",\n",
    "                        5:\"Quarterly\",\n",
    "                        6:\"Every 2 years\",\n",
    "                        7:\"Every 3 years\",\n",
    "                        8:\"Every 4 years\",\n",
    "                        9:\"Every 5 years\",\n",
    "                        10:\"Every 7 years\",\n",
    "                        11:\"Every 8 years\",\n",
    "                        12:\"Biweekly\",\n",
    "                        13:\"Changeable\",\n",
    "                        14:\"Daily\",\n",
    "                        15:\"Term mode\",\n",
    "                        16:\"Interest at maturity\",\n",
    "                        17:\"Bimonthly\",\n",
    "                        18:\"Every 13 weeks\",\n",
    "                        19:\"Irregular\",\n",
    "                        20:\"Every 28 days\",\n",
    "                        21:\"Every 35 days\",\n",
    "                        22:\"Every 26 weeks\",\n",
    "                        23:\"Not Applicable\",\n",
    "                        24:\"Tied to prime\",\n",
    "                        25:\"One time\",\n",
    "                        26:\"Every 10 years\",\n",
    "                        27:\"Frequency to be determined\",\n",
    "                        28:\"Mandatory put\",\n",
    "                        29:\"Every 52 weeks\",\n",
    "                        30:\"When interest adjusts-commercial paper\",\n",
    "                        31:\"Zero coupon\",\n",
    "                        32:\"Certain years only\",\n",
    "                        33:\"Under certain circumstances\",\n",
    "                        34:\"Every 15 years\",\n",
    "                        35:\"Custom\",\n",
    "                        36:\"Single Interest Payment\"\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8318526d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Semiannually\n",
       "1    Semiannually\n",
       "2    Semiannually\n",
       "3    Semiannually\n",
       "4    Semiannually\n",
       "Name: interest_payment_frequency, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = reference_data.copy()\n",
    "df.interest_payment_frequency.fillna(0, inplace=True)\n",
    "df.interest_payment_frequency = df.interest_payment_frequency.apply(lambda x: COUPON_FREQUENCY_DICT[x])\n",
    "df.interest_payment_frequency.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dcb129",
   "metadata": {},
   "source": [
    "Dropping a few columns that we do not use as features. These features were dropped after analyzing their importance using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d5cc363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 429 ms, sys: 128 ms, total: 557 ms\n",
      "Wall time: 554 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.drop(columns=[\n",
    "                 'sp_stand_alone',\n",
    "                 'sp_icr_school',\n",
    "                 'sp_watch_long',\n",
    "                 'sp_outlook_long',\n",
    "                 'sp_prelim_long',\n",
    "                 'MSRB_maturity_date',\n",
    "                 'MSRB_INST_ORDR_DESC',\n",
    "                 'MSRB_valid_from_date',\n",
    "                 'MSRB_valid_to_date',\n",
    "                 'upload_date',\n",
    "                 'sequence_number',\n",
    "                 'security_description',\n",
    "                 'ref_valid_from_date',\n",
    "                 'ref_valid_to_date',\n",
    "                 'additional_next_sink_date',\n",
    "                 'first_coupon_date',\n",
    "                 'last_period_accrues_from_date',\n",
    "                 'primary_market_settlement_date',\n",
    "                 'assumed_settlement_date',\n",
    "                 'sale_date','q','d'],\n",
    "                  inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4831b9f7",
   "metadata": {},
   "source": [
    "Converting the columns to correct datatypes. We also restrict the universe of trades to only investment grade bonds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0387ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.01 s, sys: 573 ms, total: 3.58 s\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df.copy()\n",
    "df['quantity'] = np.log10(df.par_traded.astype(float))\n",
    "df.coupon = df.coupon.astype(float)\n",
    "df.issue_amount = np.log10(df.issue_amount)\n",
    "\n",
    "date_cols = [col for col in list(df.columns) if 'DATE' in col.upper()]\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "prices = ['coupon', 'par_traded', 'dollar_price', 'next_call_price', 'par_call_price', 'refund_price']\n",
    "for col in prices:\n",
    "    df[col] = df[col].astype(float)\n",
    "    \n",
    "# Just including investment grade bonds\n",
    "df = df[df.sp_long.isin(['A-','A','A+','AA-','AA','AA+','AAA'])] \n",
    "df['rating'] = df.sp_long\n",
    "df['yield_spread'] = df['yield_spread'] * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3374413e",
   "metadata": {},
   "source": [
    "Creating Binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b774c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['callable'] = df.is_callable  \n",
    "df['called'] = df.is_called \n",
    "df['zerocoupon'] = df.coupon == 0\n",
    "df['whenissued'] = df.delivery_date >= df.trade_date\n",
    "df['sinking'] = ~df.next_sink_date.isnull()\n",
    "df['deferred'] = (df.interest_payment_frequency == 'Unknown') | df.zerocoupon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da55b7fa",
   "metadata": {},
   "source": [
    "Converting the dates to a number of days from the settlement date. We only consider trades to be reportedly correctly if the trades are settled within one month of the trade date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9683f458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384989\n",
      "384298\n"
     ]
    }
   ],
   "source": [
    "# Dropping trades settled one month after the trade\n",
    "print(len(df))\n",
    "df['days_to_settle'] = (df.settlement_date - df.trade_date).dt.days\n",
    "df = df[df.days_to_settle <= 31]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eafc26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['days_to_maturity'] =  np.log10(1 + (df.maturity_date - df.settlement_date).dt.days)\n",
    "df['days_to_call'] = np.log10(1 + (df.next_call_date - df.settlement_date).dt.days.fillna(0))\n",
    "df['days_to_par'] = np.log10(1 + (df.par_call_date - df.settlement_date).dt.days)\n",
    "df['call_to_maturity'] = np.log10(1 + (df.maturity_date - df.next_call_date).dt.days)\n",
    "\n",
    "\n",
    "# Removing bonds from Puerto Rico\n",
    "df = df[df.incorporated_state_code != 'PR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e1ef2",
   "metadata": {},
   "source": [
    "We drop the trades which have already been called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebc90b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384021\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "# df = df[~df.called]\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78950e02",
   "metadata": {},
   "source": [
    "Adding seconds ago and yield spreads features of the last trade to the reference data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f804359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_trade_feature(x, feature):\n",
    "    recent_trade = x[0]\n",
    "    if feature == 'yield_spread':\n",
    "        return recent_trade[0]\n",
    "    elif feature == 'seconds_ago':\n",
    "        return recent_trade[-1]\n",
    "    elif feature == 'par_traded':\n",
    "        return recent_trade[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb37f972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rtrs_control_number</th>\n",
       "      <th>trade_datetime</th>\n",
       "      <th>cusip</th>\n",
       "      <th>my_price</th>\n",
       "      <th>price_delta</th>\n",
       "      <th>msrb_cusip</th>\n",
       "      <th>yield_spread</th>\n",
       "      <th>num_prev_messages</th>\n",
       "      <th>publish_datetime</th>\n",
       "      <th>trade_type</th>\n",
       "      <th>...</th>\n",
       "      <th>sinking</th>\n",
       "      <th>deferred</th>\n",
       "      <th>days_to_settle</th>\n",
       "      <th>days_to_maturity</th>\n",
       "      <th>days_to_call</th>\n",
       "      <th>days_to_par</th>\n",
       "      <th>call_to_maturity</th>\n",
       "      <th>last_seconds_ago</th>\n",
       "      <th>last_yield_spread</th>\n",
       "      <th>last_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021100101708500</td>\n",
       "      <td>2021-10-01 11:04:26</td>\n",
       "      <td>788073DK7</td>\n",
       "      <td>112.084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788073DK7</td>\n",
       "      <td>-49.288566</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-01 11:05:24</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3.013680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.304124</td>\n",
       "      <td>-78.929506</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021100100379500</td>\n",
       "      <td>2021-10-01 09:09:10</td>\n",
       "      <td>68277DES9</td>\n",
       "      <td>99.514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68277DES9</td>\n",
       "      <td>86.171957</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-01 09:09:49</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3.709609</td>\n",
       "      <td>3.409595</td>\n",
       "      <td>3.409595</td>\n",
       "      <td>3.407731</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>83.711434</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021100102681500</td>\n",
       "      <td>2021-10-01 12:01:13</td>\n",
       "      <td>446186PP7</td>\n",
       "      <td>118.287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>446186PP7</td>\n",
       "      <td>3.711434</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-01 12:01:38</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>3.670617</td>\n",
       "      <td>3.396722</td>\n",
       "      <td>3.396722</td>\n",
       "      <td>3.340841</td>\n",
       "      <td>12.719926</td>\n",
       "      <td>15.838303</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021100102502900</td>\n",
       "      <td>2021-10-01 11:49:13</td>\n",
       "      <td>649791HG8</td>\n",
       "      <td>105.185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649791HG8</td>\n",
       "      <td>-87.828043</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-01 11:49:44</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2.710117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.891787</td>\n",
       "      <td>-85.028043</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021100102121800</td>\n",
       "      <td>2021-10-01 11:25:26</td>\n",
       "      <td>64971W5Y2</td>\n",
       "      <td>100.954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64971W5Y2</td>\n",
       "      <td>-45.688566</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-01 11:26:10</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2.320146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.150143</td>\n",
       "      <td>-68.931304</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rtrs_control_number      trade_datetime      cusip  my_price  price_delta  \\\n",
       "0     2021100101708500 2021-10-01 11:04:26  788073DK7   112.084          0.0   \n",
       "1     2021100100379500 2021-10-01 09:09:10  68277DES9    99.514          0.0   \n",
       "2     2021100102681500 2021-10-01 12:01:13  446186PP7   118.287          0.0   \n",
       "3     2021100102502900 2021-10-01 11:49:13  649791HG8   105.185          0.0   \n",
       "4     2021100102121800 2021-10-01 11:25:26  64971W5Y2   100.954          0.0   \n",
       "\n",
       "  msrb_cusip  yield_spread  num_prev_messages    publish_datetime trade_type  \\\n",
       "0  788073DK7    -49.288566                  0 2021-10-01 11:05:24          D   \n",
       "1  68277DES9     86.171957                  0 2021-10-01 09:09:49          D   \n",
       "2  446186PP7      3.711434                  0 2021-10-01 12:01:38          S   \n",
       "3  649791HG8    -87.828043                  0 2021-10-01 11:49:44          S   \n",
       "4  64971W5Y2    -45.688566                  0 2021-10-01 11:26:10          S   \n",
       "\n",
       "   ... sinking deferred  days_to_settle  days_to_maturity days_to_call  \\\n",
       "0  ...   False    False               4          3.013680     0.000000   \n",
       "1  ...   False    False               4          3.709609     3.409595   \n",
       "2  ...   False    False               4          3.670617     3.396722   \n",
       "3  ...   False    False               4          2.710117     0.000000   \n",
       "4  ...   False    False               4          2.320146     0.000000   \n",
       "\n",
       "  days_to_par call_to_maturity  last_seconds_ago  last_yield_spread  last_size  \n",
       "0         NaN              NaN         17.304124         -78.929506       55.0  \n",
       "1    3.409595         3.407731          4.430817          83.711434       20.0  \n",
       "2    3.396722         3.340841         12.719926          15.838303      100.0  \n",
       "3         NaN              NaN          8.891787         -85.028043       50.0  \n",
       "4         NaN              NaN         15.150143         -68.931304       25.0  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['last_seconds_ago'] = df.trade_history.apply(get_latest_trade_feature, args=[\"seconds_ago\"])\n",
    "df['last_yield_spread'] = df.trade_history.apply(get_latest_trade_feature, args=[\"yield_spread\"])\n",
    "df['last_size'] = df.trade_history.apply(get_latest_trade_feature, args=[\"par_traded\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c06b2",
   "metadata": {},
   "source": [
    "Filling missing values for non-categorical features. The missing values are filled by ther logical counterparts from the [47 Data Enumerations by XPath google sheet](https://docs.google.com/spreadsheets/d/1ke5Ga0OMLAY7T47I6AsS54tYTreMGvjo/edit#gid=1305746325)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bd4e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['instrument_primary_name'], inplace=True)\n",
    "df.purpose_sub_class.fillna(1,inplace=True)\n",
    "df.call_timing.fillna(0, inplace=True) #Unknown\n",
    "df.call_timing_in_part.fillna(0, inplace=True) #Unknown\n",
    "df.sink_frequency.fillna(10, inplace=True) #Under special circumstances\n",
    "df.sink_amount_type.fillna(0, inplace=True)\n",
    "df.issue_text.fillna('No issue text', inplace=True)\n",
    "df.state_tax_status.fillna(0, inplace=True)\n",
    "df.series_name.fillna('No series name', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99902ab2",
   "metadata": {},
   "source": [
    "Filling missing values for categorical features. The missing values are filled by ther logical counterparts from the [47 Data Enumerations by XPath google sheet](https://docs.google.com/spreadsheets/d/1ke5Ga0OMLAY7T47I6AsS54tYTreMGvjo/edit#gid=1305746325)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "620cdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.next_call_price.fillna(100, inplace=True)\n",
    "df.par_call_price.fillna(100, inplace=True)\n",
    "df.min_amount_outstanding.fillna(0, inplace=True)\n",
    "df.max_amount_outstanding.fillna(0, inplace=True)\n",
    "df.call_to_maturity.fillna(0, inplace=True)\n",
    "df.days_to_par.fillna(0, inplace=True)\n",
    "df.maturity_amount.fillna(0, inplace=True)\n",
    "df.issue_price.fillna(df.issue_price.mean(), inplace=True)\n",
    "df.orig_principal_amount.fillna(df.orig_principal_amount.mean(), inplace=True)\n",
    "df.original_yield.fillna(0, inplace=True)\n",
    "df.par_price.fillna(100, inplace=True)\n",
    "df.called_redemption_type.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b51363",
   "metadata": {},
   "source": [
    "Filing missing values for binary features. The missing values are filled by ther logical counterparts from the [47 Data Enumerations by XPath google sheet](https://docs.google.com/spreadsheets/d/1ke5Ga0OMLAY7T47I6AsS54tYTreMGvjo/edit#gid=1305746325)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bb875c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.extraordinary_make_whole_call.fillna(False, inplace=True)\n",
    "df.make_whole_call.fillna(False, inplace=True)\n",
    "df.default_indicator.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e792d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384003\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4cd198",
   "metadata": {},
   "source": [
    "We train the model on a subset of features. These features are defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "687fabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIERS = ['rtrs_control_number', 'cusip']\n",
    "\n",
    "\n",
    "BINARY = ['callable',\n",
    "          'sinking',\n",
    "          'zerocoupon',\n",
    "          'is_non_transaction_based_compensation',\n",
    "          'is_general_obligation',\n",
    "          'callable_at_cav',           \n",
    "          'extraordinary_make_whole_call', \n",
    "           'make_whole_call',\n",
    "           'has_unexpired_lines_of_credit',\n",
    "           'escrow_exists',\n",
    "          ]\n",
    "\n",
    "\n",
    "\n",
    "CATEGORICAL_FEATURES = ['rating',\n",
    "                        'incorporated_state_code',\n",
    "                        'trade_type',\n",
    "                        'transaction_type',\n",
    "                        'maturity_description_code',\n",
    "                        'purpose_class']\n",
    "\n",
    "NON_CAT_FEATURES = ['quantity',\n",
    "                    'days_to_maturity',\n",
    "                    'days_to_call',\n",
    "                    'coupon',\n",
    "                    'issue_amount',\n",
    "                    'last_seconds_ago',\n",
    "                    'last_yield_spread',\n",
    "                    'days_to_settle',\n",
    "                     'days_to_par',\n",
    "                     'maturity_amount',\n",
    "                     'issue_price', \n",
    "                     'orig_principal_amount',\n",
    "                     'max_amount_outstanding']\n",
    "\n",
    "TRADE_HISTORY = ['trade_history']\n",
    "TARGET = ['yield_spread']\n",
    "\n",
    "PREDICTORS = BINARY + CATEGORICAL_FEATURES + NON_CAT_FEATURES + TARGET + TRADE_HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "787fab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = df[IDENTIFIERS + PREDICTORS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1f5a3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "processed_data.maturity_amount = np.log10(1 + processed_data.maturity_amount)\n",
    "processed_data.orig_principal_amount = np.log10(1 + processed_data.orig_principal_amount)\n",
    "processed_data.max_amount_outstanding = np.log10(1 + processed_data.max_amount_outstanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ffedcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for col in NON_CAT_FEATURES:\n",
    "    processed_data[col] = processed_data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234f5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77c336db",
   "metadata": {},
   "source": [
    "A few features such as the initial issue amount cannot be filled with their logical counterparts as their values are not known and hence are dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e9ebe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384003\n",
      "383981\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_data))\n",
    "processed_data = processed_data.dropna()\n",
    "print(len(processed_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309638a",
   "metadata": {},
   "source": [
    "Splitting the date into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb283a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326384\n",
      "57597\n"
     ]
    }
   ],
   "source": [
    "train_index = int(len(processed_data) * (1-TRAIN_TEST_SPLIT))\n",
    "train_dataframe = processed_data[train_index:]\n",
    "test_dataframe = processed_data[:train_index]\n",
    "print(len(train_dataframe))\n",
    "print(len(test_dataframe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651e4d5",
   "metadata": {},
   "source": [
    "## Combining models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40a917",
   "metadata": {},
   "source": [
    "Fitting encoders to the categorical features. These encoders are then used to encode the categorical features of the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "639e12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "fmax = {}\n",
    "for f in CATEGORICAL_FEATURES:\n",
    "    fprep = preprocessing.LabelEncoder().fit(processed_data[f].drop_duplicates())\n",
    "    fmax[f] = np.max(fprep.transform(fprep.classes_))\n",
    "    encoders[f] = fprep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bad2a",
   "metadata": {},
   "source": [
    "The build model function creates and returns a Keras model. The function uses the hp argument to define the hyperparameters during model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f00a4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"KERASTUNER_TUNER_ID\"]=\"tuner0\"\n",
    "# os.environ[\"KERASTUNER_ORACLE_IP\"]=\"0.0.0.0\"\n",
    "# os.environ[\"KERASTUNER_ORACLE_PORT\"]=\"8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6bdf16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    inputs = []\n",
    "    layer = []\n",
    "\n",
    "    ############## INPUT BLOCK ###################\n",
    "    trade_history_input = layers.Input(name=\"trade_history_input\", \n",
    "                                       shape=(SEQUENCE_LENGTH,NUM_FEATURES), \n",
    "                                       dtype = tf.float32) \n",
    "\n",
    "    inputs.append(trade_history_input)\n",
    "\n",
    "    for i in NON_CAT_FEATURES + BINARY:\n",
    "        inputs.append(layers.Input(shape=(1,), name = f\"{i}\"))\n",
    "\n",
    "    for i in inputs[1:]:\n",
    "        layer.append(Normalization()(i))\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    ############## TRADE HISTORY MODEL #################\n",
    "\n",
    "    # Adding the time2vec encoding to the input to transformer\n",
    "    lstm_layer = layers.LSTM(hp.Int(\"lstm_layer_1_units\", min_value=10, max_value=500, step=50), \n",
    "                             activation='tanh',\n",
    "                             input_shape=(SEQUENCE_LENGTH,NUM_FEATURES),\n",
    "                             kernel_initializer = layer_initializer,\n",
    "                             return_sequences = True,\n",
    "                             name='LSTM')\n",
    "\n",
    "    lstm_layer_2 = layers.LSTM(hp.Int(\"lstm_layer_2_units\", min_value=10, max_value=500, step=50), \n",
    "                               activation='tanh',\n",
    "                               input_shape=(SEQUENCE_LENGTH,50),\n",
    "                               kernel_initializer = layer_initializer,\n",
    "                               return_sequences = False,\n",
    "                               name='LSTM_2')\n",
    "\n",
    "    features = lstm_layer(inputs[0])\n",
    "    features = lstm_layer_2(features)\n",
    "\n",
    "    trade_history_output = layers.Dense(hp.Int(\"trade_history_output_layer\", min_value=10, max_value=500, step=50), \n",
    "                                        activation='relu',\n",
    "                                        kernel_initializer=layer_initializer)(features)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "    ############## REFERENCE DATA MODEL ################\n",
    "    global encoders\n",
    "    global fmax\n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        fin = layers.Input(shape=(1,), name = f)\n",
    "        inputs.append(fin)\n",
    "        embedded = layers.Flatten(name = f + \"_flat\")( layers.Embedding(input_dim = fmax[f]+1,\n",
    "                                                                        output_dim = hp.Int(\"embedding_dim\", min_value=10, max_value=500, step=50),\n",
    "                                                                        input_length= 1,\n",
    "                                                                        name = f + \"_embed\",\n",
    "                                                                        embeddings_initializer=layer_initializer)(fin))\n",
    "        layer.append(embedded)\n",
    "\n",
    "    reference_hidden = layers.Dense(hp.Int(\"reference_hidden_1_units\", min_value=10, max_value=500, step=50), \n",
    "                                    activation='relu',\n",
    "                                    kernel_initializer=layer_initializer,\n",
    "                                    name='reference_hidden_1')(layers.concatenate(layer))\n",
    "\n",
    "    reference_hidden2 = layers.Dense(hp.Int(\"reference_hidden_2_units\", min_value=10, max_value=500, step=50), \n",
    "                                     activation='relu',\n",
    "                                     kernel_initializer=layer_initializer,\n",
    "                                     name='reference_hidden_2')(reference_hidden)\n",
    "\n",
    "    referenece_output = layers.Dense(hp.Int(\"reference_hidden_3_units\", min_value=10, max_value=500, step=50), \n",
    "                                     activation='tanh',\n",
    "                                     kernel_initializer=layer_initializer,\n",
    "                                     name='reference_hidden_3')(reference_hidden2)\n",
    "\n",
    "    ####################################################\n",
    "\n",
    "\n",
    "    feed_forward_input = layers.concatenate([referenece_output, trade_history_output])\n",
    "\n",
    "    hidden = layers.Dense(hp.Int(\"output_block_1_units\", min_value=250, max_value=600, step=50), \n",
    "                          activation='relu',\n",
    "                          kernel_initializer=layer_initializer)(feed_forward_input)\n",
    "\n",
    "    hidden2 = layers.Dense(hp.Int(\"output_block_2_units\", min_value=100, max_value=600, step=50), \n",
    "                           activation='tanh',\n",
    "                           kernel_initializer=layer_initializer)(hidden)\n",
    "\n",
    "    final = layers.Dense(1,\n",
    "                         kernel_initializer=layer_initializer)(hidden2)\n",
    "\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=final)\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])),\n",
    "              loss=keras.losses.MeanSquaredError(),\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ef5b1",
   "metadata": {},
   "source": [
    "The create input function encodes the categorical features. It then combines the trade history, categorical, non-categorical, and binary features to return a NumPy array containing the data to be fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ccf4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(df):\n",
    "    global encoders\n",
    "    datalist = []\n",
    "    datalist.append(np.stack(df['trade_history'].to_numpy()))\n",
    "    for f in NON_CAT_FEATURES + BINARY:\n",
    "        datalist.append(df[f].to_numpy().astype('float32'))\n",
    "        \n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        encoded = encoders[f].transform(df[f])\n",
    "        datalist.append(encoded.astype('float32'))\n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6b44b",
   "metadata": {},
   "source": [
    "Defining the tuner for hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46c4c01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_mean_absolute_error\",\n",
    "    max_trials=25,\n",
    "    overwrite=True,\n",
    "    directory=\"model_tuning\",\n",
    "    project_name=\"yield_spread_model\",\n",
    "    distribution_strategy=tf.distribute.MirroredStrategy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f20d487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 10\n",
      "lstm_layer_1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "lstm_layer_2_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "trade_history_output_layer (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "embedding_dim (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "reference_hidden_1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "reference_hidden_2_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "reference_hidden_3_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 500, 'step': 50, 'sampling': None}\n",
      "output_block_1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 250, 'max_value': 600, 'step': 50, 'sampling': None}\n",
      "output_block_2_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 100, 'max_value': 600, 'step': 50, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d84581e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = int(len(train_dataframe) * (1-0.9))\n",
    "train_dataframe = train_dataframe[val_index:]\n",
    "val_dataframe = train_dataframe[:val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72584b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 455 ms, sys: 0 ns, total: 455 ms\n",
      "Wall time: 453 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = create_input(train_dataframe)\n",
    "y_train = train_dataframe.yield_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7e2b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.3 ms, sys: 0 ns, total: 52.3 ms\n",
      "Wall time: 51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_val = create_input(val_dataframe)\n",
    "y_val = val_dataframe.yield_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ac36c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 33m 16s]\n",
      "val_mean_absolute_error: 8.348470687866211\n",
      "\n",
      "Best val_mean_absolute_error So Far: 6.5781097412109375\n",
      "Total elapsed time: 02h 48m 51s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "lstm_layer_1_units|60                |360               \n",
      "lstm_layer_2_units|460               |460               \n",
      "trade_history_o...|110               |360               \n",
      "embedding_dim     |410               |310               \n",
      "reference_hidde...|60                |160               \n",
      "reference_hidde...|360               |360               \n",
      "reference_hidde...|160               |260               \n",
      "output_block_1_...|500               |250               \n",
      "output_block_2_...|500               |350               \n",
      "learning_rate     |0.001             |0.0001            \n",
      "\n",
      "Epoch 1/30\n",
      "7436/7436 [==============================] - 74s 9ms/step - loss: 485.1805 - mean_absolute_error: 14.3743 - val_loss: 438.7197 - val_mean_absolute_error: 13.4385\n",
      "Epoch 2/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 427.6018 - mean_absolute_error: 13.3155 - val_loss: 418.5048 - val_mean_absolute_error: 13.0428\n",
      "Epoch 3/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 421.7386 - mean_absolute_error: 13.1643 - val_loss: 409.5954 - val_mean_absolute_error: 12.8504\n",
      "Epoch 4/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 417.7304 - mean_absolute_error: 13.0585 - val_loss: 400.2829 - val_mean_absolute_error: 12.7608\n",
      "Epoch 5/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 418.6670 - mean_absolute_error: 13.0240 - val_loss: 424.3929 - val_mean_absolute_error: 13.4678\n",
      "Epoch 6/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 416.3130 - mean_absolute_error: 13.0394 - val_loss: 407.6508 - val_mean_absolute_error: 12.6151\n",
      "Epoch 7/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 428.6728 - mean_absolute_error: 13.2690 - val_loss: 450.6621 - val_mean_absolute_error: 13.6832\n",
      "Epoch 8/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 463.2050 - mean_absolute_error: 13.8674 - val_loss: 454.6850 - val_mean_absolute_error: 13.6125\n",
      "Epoch 9/30\n",
      "7436/7436 [==============================] - 67s 9ms/step - loss: 461.5111 - mean_absolute_error: 13.8507 - val_loss: 444.5323 - val_mean_absolute_error: 13.4560\n",
      "Epoch 10/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 463.7954 - mean_absolute_error: 13.8930 - val_loss: 446.2874 - val_mean_absolute_error: 13.7321\n",
      "Epoch 11/30\n",
      "7436/7436 [==============================] - 66s 9ms/step - loss: 462.3261 - mean_absolute_error: 13.9205 - val_loss: 474.7612 - val_mean_absolute_error: 14.2016\n",
      "Epoch 12/30\n",
      "4315/7436 [================>.............] - ETA: 26s - loss: 466.2614 - mean_absolute_error: 14.0618"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=30, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68142d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-cpu.2-6.m78",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-6:m78"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
