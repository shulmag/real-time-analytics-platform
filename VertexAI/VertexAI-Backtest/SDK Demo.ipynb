{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d5e9cf-2bf5-4cbd-b1b7-144720b16cb4",
   "metadata": {},
   "source": [
    "**Last Updated 29/9/23:**\n",
    "\n",
    "The focus of this notebook is to demonstrate how to programatically configure a Vertex AI custom container job and hyperparameter tuning job. The main benefit of this is for larger jobs like backtesting model performance across several months where doing so on GCP console is troublesome. In general, the SDK is easy to use - simply instantiate a CustomJob class, pass it a dictionary of relevant parameters and if doing a HyperparameterTuningJob, pass the CustomJob as an argument to the HyperparameterTuningJob class. Some variables, such as location, can be initiated just once when initiating aiplatform, and passing it as argument to individual jobs only serves to override the original value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e35a110-fe24-4f05-9203-ff4792ca0ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Utilities:\n",
    "\n",
    "Mainly, a function to clear the bigquery table for backtesting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2154b1-8631-45c9-9684-c0b5493c6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle5 as pickle\n",
    "import gcsfs\n",
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/jupyter/ficc/isaac_creds.json\"\n",
    "fs = gcsfs.GCSFileSystem(project='eng-reactor-287421')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99921ce4-6271-45fe-91e5-df40ca4bea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data_from_pickle(path, bucket = 'isaac_data'):\n",
    "#     if os.path.isfile(path):\n",
    "#         print('File available, loading pickle')\n",
    "#         with open(path, 'rb') as f:\n",
    "#             data = pickle.load(f)\n",
    "#     else:\n",
    "#         print(f'File not available, downloading from cloud storage and saving to {path}')\n",
    "#         gc_path = os.path.join(bucket, path)\n",
    "#         print(gc_path)\n",
    "#         with fs.open(gc_path) as gf:\n",
    "#             data = pd.read_pickle(gf)\n",
    "#         with open(path, 'wb') as f:\n",
    "#             pickle.dump(data, f)\n",
    "#     return data\n",
    "\n",
    "# path = '/home/jupyter/ficc/ml_models/sequence_predictors/isaac_experiments/New Features/data_latest_01-08_no_exclusions.pkl'\n",
    "# data = load_data_from_pickle(path)\n",
    "\n",
    "# data.to_pickle('gs://custom-train-job-test/large_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848efb28-bce3-4d63-bb2c-4135b3435f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSchema():\n",
    "    schema = [bigquery.SchemaField(\"rtrs_control_number\", \"INTEGER\"),\n",
    "                bigquery.SchemaField(\"cusip\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"trade_date\", \"DATE\"),\n",
    "                bigquery.SchemaField(\"yield\", \"FLOAT\"),\n",
    "                bigquery.SchemaField(\"new_ys\", \"FLOAT\"),\n",
    "                bigquery.SchemaField(\"new_ficc_ycl\", \"FLOAT\"),\n",
    "                bigquery.SchemaField(\"dollar_price\", \"FLOAT\"),\n",
    "                bigquery.SchemaField(\"new_ys_prediction\", \"FLOAT\"),\n",
    "             bigquery.SchemaField(\"prediction_datetime\", \"DATETIME\")]\n",
    "    return schema\n",
    "\n",
    "def uploadData(df, TABLE_ID, schema, write_disposition=\"WRITE_APPEND\"):\n",
    "    client = bigquery.Client(project='eng-reactor-287421', location=\"US\")\n",
    "    job_config = bigquery.LoadJobConfig(schema = schema, write_disposition=write_disposition)\n",
    "\n",
    "    job = client.load_table_from_dataframe(df, TABLE_ID,job_config=job_config)\n",
    "\n",
    "    try:\n",
    "        job.result()\n",
    "        print(\"BQ upload Successful\")\n",
    "    except Exception as e:\n",
    "        print(\"BQ failed to Upload\")\n",
    "        \n",
    "# def clear_bq():\n",
    "#     save_cols = ['rtrs_control_number', 'cusip', 'trade_date', 'dollar_price', 'yield', 'new_ficc_ycl', 'new_ys', 'new_ys_prediction', 'prediction_datetime']\n",
    "#     df = pd.DataFrame(columns=save_cols)\n",
    "#     uploadData(df, \n",
    "#                \"eng-reactor-287421.historical_predictions_test.historical_predictions_test\",\n",
    "#                getSchema(),\n",
    "#                'WRITE_TRUNCATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85101701-3376-4235-940f-680df0d01a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ upload Successful\n"
     ]
    }
   ],
   "source": [
    "# CLEARS BIG QUERY TABLE BE CAREFUL WHEN RUNNING \n",
    "# clear_bq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7543f-88ea-45d6-855e-4efe2e7553bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VERTEX AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf2af1e-8f9c-46e3-803c-2fd3975ff9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580eb178-0e39-4d53-8b57-193c660717c7",
   "metadata": {},
   "source": [
    "Arguments for HPT job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f1338c-554e-4c80-a98a-fd1993af8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = \"us-central1\"\n",
    "STAGING_BUCKET = \"gs://ficc-historical-results\"\n",
    "PROJECT_ID ='eng-reactor-287421'\n",
    "SERVICE_ACCOUNT = \"964018767272-compute@developer.gserviceaccount.com\"\n",
    "JOB_NAME = \"model_backtest_202301_202302\" \n",
    "CONTAINER_URI = \"us-east4-docker.pkg.dev/eng-reactor-287421/custom-train-job/ficc-historical-models:latest\"\n",
    "\n",
    "aip.init(project=PROJECT_ID,\n",
    "         staging_bucket=STAGING_BUCKET,\n",
    "         location=LOCATION)\n",
    "\n",
    "disk_spec = {\n",
    "    \"boot_disk_type\": \"pd-ssd\"  ,\n",
    "    \"boot_disk_size_gb\": 100\n",
    "}\n",
    "\n",
    "machine_spec = {\n",
    "    \"machine_type\": \"n1-highmem-16\",\n",
    "    \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "    \"accelerator_count\": 1\n",
    "}\n",
    "\n",
    "\n",
    "containerSpec = {\n",
    "    \"image_uri\": CONTAINER_URI,\n",
    "    \"args\": [\n",
    "        \"--train_months=6\",\n",
    "        \"--NUM_EPOCHS=150\",\n",
    "        \"--VALIDATION_SPLIT=0.1\",\n",
    "        \"--bucket=ficc-historical-results\",\n",
    "        \"--file=processed_data_2021-08_2023-02_dyc.pkl\",\n",
    "        \"--BATCH_SIZE=10000\",\n",
    "        \"--LEARNING_RATE=0.0007\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "worker_pool_spec = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": machine_spec,\n",
    "        \"disk_spec\": disk_spec,\n",
    "        \"container_spec\": containerSpec\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97374861-f980-4b37-bc2f-fd4d63f0ab19",
   "metadata": {},
   "source": [
    "Creating custom job with arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d49ad51-fc41-4fb7-902d-4029f418bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aip.CustomJob(display_name=JOB_NAME, \n",
    "                worker_pool_specs=worker_pool_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f028c34-00d8-43a7-a1f0-bd76e5acb584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# target_dates = pd.bdate_range('2022-01-01', '2022-12-31').strftime('%Y-%m-%d').to_list()\n",
    "# target_dates = pd.bdate_range('2023-01-01', '2023-02-28').strftime('%Y-%m-%d').to_list()\n",
    "target_dates = pd.bdate_range('2022-05-01', '2022-05-31').strftime('%Y-%m-%d').to_list()\n",
    "\n",
    "print(len(target_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69ef2454-7f42-439c-bf55-14078fbbe0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(target_dates[0::len(target_dates)-1])\n",
    "# target_dates = target_dates[0::len(target_dates)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e34ac-ddf0-4c38-9ae5-788125228093",
   "metadata": {},
   "source": [
    "Select dates for backtesting as a hyperparameter. Vertex AI will take a different value every run. With N runs = N dates, every date will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb8d793a-ef84-45c3-90b4-582f8f833cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dates = [\n",
    "#     '2023-03-01',\n",
    "#                 # '2023-04-03',\n",
    "#                 '2023-05-01',\n",
    "#                 '2023-06-01',\n",
    "#                 # '2023-07-03',\n",
    "#                 # '2023-08-01',\n",
    "#                 # '2023-09-01',\n",
    "#                 '2023-09-29',\n",
    "#                 # '2023-05-29'\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af31b0b6-16dc-4ed4-867f-bf749be78628",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(target_dates)\n",
    "hpt_dates = hpt.CategoricalParameterSpec(target_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273b7a4-580e-406c-aa07-ca9d95b88f29",
   "metadata": {},
   "source": [
    "Instantiate HyperparameterTuningJob class and pass arguments, then run on correct service account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b94c48f-c7b5-40e8-b0d3-5521a2481cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GPUS = 30 \n",
    "\n",
    "hpt_job = aip.HyperparameterTuningJob(\n",
    "    display_name=JOB_NAME,\n",
    "    custom_job=job,\n",
    "    metric_spec={\n",
    "        \"mae\": \"minimize\",\n",
    "    },\n",
    "    parameter_spec={\n",
    "        \"target_date\": hpt_dates,\n",
    "    },\n",
    "    max_trial_count=N,\n",
    "    parallel_trial_count=min(MAX_GPUS, N),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ccce4c-a2d0-441f-86e2-1aac1147dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating HyperparameterTuningJob\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob created. Resource name: projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728\n",
      "INFO:google.cloud.aiplatform.jobs:To use this HyperparameterTuningJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:hpt_job = aiplatform.HyperparameterTuningJob.get('projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728')\n",
      "INFO:google.cloud.aiplatform.jobs:View HyperparameterTuningJob:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/1130062451706953728?project=964018767272\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:HyperparameterTuningJob projects/964018767272/locations/us-central1/hyperparameterTuningJobs/1130062451706953728 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "ServiceUnavailable",
     "evalue": "503 The service is currently unavailable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"The service is currently unavailable.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:74.125.199.95:443 {grpc_message:\"The service is currently unavailable.\", grpc_status:14, created_time:\"2023-11-03T19:26:33.310840825+00:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13836/395021863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhpt_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSERVICE_ACCOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, timeout, restart_job_on_worker_restart, tensorboard, sync)\u001b[0m\n\u001b[1;32m   1603\u001b[0m             )\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mprevious_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_JOB_COMPLETE_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprevious_time\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlog_wait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mstate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Fetch the Job again for most up-to-date job state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sync_gca_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_sync_gca_resource\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;34m\"\"\"Sync GAPIC service representation of client class resource.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gca_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_get_gca_resource\u001b[0;34m(self, resource_name)\u001b[0m\n\u001b[1;32m    532\u001b[0m         )\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getter_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sync_gca_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/cloud/aiplatform_v1/services/job_service/client.py\u001b[0m in \u001b[0;36mget_hyperparameter_tuning_job\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;31m# Done; return the response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 The service is currently unavailable."
     ]
    }
   ],
   "source": [
    "hpt_job.run(service_account = SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3dca9-ef1e-4fc9-b3c3-676f2a60153d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
